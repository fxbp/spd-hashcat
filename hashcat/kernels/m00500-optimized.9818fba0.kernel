//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 6.2
.target sm_30, texmode_independent
.address_size 64

	// .globl	gpu_decompress

.entry gpu_decompress(
	.param .u64 .ptr .global .align 4 gpu_decompress_param_0,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_1,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_2,
	.param .u64 gpu_decompress_param_3
)
{
	.local .align 4 .b8 	__local_depot0[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<44>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd5, [gpu_decompress_param_0];
	ld.param.u64 	%rd6, [gpu_decompress_param_1];
	ld.param.u64 	%rd7, [gpu_decompress_param_2];
	ld.param.u64 	%rd8, [gpu_decompress_param_3];
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd9;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %ntid.x;
	mov.b32	%r25, %envreg3;
	mad.lo.s32 	%r26, %r23, %r24, %r25;
	mov.u32 	%r27, %tid.x;
	add.s32 	%r1, %r26, %r27;
	cvt.s64.s32	%rd10, %r1;
	setp.ge.u64	%p1, %rd10, %rd8;
	@%p1 bra 	BB0_12;

	mul.wide.s32 	%rd11, %r1, 12;
	add.s64 	%rd12, %rd5, %rd11;
	ld.global.u32 	%r2, [%rd12];
	ld.global.u32 	%r3, [%rd12+4];
	ld.global.u32 	%r4, [%rd12+8];
	mov.u64 	%rd13, 0;
	st.local.u32 	[%rd1+4], %rd13;
	st.local.u32 	[%rd1], %rd13;
	st.local.u32 	[%rd1+12], %rd13;
	st.local.u32 	[%rd1+8], %rd13;
	st.local.u32 	[%rd1+20], %rd13;
	st.local.u32 	[%rd1+16], %rd13;
	st.local.u32 	[%rd1+28], %rd13;
	st.local.u32 	[%rd1+24], %rd13;
	st.local.u32 	[%rd1+36], %rd13;
	st.local.u32 	[%rd1+32], %rd13;
	st.local.u32 	[%rd1+44], %rd13;
	st.local.u32 	[%rd1+40], %rd13;
	st.local.u32 	[%rd1+52], %rd13;
	st.local.u32 	[%rd1+48], %rd13;
	st.local.u32 	[%rd1+60], %rd13;
	st.local.u32 	[%rd1+56], %rd13;
	st.local.u32 	[%rd1+68], %rd13;
	st.local.u32 	[%rd1+64], %rd13;
	st.local.u32 	[%rd1+76], %rd13;
	st.local.u32 	[%rd1+72], %rd13;
	st.local.u32 	[%rd1+84], %rd13;
	st.local.u32 	[%rd1+80], %rd13;
	st.local.u32 	[%rd1+92], %rd13;
	st.local.u32 	[%rd1+88], %rd13;
	st.local.u32 	[%rd1+100], %rd13;
	st.local.u32 	[%rd1+96], %rd13;
	st.local.u32 	[%rd1+108], %rd13;
	st.local.u32 	[%rd1+104], %rd13;
	st.local.u32 	[%rd1+116], %rd13;
	st.local.u32 	[%rd1+112], %rd13;
	st.local.u32 	[%rd1+124], %rd13;
	st.local.u32 	[%rd1+120], %rd13;
	st.local.u32 	[%rd1+132], %rd13;
	st.local.u32 	[%rd1+128], %rd13;
	st.local.u32 	[%rd1+140], %rd13;
	st.local.u32 	[%rd1+136], %rd13;
	st.local.u32 	[%rd1+148], %rd13;
	st.local.u32 	[%rd1+144], %rd13;
	st.local.u32 	[%rd1+156], %rd13;
	st.local.u32 	[%rd1+152], %rd13;
	st.local.u32 	[%rd1+164], %rd13;
	st.local.u32 	[%rd1+160], %rd13;
	st.local.u32 	[%rd1+172], %rd13;
	st.local.u32 	[%rd1+168], %rd13;
	st.local.u32 	[%rd1+180], %rd13;
	st.local.u32 	[%rd1+176], %rd13;
	st.local.u32 	[%rd1+188], %rd13;
	st.local.u32 	[%rd1+184], %rd13;
	st.local.u32 	[%rd1+196], %rd13;
	st.local.u32 	[%rd1+192], %rd13;
	st.local.u32 	[%rd1+204], %rd13;
	st.local.u32 	[%rd1+200], %rd13;
	st.local.u32 	[%rd1+212], %rd13;
	st.local.u32 	[%rd1+208], %rd13;
	st.local.u32 	[%rd1+220], %rd13;
	st.local.u32 	[%rd1+216], %rd13;
	st.local.u32 	[%rd1+228], %rd13;
	st.local.u32 	[%rd1+224], %rd13;
	st.local.u32 	[%rd1+236], %rd13;
	st.local.u32 	[%rd1+232], %rd13;
	st.local.u32 	[%rd1+244], %rd13;
	st.local.u32 	[%rd1+240], %rd13;
	st.local.u32 	[%rd1+252], %rd13;
	st.local.u32 	[%rd1+248], %rd13;
	setp.eq.s32	%p2, %r3, 0;
	@%p2 bra 	BB0_10;

	and.b32  	%r5, %r3, 3;
	setp.eq.s32	%p3, %r5, 0;
	mov.u32 	%r54, 0;
	@%p3 bra 	BB0_8;

	setp.eq.s32	%p4, %r5, 1;
	mov.u32 	%r50, 0;
	@%p4 bra 	BB0_7;

	setp.eq.s32	%p5, %r5, 2;
	mov.u32 	%r48, 0;
	@%p5 bra 	BB0_6;

	mul.wide.u32 	%rd14, %r2, 4;
	add.s64 	%rd15, %rd6, %rd14;
	ld.global.u32 	%r32, [%rd15];
	st.local.u32 	[%rd1], %r32;
	add.s32 	%r2, %r2, 1;
	mov.u32 	%r48, 1;

BB0_6:
	mul.wide.u32 	%rd16, %r2, 4;
	add.s64 	%rd17, %rd6, %rd16;
	ld.global.u32 	%r33, [%rd17];
	mul.wide.u32 	%rd18, %r48, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.local.u32 	[%rd19], %r33;
	add.s32 	%r50, %r48, 1;
	add.s32 	%r2, %r2, 1;

BB0_7:
	mul.wide.u32 	%rd20, %r2, 4;
	add.s64 	%rd21, %rd6, %rd20;
	ld.global.u32 	%r34, [%rd21];
	mul.wide.u32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.local.u32 	[%rd23], %r34;
	add.s32 	%r54, %r50, 1;
	add.s32 	%r2, %r2, 1;

BB0_8:
	setp.lt.u32	%p6, %r3, 4;
	@%p6 bra 	BB0_10;

BB0_9:
	mul.wide.u32 	%rd24, %r2, 4;
	add.s64 	%rd25, %rd6, %rd24;
	ld.global.u32 	%r35, [%rd25];
	mul.wide.u32 	%rd26, %r54, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.local.u32 	[%rd27], %r35;
	add.s32 	%r36, %r2, 1;
	mul.wide.u32 	%rd28, %r36, 4;
	add.s64 	%rd29, %rd6, %rd28;
	ld.global.u32 	%r37, [%rd29];
	add.s32 	%r38, %r54, 1;
	mul.wide.u32 	%rd30, %r38, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.local.u32 	[%rd31], %r37;
	add.s32 	%r39, %r2, 2;
	mul.wide.u32 	%rd32, %r39, 4;
	add.s64 	%rd33, %rd6, %rd32;
	ld.global.u32 	%r40, [%rd33];
	add.s32 	%r41, %r54, 2;
	mul.wide.u32 	%rd34, %r41, 4;
	add.s64 	%rd35, %rd1, %rd34;
	st.local.u32 	[%rd35], %r40;
	add.s32 	%r42, %r2, 3;
	mul.wide.u32 	%rd36, %r42, 4;
	add.s64 	%rd37, %rd6, %rd36;
	ld.global.u32 	%r43, [%rd37];
	add.s32 	%r44, %r54, 3;
	mul.wide.u32 	%rd38, %r44, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.local.u32 	[%rd39], %r43;
	add.s32 	%r2, %r2, 4;
	add.s32 	%r54, %r54, 4;
	setp.lt.u32	%p7, %r54, %r3;
	@%p7 bra 	BB0_9;

BB0_10:
	st.local.u32 	[%rd1+256], %r4;
	mul.wide.s32 	%rd40, %r1, 260;
	add.s64 	%rd4, %rd7, %rd40;
	mov.u32 	%r55, 0;
	mov.pred 	%p8, 0;
	@%p8 bra 	BB0_12;

BB0_11:
	mul.wide.s32 	%rd41, %r55, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.local.u32 	%r46, [%rd42];
	add.s64 	%rd43, %rd4, %rd41;
	st.global.u32 	[%rd43], %r46;
	add.s32 	%r55, %r55, 1;
	setp.lt.u32	%p9, %r55, 65;
	@%p9 bra 	BB0_11;

BB0_12:
	ret;
}

	// .globl	gpu_memset
.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd1, [gpu_memset_param_0];
	ld.param.u32 	%r2, [gpu_memset_param_1];
	ld.param.u64 	%rd2, [gpu_memset_param_2];
	mov.b32	%r3, %envreg3;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mad.lo.s32 	%r6, %r4, %r5, %r3;
	mov.u32 	%r7, %tid.x;
	add.s32 	%r1, %r6, %r7;
	cvt.s64.s32	%rd3, %r1;
	setp.ge.u64	%p1, %rd3, %rd2;
	@%p1 bra 	BB1_2;

	mul.wide.s32 	%rd4, %r1, 16;
	add.s64 	%rd5, %rd1, %rd4;
	st.global.v4.u32 	[%rd5], {%r2, %r2, %r2, %r2};

BB1_2:
	ret;
}

	// .globl	gpu_atinit
.entry gpu_atinit(
	.param .u64 .ptr .global .align 4 gpu_atinit_param_0,
	.param .u64 gpu_atinit_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [gpu_atinit_param_0];
	ld.param.u64 	%rd3, [gpu_atinit_param_1];
	mov.b32	%r2, %envreg3;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r3, %r4, %r2;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB2_2;

	cvt.u32.u64	%r7, %rd1;
	shr.u64 	%rd4, %rd1, 32;
	cvt.u32.u64	%r8, %rd4;
	xor.b32  	%r9, %r7, 1549556828;
	xor.b32  	%r10, %r8, 909522486;
	mul.wide.s32 	%rd5, %r1, 260;
	add.s64 	%rd6, %rd2, %rd5;
	st.global.u32 	[%rd6], %r9;
	st.global.u32 	[%rd6+4], %r10;
	mov.u32 	%r11, 0;
	st.global.u32 	[%rd6+8], %r11;
	st.global.u32 	[%rd6+12], %r11;
	st.global.u32 	[%rd6+16], %r11;
	st.global.u32 	[%rd6+20], %r11;
	st.global.u32 	[%rd6+24], %r11;
	st.global.u32 	[%rd6+28], %r11;
	st.global.u32 	[%rd6+32], %r11;
	st.global.u32 	[%rd6+36], %r11;
	st.global.u32 	[%rd6+40], %r11;
	st.global.u32 	[%rd6+44], %r11;
	st.global.u32 	[%rd6+48], %r11;
	st.global.u32 	[%rd6+52], %r11;
	st.global.u32 	[%rd6+56], %r11;
	st.global.u32 	[%rd6+60], %r11;
	st.global.u32 	[%rd6+64], %r11;
	st.global.u32 	[%rd6+68], %r11;
	st.global.u32 	[%rd6+72], %r11;
	st.global.u32 	[%rd6+76], %r11;
	st.global.u32 	[%rd6+80], %r11;
	st.global.u32 	[%rd6+84], %r11;
	st.global.u32 	[%rd6+88], %r11;
	st.global.u32 	[%rd6+92], %r11;
	st.global.u32 	[%rd6+96], %r11;
	st.global.u32 	[%rd6+100], %r11;
	st.global.u32 	[%rd6+104], %r11;
	st.global.u32 	[%rd6+108], %r11;
	st.global.u32 	[%rd6+112], %r11;
	st.global.u32 	[%rd6+116], %r11;
	st.global.u32 	[%rd6+120], %r11;
	st.global.u32 	[%rd6+124], %r11;
	st.global.u32 	[%rd6+128], %r11;
	st.global.u32 	[%rd6+132], %r11;
	st.global.u32 	[%rd6+136], %r11;
	st.global.u32 	[%rd6+140], %r11;
	st.global.u32 	[%rd6+144], %r11;
	st.global.u32 	[%rd6+148], %r11;
	st.global.u32 	[%rd6+152], %r11;
	st.global.u32 	[%rd6+156], %r11;
	st.global.u32 	[%rd6+160], %r11;
	st.global.u32 	[%rd6+164], %r11;
	st.global.u32 	[%rd6+168], %r11;
	st.global.u32 	[%rd6+172], %r11;
	st.global.u32 	[%rd6+176], %r11;
	st.global.u32 	[%rd6+180], %r11;
	st.global.u32 	[%rd6+184], %r11;
	st.global.u32 	[%rd6+188], %r11;
	st.global.u32 	[%rd6+192], %r11;
	st.global.u32 	[%rd6+196], %r11;
	st.global.u32 	[%rd6+200], %r11;
	st.global.u32 	[%rd6+204], %r11;
	st.global.u32 	[%rd6+208], %r11;
	st.global.u32 	[%rd6+212], %r11;
	st.global.u32 	[%rd6+216], %r11;
	st.global.u32 	[%rd6+220], %r11;
	st.global.u32 	[%rd6+224], %r11;
	st.global.u32 	[%rd6+228], %r11;
	st.global.u32 	[%rd6+232], %r11;
	st.global.u32 	[%rd6+236], %r11;
	st.global.u32 	[%rd6+240], %r11;
	st.global.u32 	[%rd6+244], %r11;
	st.global.u32 	[%rd6+248], %r11;
	st.global.u32 	[%rd6+252], %r11;
	mov.u32 	%r12, 7;
	st.global.u32 	[%rd6+256], %r12;

BB2_2:
	ret;
}

	// .globl	m00500_init
.entry m00500_init(
	.param .u64 .ptr .global .align 4 m00500_init_param_0,
	.param .u64 .ptr .global .align 4 m00500_init_param_1,
	.param .u64 .ptr .global .align 4 m00500_init_param_2,
	.param .u64 .ptr .global .align 4 m00500_init_param_3,
	.param .u64 .ptr .global .align 4 m00500_init_param_4,
	.param .u64 .ptr .global .align 1 m00500_init_param_5,
	.param .u64 .ptr .global .align 4 m00500_init_param_6,
	.param .u64 .ptr .global .align 4 m00500_init_param_7,
	.param .u64 .ptr .global .align 4 m00500_init_param_8,
	.param .u64 .ptr .global .align 4 m00500_init_param_9,
	.param .u64 .ptr .global .align 4 m00500_init_param_10,
	.param .u64 .ptr .global .align 4 m00500_init_param_11,
	.param .u64 .ptr .global .align 4 m00500_init_param_12,
	.param .u64 .ptr .global .align 4 m00500_init_param_13,
	.param .u64 .ptr .global .align 8 m00500_init_param_14,
	.param .u64 .ptr .global .align 4 m00500_init_param_15,
	.param .u64 .ptr .global .align 4 m00500_init_param_16,
	.param .u64 .ptr .global .align 4 m00500_init_param_17,
	.param .u64 .ptr .global .align 1 m00500_init_param_18,
	.param .u64 .ptr .global .align 4 m00500_init_param_19,
	.param .u64 .ptr .global .align 16 m00500_init_param_20,
	.param .u64 .ptr .global .align 16 m00500_init_param_21,
	.param .u64 .ptr .global .align 16 m00500_init_param_22,
	.param .u64 .ptr .global .align 16 m00500_init_param_23,
	.param .u32 m00500_init_param_24,
	.param .u32 m00500_init_param_25,
	.param .u32 m00500_init_param_26,
	.param .u32 m00500_init_param_27,
	.param .u32 m00500_init_param_28,
	.param .u32 m00500_init_param_29,
	.param .u32 m00500_init_param_30,
	.param .u32 m00500_init_param_31,
	.param .u32 m00500_init_param_32,
	.param .u32 m00500_init_param_33,
	.param .u64 m00500_init_param_34
)
{
	.reg .pred 	%p<203>;
	.reg .b32 	%r<1773>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd1, [m00500_init_param_0];
	ld.param.u64 	%rd3, [m00500_init_param_17];
	ld.param.u32 	%r246, [m00500_init_param_27];
	ld.param.u64 	%rd4, [m00500_init_param_34];
	mov.b32	%r247, %envreg3;
	mov.u32 	%r248, %ctaid.x;
	mov.u32 	%r249, %ntid.x;
	mad.lo.s32 	%r250, %r248, %r249, %r247;
	mov.u32 	%r251, %tid.x;
	add.s32 	%r1, %r250, %r251;
	cvt.s64.s32	%rd5, %r1;
	setp.ge.u64	%p1, %rd5, %rd4;
	@%p1 bra 	BB3_331;

	mul.wide.s32 	%rd6, %r1, 260;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.u32 	%r1699, [%rd7];
	ld.global.u32 	%r1698, [%rd7+4];
	ld.global.u32 	%r1697, [%rd7+8];
	ld.global.u32 	%r1696, [%rd7+12];
	ld.global.u32 	%r6, [%rd7+256];
	and.b32  	%r1728, %r6, 63;
	mul.wide.u32 	%rd8, %r246, 560;
	add.s64 	%rd9, %rd3, %rd8;
	ld.global.u32 	%r8, [%rd9];
	ld.global.u32 	%r9, [%rd9+4];
	ld.global.u32 	%r10, [%rd9+512];
	and.b32  	%r275, %r6, 3;
	mov.u32 	%r276, 4;
	sub.s32 	%r277, %r276, %r275;
	shl.b32 	%r278, %r277, 2;
	mov.u32 	%r279, 1985229328;
	shr.u32 	%r280, %r279, %r278;
	and.b32  	%r263, %r280, 65535;
	mov.u32 	%r273, 0;
	// inline asm
	prmt.b32 %r252, %r273, %r8, %r263;
	// inline asm
	// inline asm
	prmt.b32 %r256, %r8, %r9, %r263;
	// inline asm
	// inline asm
	prmt.b32 %r260, %r9, %r273, %r263;
	// inline asm
	bfe.u32 	%r274, %r6, 2, 4;
	setp.gt.s32	%p2, %r274, 5;
	@%p2 bra 	BB3_11;

	setp.gt.s32	%p10, %r274, 2;
	@%p10 bra 	BB3_7;

	setp.eq.s32	%p14, %r274, 0;
	@%p14 bra 	BB3_27;

	setp.eq.s32	%p15, %r274, 1;
	@%p15 bra 	BB3_26;
	bra.uni 	BB3_5;

BB3_26:
	or.b32  	%r1665, %r252, %r1698;
	mov.u32 	%r1663, %r260;
	mov.u32 	%r1664, %r256;
	mov.u32 	%r1666, %r1699;
	bra.uni 	BB3_28;

BB3_11:
	setp.gt.s32	%p3, %r274, 8;
	@%p3 bra 	BB3_16;

	setp.eq.s32	%p7, %r274, 6;
	@%p7 bra 	BB3_23;

	setp.eq.s32	%p8, %r274, 7;
	@%p8 bra 	BB3_22;
	bra.uni 	BB3_14;

BB3_22:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r252;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r260;
	mov.u32 	%r1674, %r256;
	bra.uni 	BB3_32;

BB3_7:
	setp.eq.s32	%p11, %r274, 3;
	@%p11 bra 	BB3_25;

	setp.eq.s32	%p12, %r274, 4;
	@%p12 bra 	BB3_24;
	bra.uni 	BB3_9;

BB3_24:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r260;
	mov.u32 	%r1669, %r256;
	mov.u32 	%r1670, %r252;
	bra.uni 	BB3_30;

BB3_16:
	setp.eq.s32	%p4, %r274, 9;
	@%p4 bra 	BB3_21;

	setp.eq.s32	%p5, %r274, 10;
	@%p5 bra 	BB3_20;
	bra.uni 	BB3_18;

BB3_20:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r256;
	mov.u32 	%r1672, %r252;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r260;
	bra.uni 	BB3_33;

BB3_27:
	or.b32  	%r1666, %r252, %r1699;
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r260;
	mov.u32 	%r1665, %r256;

BB3_28:
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	bra.uni 	BB3_29;

BB3_5:
	setp.eq.s32	%p16, %r274, 2;
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r273;
	@%p16 bra 	BB3_6;
	bra.uni 	BB3_33;

BB3_6:
	or.b32  	%r1664, %r252, %r1697;
	mov.u32 	%r1663, %r256;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r260;
	bra.uni 	BB3_30;

BB3_23:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r256;
	mov.u32 	%r1668, %r252;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r260;
	bra.uni 	BB3_32;

BB3_14:
	setp.eq.s32	%p9, %r274, 8;
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r273;
	@%p9 bra 	BB3_15;
	bra.uni 	BB3_33;

BB3_15:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r260;
	mov.u32 	%r1673, %r256;
	mov.u32 	%r1674, %r252;
	bra.uni 	BB3_32;

BB3_25:
	or.b32  	%r1663, %r252, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r260;
	mov.u32 	%r1670, %r256;
	bra.uni 	BB3_30;

BB3_9:
	setp.eq.s32	%p13, %r274, 5;
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r273;
	@%p13 bra 	BB3_10;
	bra.uni 	BB3_33;

BB3_10:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r260;
	mov.u32 	%r1668, %r256;
	mov.u32 	%r1669, %r252;

BB3_29:
	mov.u32 	%r1670, %r273;

BB3_30:
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	bra.uni 	BB3_31;

BB3_21:
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r260;
	mov.u32 	%r1672, %r256;
	mov.u32 	%r1673, %r252;

BB3_31:
	mov.u32 	%r1674, %r273;

BB3_32:
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r273;

BB3_33:
	add.s32 	%r395, %r10, %r6;
	and.b32  	%r396, %r395, 3;
	sub.s32 	%r398, %r276, %r396;
	shl.b32 	%r399, %r398, 2;
	shr.u32 	%r401, %r279, %r399;
	and.b32  	%r393, %r401, 65535;
	// inline asm
	prmt.b32 %r374, %r273, %r1699, %r393;
	// inline asm
	// inline asm
	prmt.b32 %r378, %r1699, %r1698, %r393;
	// inline asm
	// inline asm
	prmt.b32 %r382, %r1698, %r1697, %r393;
	// inline asm
	// inline asm
	prmt.b32 %r1690, %r1697, %r1696, %r393;
	// inline asm
	// inline asm
	prmt.b32 %r390, %r1696, %r273, %r393;
	// inline asm
	add.s32 	%r37, %r10, %r1728;
	shr.u32 	%r394, %r37, 2;
	setp.gt.s32	%p17, %r394, 4;
	@%p17 bra 	BB3_42;

	setp.gt.s32	%p24, %r394, 1;
	@%p24 bra 	BB3_38;

	setp.eq.s32	%p28, %r394, 0;
	@%p28 bra 	BB3_55;
	bra.uni 	BB3_36;

BB3_55:
	or.b32  	%r1666, %r374, %r1666;
	mov.u32 	%r1663, %r1690;
	mov.u32 	%r1664, %r382;
	mov.u32 	%r1665, %r378;
	mov.u32 	%r1670, %r390;
	bra.uni 	BB3_56;

BB3_42:
	setp.gt.s32	%p18, %r394, 6;
	@%p18 bra 	BB3_46;

	setp.eq.s32	%p22, %r394, 5;
	@%p22 bra 	BB3_52;
	bra.uni 	BB3_44;

BB3_52:
	or.b32  	%r1669, %r374, %r1669;
	mov.u32 	%r1667, %r382;
	mov.u32 	%r1668, %r378;
	mov.u32 	%r1673, %r390;
	mov.u32 	%r1674, %r1690;
	bra.uni 	BB3_56;

BB3_38:
	setp.eq.s32	%p25, %r394, 2;
	@%p25 bra 	BB3_54;

	setp.eq.s32	%p26, %r394, 3;
	@%p26 bra 	BB3_53;
	bra.uni 	BB3_40;

BB3_53:
	or.b32  	%r1663, %r374, %r1663;
	mov.u32 	%r1667, %r390;
	mov.u32 	%r1668, %r1690;
	mov.u32 	%r1669, %r382;
	mov.u32 	%r1670, %r378;
	bra.uni 	BB3_56;

BB3_46:
	setp.eq.s32	%p19, %r394, 7;
	@%p19 bra 	BB3_51;

	setp.eq.s32	%p20, %r394, 8;
	@%p20 bra 	BB3_50;
	bra.uni 	BB3_48;

BB3_50:
	or.b32  	%r1674, %r374, %r1674;
	mov.u32 	%r1671, %r1690;
	mov.u32 	%r1672, %r382;
	mov.u32 	%r1673, %r378;
	mov.u32 	%r1690, %r390;
	bra.uni 	BB3_57;

BB3_36:
	setp.eq.s32	%p29, %r394, 1;
	@%p29 bra 	BB3_37;
	bra.uni 	BB3_56;

BB3_37:
	or.b32  	%r1665, %r374, %r1665;
	mov.u32 	%r1663, %r382;
	mov.u32 	%r1664, %r378;
	mov.u32 	%r1669, %r390;
	mov.u32 	%r1670, %r1690;
	bra.uni 	BB3_56;

BB3_44:
	setp.eq.s32	%p23, %r394, 6;
	@%p23 bra 	BB3_45;
	bra.uni 	BB3_56;

BB3_45:
	or.b32  	%r1668, %r374, %r1668;
	mov.u32 	%r1667, %r378;
	mov.u32 	%r1672, %r390;
	mov.u32 	%r1673, %r1690;
	mov.u32 	%r1674, %r382;
	bra.uni 	BB3_56;

BB3_18:
	setp.ne.s32	%p6, %r274, 11;
	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r273;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r273;
	mov.u32 	%r1676, %r273;
	@%p6 bra 	BB3_33;

	mov.u32 	%r1663, %r1696;
	mov.u32 	%r1664, %r1697;
	mov.u32 	%r1665, %r1698;
	mov.u32 	%r1666, %r1699;
	mov.u32 	%r1667, %r273;
	mov.u32 	%r1668, %r273;
	mov.u32 	%r1669, %r273;
	mov.u32 	%r1670, %r273;
	mov.u32 	%r1671, %r252;
	mov.u32 	%r1672, %r273;
	mov.u32 	%r1673, %r273;
	mov.u32 	%r1674, %r273;
	mov.u32 	%r1675, %r260;
	mov.u32 	%r1676, %r256;
	bra.uni 	BB3_33;

BB3_54:
	or.b32  	%r1664, %r374, %r1664;
	mov.u32 	%r1663, %r378;
	mov.u32 	%r1668, %r390;
	mov.u32 	%r1669, %r1690;
	mov.u32 	%r1670, %r382;
	bra.uni 	BB3_56;

BB3_40:
	setp.eq.s32	%p27, %r394, 4;
	@%p27 bra 	BB3_41;
	bra.uni 	BB3_56;

BB3_41:
	or.b32  	%r1670, %r374, %r1670;
	mov.u32 	%r1667, %r1690;
	mov.u32 	%r1668, %r382;
	mov.u32 	%r1669, %r378;
	mov.u32 	%r1674, %r390;
	bra.uni 	BB3_56;

BB3_51:
	or.b32  	%r1667, %r374, %r1667;
	mov.u32 	%r1671, %r390;
	mov.u32 	%r1672, %r1690;
	mov.u32 	%r1673, %r382;
	mov.u32 	%r1674, %r378;
	bra.uni 	BB3_56;

BB3_48:
	setp.ne.s32	%p21, %r394, 9;
	@%p21 bra 	BB3_56;

	or.b32  	%r1673, %r374, %r1673;
	mov.u32 	%r1671, %r382;
	mov.u32 	%r1672, %r378;
	mov.u32 	%r1675, %r390;
	bra.uni 	BB3_57;

BB3_56:
	mov.u32 	%r1690, %r1676;

BB3_57:
	add.s32 	%r403, %r37, %r1728;
	bfe.u32 	%r404, %r403, 2, 2;
	add.s32 	%r405, %r37, %r6;
	shl.b32 	%r406, %r405, 3;
	and.b32  	%r407, %r406, 24;
	mov.u32 	%r408, 255;
	shl.b32 	%r409, %r408, %r407;
	setp.eq.s32	%p30, %r404, 0;
	selp.b32	%r410, %r409, 0, %p30;
	setp.eq.s32	%p31, %r404, 1;
	selp.b32	%r411, %r409, 0, %p31;
	setp.eq.s32	%p32, %r404, 2;
	selp.b32	%r412, %r409, 0, %p32;
	setp.eq.s32	%p33, %r404, 3;
	selp.b32	%r413, %r409, 0, %p33;
	shr.u32 	%r414, %r403, 4;
	setp.eq.s32	%p34, %r414, 0;
	selp.b32	%r415, -2139062144, 0, %p34;
	and.b32  	%r416, %r410, %r415;
	or.b32  	%r417, %r1666, %r416;
	and.b32  	%r418, %r411, %r415;
	or.b32  	%r419, %r1665, %r418;
	and.b32  	%r420, %r412, %r415;
	or.b32  	%r421, %r1664, %r420;
	and.b32  	%r422, %r413, %r415;
	or.b32  	%r423, %r1663, %r422;
	setp.eq.s32	%p35, %r414, 1;
	selp.b32	%r424, -2139062144, 0, %p35;
	and.b32  	%r425, %r410, %r424;
	or.b32  	%r426, %r1670, %r425;
	and.b32  	%r427, %r411, %r424;
	or.b32  	%r428, %r1669, %r427;
	and.b32  	%r429, %r412, %r424;
	or.b32  	%r430, %r1668, %r429;
	and.b32  	%r431, %r413, %r424;
	or.b32  	%r432, %r1667, %r431;
	setp.eq.s32	%p36, %r414, 2;
	selp.b32	%r433, -2139062144, 0, %p36;
	and.b32  	%r434, %r410, %r433;
	or.b32  	%r435, %r1674, %r434;
	and.b32  	%r436, %r411, %r433;
	or.b32  	%r437, %r1673, %r436;
	and.b32  	%r438, %r412, %r433;
	or.b32  	%r439, %r1672, %r438;
	and.b32  	%r440, %r413, %r433;
	or.b32  	%r441, %r1671, %r440;
	setp.eq.s32	%p37, %r414, 3;
	selp.b32	%r442, -2139062144, 0, %p37;
	and.b32  	%r443, %r410, %r442;
	or.b32  	%r444, %r1690, %r443;
	and.b32  	%r445, %r411, %r442;
	or.b32  	%r446, %r1675, %r445;
	and.b32  	%r447, %r413, %r442;
	shl.b32 	%r448, %r403, 3;
	add.s32 	%r449, %r417, -680876937;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r449, 7;
	shr.b32 	%rhs, %r449, 25;
	add.u32 	%r450, %lhs, %rhs;
	}
	add.s32 	%r451, %r450, -271733879;
	and.b32  	%r452, %r451, 2004318071;
	xor.b32  	%r453, %r452, -1732584194;
	add.s32 	%r454, %r419, %r453;
	add.s32 	%r455, %r454, -117830708;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r455, 12;
	shr.b32 	%rhs, %r455, 20;
	add.u32 	%r456, %lhs, %rhs;
	}
	add.s32 	%r457, %r456, %r451;
	xor.b32  	%r458, %r451, -271733879;
	and.b32  	%r459, %r457, %r458;
	xor.b32  	%r460, %r459, -271733879;
	add.s32 	%r461, %r421, %r460;
	add.s32 	%r462, %r461, -1126478375;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r462, 17;
	shr.b32 	%rhs, %r462, 15;
	add.u32 	%r463, %lhs, %rhs;
	}
	add.s32 	%r464, %r463, %r457;
	xor.b32  	%r465, %r457, %r451;
	and.b32  	%r466, %r464, %r465;
	xor.b32  	%r467, %r466, %r451;
	add.s32 	%r468, %r423, %r467;
	add.s32 	%r469, %r468, -1316259209;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r469, 22;
	shr.b32 	%rhs, %r469, 10;
	add.u32 	%r470, %lhs, %rhs;
	}
	add.s32 	%r471, %r470, %r464;
	xor.b32  	%r472, %r464, %r457;
	and.b32  	%r473, %r471, %r472;
	xor.b32  	%r474, %r473, %r457;
	add.s32 	%r475, %r426, %r450;
	add.s32 	%r476, %r475, %r474;
	add.s32 	%r477, %r476, -448152776;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r477, 7;
	shr.b32 	%rhs, %r477, 25;
	add.u32 	%r478, %lhs, %rhs;
	}
	add.s32 	%r479, %r478, %r471;
	xor.b32  	%r480, %r471, %r464;
	and.b32  	%r481, %r479, %r480;
	xor.b32  	%r482, %r481, %r464;
	add.s32 	%r483, %r428, %r457;
	add.s32 	%r484, %r483, %r482;
	add.s32 	%r485, %r484, 1200080426;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r485, 12;
	shr.b32 	%rhs, %r485, 20;
	add.u32 	%r486, %lhs, %rhs;
	}
	add.s32 	%r487, %r486, %r479;
	xor.b32  	%r488, %r479, %r471;
	and.b32  	%r489, %r487, %r488;
	xor.b32  	%r490, %r489, %r471;
	add.s32 	%r491, %r430, %r464;
	add.s32 	%r492, %r491, %r490;
	add.s32 	%r493, %r492, -1473231341;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r493, 17;
	shr.b32 	%rhs, %r493, 15;
	add.u32 	%r494, %lhs, %rhs;
	}
	add.s32 	%r495, %r494, %r487;
	xor.b32  	%r496, %r487, %r479;
	and.b32  	%r497, %r495, %r496;
	xor.b32  	%r498, %r497, %r479;
	add.s32 	%r499, %r432, %r471;
	add.s32 	%r500, %r499, %r498;
	add.s32 	%r501, %r500, -45705983;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r501, 22;
	shr.b32 	%rhs, %r501, 10;
	add.u32 	%r502, %lhs, %rhs;
	}
	add.s32 	%r503, %r502, %r495;
	xor.b32  	%r504, %r495, %r487;
	and.b32  	%r505, %r503, %r504;
	xor.b32  	%r506, %r505, %r487;
	add.s32 	%r507, %r435, %r479;
	add.s32 	%r508, %r507, %r506;
	add.s32 	%r509, %r508, 1770035416;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r509, 7;
	shr.b32 	%rhs, %r509, 25;
	add.u32 	%r510, %lhs, %rhs;
	}
	add.s32 	%r511, %r510, %r503;
	xor.b32  	%r512, %r503, %r495;
	and.b32  	%r513, %r511, %r512;
	xor.b32  	%r514, %r513, %r495;
	add.s32 	%r515, %r437, %r487;
	add.s32 	%r516, %r515, %r514;
	add.s32 	%r517, %r516, -1958414417;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r517, 12;
	shr.b32 	%rhs, %r517, 20;
	add.u32 	%r518, %lhs, %rhs;
	}
	add.s32 	%r519, %r518, %r511;
	xor.b32  	%r520, %r511, %r503;
	and.b32  	%r521, %r519, %r520;
	xor.b32  	%r522, %r521, %r503;
	add.s32 	%r523, %r439, %r495;
	add.s32 	%r524, %r523, %r522;
	add.s32 	%r525, %r524, -42063;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r525, 17;
	shr.b32 	%rhs, %r525, 15;
	add.u32 	%r526, %lhs, %rhs;
	}
	add.s32 	%r527, %r526, %r519;
	xor.b32  	%r528, %r519, %r511;
	and.b32  	%r529, %r527, %r528;
	xor.b32  	%r530, %r529, %r511;
	add.s32 	%r531, %r441, %r503;
	add.s32 	%r532, %r531, %r530;
	add.s32 	%r533, %r532, -1990404162;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r533, 22;
	shr.b32 	%rhs, %r533, 10;
	add.u32 	%r534, %lhs, %rhs;
	}
	add.s32 	%r535, %r534, %r527;
	xor.b32  	%r536, %r527, %r519;
	and.b32  	%r537, %r535, %r536;
	xor.b32  	%r538, %r537, %r519;
	add.s32 	%r539, %r444, %r511;
	add.s32 	%r540, %r539, %r538;
	add.s32 	%r541, %r540, 1804603682;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r541, 7;
	shr.b32 	%rhs, %r541, 25;
	add.u32 	%r542, %lhs, %rhs;
	}
	add.s32 	%r543, %r542, %r535;
	xor.b32  	%r544, %r535, %r527;
	and.b32  	%r545, %r543, %r544;
	xor.b32  	%r546, %r545, %r527;
	add.s32 	%r547, %r446, %r519;
	add.s32 	%r548, %r547, %r546;
	add.s32 	%r549, %r548, -40341101;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r549, 12;
	shr.b32 	%rhs, %r549, 20;
	add.u32 	%r550, %lhs, %rhs;
	}
	add.s32 	%r551, %r550, %r543;
	xor.b32  	%r552, %r543, %r535;
	and.b32  	%r553, %r551, %r552;
	xor.b32  	%r554, %r553, %r535;
	add.s32 	%r555, %r448, %r527;
	add.s32 	%r556, %r555, %r554;
	add.s32 	%r557, %r556, -1502002290;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r557, 17;
	shr.b32 	%rhs, %r557, 15;
	add.u32 	%r558, %lhs, %rhs;
	}
	add.s32 	%r559, %r558, %r551;
	xor.b32  	%r560, %r551, %r543;
	and.b32  	%r561, %r559, %r560;
	xor.b32  	%r562, %r561, %r543;
	add.s32 	%r563, %r447, %r535;
	add.s32 	%r564, %r563, %r562;
	add.s32 	%r565, %r564, 1236535329;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r565, 22;
	shr.b32 	%rhs, %r565, 10;
	add.u32 	%r566, %lhs, %rhs;
	}
	add.s32 	%r567, %r566, %r559;
	xor.b32  	%r568, %r567, %r559;
	and.b32  	%r569, %r568, %r551;
	xor.b32  	%r570, %r569, %r559;
	add.s32 	%r571, %r419, %r543;
	add.s32 	%r572, %r571, %r570;
	add.s32 	%r573, %r572, -165796510;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r573, 5;
	shr.b32 	%rhs, %r573, 27;
	add.u32 	%r574, %lhs, %rhs;
	}
	add.s32 	%r575, %r574, %r567;
	xor.b32  	%r576, %r575, %r567;
	and.b32  	%r577, %r576, %r559;
	xor.b32  	%r578, %r577, %r567;
	add.s32 	%r579, %r430, %r551;
	add.s32 	%r580, %r579, %r578;
	add.s32 	%r581, %r580, -1069501632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r581, 9;
	shr.b32 	%rhs, %r581, 23;
	add.u32 	%r582, %lhs, %rhs;
	}
	add.s32 	%r583, %r582, %r575;
	xor.b32  	%r584, %r583, %r575;
	and.b32  	%r585, %r584, %r567;
	xor.b32  	%r586, %r585, %r575;
	add.s32 	%r587, %r441, %r559;
	add.s32 	%r588, %r587, %r586;
	add.s32 	%r589, %r588, 643717713;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r589, 14;
	shr.b32 	%rhs, %r589, 18;
	add.u32 	%r590, %lhs, %rhs;
	}
	add.s32 	%r591, %r590, %r583;
	xor.b32  	%r592, %r591, %r583;
	and.b32  	%r593, %r592, %r575;
	xor.b32  	%r594, %r593, %r583;
	add.s32 	%r595, %r417, %r567;
	add.s32 	%r596, %r595, %r594;
	add.s32 	%r597, %r596, -373897302;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r597, 20;
	shr.b32 	%rhs, %r597, 12;
	add.u32 	%r598, %lhs, %rhs;
	}
	add.s32 	%r599, %r598, %r591;
	xor.b32  	%r600, %r599, %r591;
	and.b32  	%r601, %r600, %r583;
	xor.b32  	%r602, %r601, %r591;
	add.s32 	%r603, %r428, %r575;
	add.s32 	%r604, %r603, %r602;
	add.s32 	%r605, %r604, -701558691;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r605, 5;
	shr.b32 	%rhs, %r605, 27;
	add.u32 	%r606, %lhs, %rhs;
	}
	add.s32 	%r607, %r606, %r599;
	xor.b32  	%r608, %r607, %r599;
	and.b32  	%r609, %r608, %r591;
	xor.b32  	%r610, %r609, %r599;
	add.s32 	%r611, %r439, %r583;
	add.s32 	%r612, %r611, %r610;
	add.s32 	%r613, %r612, 38016083;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r613, 9;
	shr.b32 	%rhs, %r613, 23;
	add.u32 	%r614, %lhs, %rhs;
	}
	add.s32 	%r615, %r614, %r607;
	xor.b32  	%r616, %r615, %r607;
	and.b32  	%r617, %r616, %r599;
	xor.b32  	%r618, %r617, %r607;
	add.s32 	%r619, %r447, %r591;
	add.s32 	%r620, %r619, %r618;
	add.s32 	%r621, %r620, -660478335;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r621, 14;
	shr.b32 	%rhs, %r621, 18;
	add.u32 	%r622, %lhs, %rhs;
	}
	add.s32 	%r623, %r622, %r615;
	xor.b32  	%r624, %r623, %r615;
	and.b32  	%r625, %r624, %r607;
	xor.b32  	%r626, %r625, %r615;
	add.s32 	%r627, %r426, %r599;
	add.s32 	%r628, %r627, %r626;
	add.s32 	%r629, %r628, -405537848;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r629, 20;
	shr.b32 	%rhs, %r629, 12;
	add.u32 	%r630, %lhs, %rhs;
	}
	add.s32 	%r631, %r630, %r623;
	xor.b32  	%r632, %r631, %r623;
	and.b32  	%r633, %r632, %r615;
	xor.b32  	%r634, %r633, %r623;
	add.s32 	%r635, %r437, %r607;
	add.s32 	%r636, %r635, %r634;
	add.s32 	%r637, %r636, 568446438;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r637, 5;
	shr.b32 	%rhs, %r637, 27;
	add.u32 	%r638, %lhs, %rhs;
	}
	add.s32 	%r639, %r638, %r631;
	xor.b32  	%r640, %r639, %r631;
	and.b32  	%r641, %r640, %r623;
	xor.b32  	%r642, %r641, %r631;
	add.s32 	%r643, %r448, %r615;
	add.s32 	%r644, %r643, %r642;
	add.s32 	%r645, %r644, -1019803690;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r645, 9;
	shr.b32 	%rhs, %r645, 23;
	add.u32 	%r646, %lhs, %rhs;
	}
	add.s32 	%r647, %r646, %r639;
	xor.b32  	%r648, %r647, %r639;
	and.b32  	%r649, %r648, %r631;
	xor.b32  	%r650, %r649, %r639;
	add.s32 	%r651, %r423, %r623;
	add.s32 	%r652, %r651, %r650;
	add.s32 	%r653, %r652, -187363961;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r653, 14;
	shr.b32 	%rhs, %r653, 18;
	add.u32 	%r654, %lhs, %rhs;
	}
	add.s32 	%r655, %r654, %r647;
	xor.b32  	%r656, %r655, %r647;
	and.b32  	%r657, %r656, %r639;
	xor.b32  	%r658, %r657, %r647;
	add.s32 	%r659, %r435, %r631;
	add.s32 	%r660, %r659, %r658;
	add.s32 	%r661, %r660, 1163531501;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r661, 20;
	shr.b32 	%rhs, %r661, 12;
	add.u32 	%r662, %lhs, %rhs;
	}
	add.s32 	%r663, %r662, %r655;
	xor.b32  	%r664, %r663, %r655;
	and.b32  	%r665, %r664, %r647;
	xor.b32  	%r666, %r665, %r655;
	add.s32 	%r667, %r446, %r639;
	add.s32 	%r668, %r667, %r666;
	add.s32 	%r669, %r668, -1444681467;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r669, 5;
	shr.b32 	%rhs, %r669, 27;
	add.u32 	%r670, %lhs, %rhs;
	}
	add.s32 	%r671, %r670, %r663;
	xor.b32  	%r672, %r671, %r663;
	and.b32  	%r673, %r672, %r655;
	xor.b32  	%r674, %r673, %r663;
	add.s32 	%r675, %r421, %r647;
	add.s32 	%r676, %r675, %r674;
	add.s32 	%r677, %r676, -51403784;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r677, 9;
	shr.b32 	%rhs, %r677, 23;
	add.u32 	%r678, %lhs, %rhs;
	}
	add.s32 	%r679, %r678, %r671;
	xor.b32  	%r680, %r679, %r671;
	and.b32  	%r681, %r680, %r663;
	xor.b32  	%r682, %r681, %r671;
	add.s32 	%r683, %r432, %r655;
	add.s32 	%r684, %r683, %r682;
	add.s32 	%r685, %r684, 1735328473;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r685, 14;
	shr.b32 	%rhs, %r685, 18;
	add.u32 	%r686, %lhs, %rhs;
	}
	add.s32 	%r687, %r686, %r679;
	xor.b32  	%r688, %r687, %r679;
	and.b32  	%r689, %r688, %r671;
	xor.b32  	%r690, %r689, %r679;
	add.s32 	%r691, %r444, %r663;
	add.s32 	%r692, %r691, %r690;
	add.s32 	%r693, %r692, -1926607734;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r693, 20;
	shr.b32 	%rhs, %r693, 12;
	add.u32 	%r694, %lhs, %rhs;
	}
	add.s32 	%r695, %r694, %r687;
	xor.b32  	%r696, %r695, %r687;
	xor.b32  	%r697, %r696, %r679;
	add.s32 	%r698, %r428, %r671;
	add.s32 	%r699, %r698, %r697;
	add.s32 	%r700, %r699, -378558;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r700, 4;
	shr.b32 	%rhs, %r700, 28;
	add.u32 	%r701, %lhs, %rhs;
	}
	add.s32 	%r702, %r701, %r695;
	xor.b32  	%r703, %r702, %r696;
	add.s32 	%r704, %r435, %r679;
	add.s32 	%r705, %r704, %r703;
	add.s32 	%r706, %r705, -2022574463;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r706, 11;
	shr.b32 	%rhs, %r706, 21;
	add.u32 	%r707, %lhs, %rhs;
	}
	add.s32 	%r708, %r707, %r702;
	xor.b32  	%r709, %r708, %r702;
	xor.b32  	%r710, %r709, %r695;
	add.s32 	%r711, %r441, %r687;
	add.s32 	%r712, %r711, %r710;
	add.s32 	%r713, %r712, 1839030562;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r713, 16;
	shr.b32 	%rhs, %r713, 16;
	add.u32 	%r714, %lhs, %rhs;
	}
	add.s32 	%r715, %r714, %r708;
	xor.b32  	%r716, %r715, %r709;
	add.s32 	%r717, %r448, %r695;
	add.s32 	%r718, %r717, %r716;
	add.s32 	%r719, %r718, -35309556;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r719, 23;
	shr.b32 	%rhs, %r719, 9;
	add.u32 	%r720, %lhs, %rhs;
	}
	add.s32 	%r721, %r720, %r715;
	xor.b32  	%r722, %r721, %r715;
	xor.b32  	%r723, %r722, %r708;
	add.s32 	%r724, %r419, %r702;
	add.s32 	%r725, %r724, %r723;
	add.s32 	%r726, %r725, -1530992060;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r726, 4;
	shr.b32 	%rhs, %r726, 28;
	add.u32 	%r727, %lhs, %rhs;
	}
	add.s32 	%r728, %r727, %r721;
	xor.b32  	%r729, %r728, %r722;
	add.s32 	%r730, %r426, %r708;
	add.s32 	%r731, %r730, %r729;
	add.s32 	%r732, %r731, 1272893353;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r732, 11;
	shr.b32 	%rhs, %r732, 21;
	add.u32 	%r733, %lhs, %rhs;
	}
	add.s32 	%r734, %r733, %r728;
	xor.b32  	%r735, %r734, %r728;
	xor.b32  	%r736, %r735, %r721;
	add.s32 	%r737, %r432, %r715;
	add.s32 	%r738, %r737, %r736;
	add.s32 	%r739, %r738, -155497632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r739, 16;
	shr.b32 	%rhs, %r739, 16;
	add.u32 	%r740, %lhs, %rhs;
	}
	add.s32 	%r741, %r740, %r734;
	xor.b32  	%r742, %r741, %r735;
	add.s32 	%r743, %r439, %r721;
	add.s32 	%r744, %r743, %r742;
	add.s32 	%r745, %r744, -1094730640;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r745, 23;
	shr.b32 	%rhs, %r745, 9;
	add.u32 	%r746, %lhs, %rhs;
	}
	add.s32 	%r747, %r746, %r741;
	xor.b32  	%r748, %r747, %r741;
	xor.b32  	%r749, %r748, %r734;
	add.s32 	%r750, %r446, %r728;
	add.s32 	%r751, %r750, %r749;
	add.s32 	%r752, %r751, 681279174;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r752, 4;
	shr.b32 	%rhs, %r752, 28;
	add.u32 	%r753, %lhs, %rhs;
	}
	add.s32 	%r754, %r753, %r747;
	xor.b32  	%r755, %r754, %r748;
	add.s32 	%r756, %r417, %r734;
	add.s32 	%r757, %r756, %r755;
	add.s32 	%r758, %r757, -358537222;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r758, 11;
	shr.b32 	%rhs, %r758, 21;
	add.u32 	%r759, %lhs, %rhs;
	}
	add.s32 	%r760, %r759, %r754;
	xor.b32  	%r761, %r760, %r754;
	xor.b32  	%r762, %r761, %r747;
	add.s32 	%r763, %r423, %r741;
	add.s32 	%r764, %r763, %r762;
	add.s32 	%r765, %r764, -722521979;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r765, 16;
	shr.b32 	%rhs, %r765, 16;
	add.u32 	%r766, %lhs, %rhs;
	}
	add.s32 	%r767, %r766, %r760;
	xor.b32  	%r768, %r767, %r761;
	add.s32 	%r769, %r430, %r747;
	add.s32 	%r770, %r769, %r768;
	add.s32 	%r771, %r770, 76029189;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r771, 23;
	shr.b32 	%rhs, %r771, 9;
	add.u32 	%r772, %lhs, %rhs;
	}
	add.s32 	%r773, %r772, %r767;
	xor.b32  	%r774, %r773, %r767;
	xor.b32  	%r775, %r774, %r760;
	add.s32 	%r776, %r437, %r754;
	add.s32 	%r777, %r776, %r775;
	add.s32 	%r778, %r777, -640364487;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r778, 4;
	shr.b32 	%rhs, %r778, 28;
	add.u32 	%r779, %lhs, %rhs;
	}
	add.s32 	%r780, %r779, %r773;
	xor.b32  	%r781, %r780, %r774;
	add.s32 	%r782, %r444, %r760;
	add.s32 	%r783, %r782, %r781;
	add.s32 	%r784, %r783, -421815835;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r784, 11;
	shr.b32 	%rhs, %r784, 21;
	add.u32 	%r785, %lhs, %rhs;
	}
	add.s32 	%r786, %r785, %r780;
	xor.b32  	%r787, %r786, %r780;
	xor.b32  	%r788, %r787, %r773;
	add.s32 	%r789, %r447, %r767;
	add.s32 	%r790, %r789, %r788;
	add.s32 	%r791, %r790, 530742520;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r791, 16;
	shr.b32 	%rhs, %r791, 16;
	add.u32 	%r792, %lhs, %rhs;
	}
	add.s32 	%r793, %r792, %r786;
	xor.b32  	%r794, %r793, %r787;
	add.s32 	%r795, %r421, %r773;
	add.s32 	%r796, %r795, %r794;
	add.s32 	%r797, %r796, -995338651;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r797, 23;
	shr.b32 	%rhs, %r797, 9;
	add.u32 	%r798, %lhs, %rhs;
	}
	add.s32 	%r799, %r798, %r793;
	not.b32 	%r800, %r786;
	or.b32  	%r801, %r799, %r800;
	xor.b32  	%r802, %r801, %r793;
	add.s32 	%r803, %r417, %r780;
	add.s32 	%r804, %r803, %r802;
	add.s32 	%r805, %r804, -198630844;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r805, 6;
	shr.b32 	%rhs, %r805, 26;
	add.u32 	%r806, %lhs, %rhs;
	}
	add.s32 	%r807, %r806, %r799;
	not.b32 	%r808, %r793;
	or.b32  	%r809, %r807, %r808;
	xor.b32  	%r810, %r809, %r799;
	add.s32 	%r811, %r432, %r786;
	add.s32 	%r812, %r811, %r810;
	add.s32 	%r813, %r812, 1126891415;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r813, 10;
	shr.b32 	%rhs, %r813, 22;
	add.u32 	%r814, %lhs, %rhs;
	}
	add.s32 	%r815, %r814, %r807;
	not.b32 	%r816, %r799;
	or.b32  	%r817, %r815, %r816;
	xor.b32  	%r818, %r817, %r807;
	add.s32 	%r819, %r448, %r793;
	add.s32 	%r820, %r819, %r818;
	add.s32 	%r821, %r820, -1416354905;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r821, 15;
	shr.b32 	%rhs, %r821, 17;
	add.u32 	%r822, %lhs, %rhs;
	}
	add.s32 	%r823, %r822, %r815;
	not.b32 	%r824, %r807;
	or.b32  	%r825, %r823, %r824;
	xor.b32  	%r826, %r825, %r815;
	add.s32 	%r827, %r428, %r799;
	add.s32 	%r828, %r827, %r826;
	add.s32 	%r829, %r828, -57434055;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r829, 21;
	shr.b32 	%rhs, %r829, 11;
	add.u32 	%r830, %lhs, %rhs;
	}
	add.s32 	%r831, %r830, %r823;
	not.b32 	%r832, %r815;
	or.b32  	%r833, %r831, %r832;
	xor.b32  	%r834, %r833, %r823;
	add.s32 	%r835, %r444, %r807;
	add.s32 	%r836, %r835, %r834;
	add.s32 	%r837, %r836, 1700485571;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r837, 6;
	shr.b32 	%rhs, %r837, 26;
	add.u32 	%r838, %lhs, %rhs;
	}
	add.s32 	%r839, %r838, %r831;
	not.b32 	%r840, %r823;
	or.b32  	%r841, %r839, %r840;
	xor.b32  	%r842, %r841, %r831;
	add.s32 	%r843, %r423, %r815;
	add.s32 	%r844, %r843, %r842;
	add.s32 	%r845, %r844, -1894986606;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r845, 10;
	shr.b32 	%rhs, %r845, 22;
	add.u32 	%r846, %lhs, %rhs;
	}
	add.s32 	%r847, %r846, %r839;
	not.b32 	%r848, %r831;
	or.b32  	%r849, %r847, %r848;
	xor.b32  	%r850, %r849, %r839;
	add.s32 	%r851, %r439, %r823;
	add.s32 	%r852, %r851, %r850;
	add.s32 	%r853, %r852, -1051523;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r853, 15;
	shr.b32 	%rhs, %r853, 17;
	add.u32 	%r854, %lhs, %rhs;
	}
	add.s32 	%r855, %r854, %r847;
	not.b32 	%r856, %r839;
	or.b32  	%r857, %r855, %r856;
	xor.b32  	%r858, %r857, %r847;
	add.s32 	%r859, %r419, %r831;
	add.s32 	%r860, %r859, %r858;
	add.s32 	%r861, %r860, -2054922799;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r861, 21;
	shr.b32 	%rhs, %r861, 11;
	add.u32 	%r862, %lhs, %rhs;
	}
	add.s32 	%r863, %r862, %r855;
	not.b32 	%r864, %r847;
	or.b32  	%r865, %r863, %r864;
	xor.b32  	%r866, %r865, %r855;
	add.s32 	%r867, %r435, %r839;
	add.s32 	%r868, %r867, %r866;
	add.s32 	%r869, %r868, 1873313359;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r869, 6;
	shr.b32 	%rhs, %r869, 26;
	add.u32 	%r870, %lhs, %rhs;
	}
	add.s32 	%r871, %r870, %r863;
	not.b32 	%r872, %r855;
	or.b32  	%r873, %r871, %r872;
	xor.b32  	%r874, %r873, %r863;
	add.s32 	%r875, %r447, %r847;
	add.s32 	%r876, %r875, %r874;
	add.s32 	%r877, %r876, -30611744;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r877, 10;
	shr.b32 	%rhs, %r877, 22;
	add.u32 	%r878, %lhs, %rhs;
	}
	add.s32 	%r879, %r878, %r871;
	not.b32 	%r880, %r863;
	or.b32  	%r881, %r879, %r880;
	xor.b32  	%r882, %r881, %r871;
	add.s32 	%r883, %r430, %r855;
	add.s32 	%r884, %r883, %r882;
	add.s32 	%r885, %r884, -1560198380;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r885, 15;
	shr.b32 	%rhs, %r885, 17;
	add.u32 	%r886, %lhs, %rhs;
	}
	add.s32 	%r887, %r886, %r879;
	not.b32 	%r888, %r871;
	or.b32  	%r889, %r887, %r888;
	xor.b32  	%r890, %r889, %r879;
	add.s32 	%r891, %r446, %r863;
	add.s32 	%r892, %r891, %r890;
	add.s32 	%r893, %r892, 1309151649;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r893, 21;
	shr.b32 	%rhs, %r893, 11;
	add.u32 	%r894, %lhs, %rhs;
	}
	add.s32 	%r895, %r894, %r887;
	not.b32 	%r896, %r879;
	or.b32  	%r897, %r895, %r896;
	xor.b32  	%r898, %r897, %r887;
	add.s32 	%r899, %r426, %r871;
	add.s32 	%r900, %r899, %r898;
	add.s32 	%r901, %r900, -145523070;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r901, 6;
	shr.b32 	%rhs, %r901, 26;
	add.u32 	%r902, %lhs, %rhs;
	}
	add.s32 	%r903, %r902, %r895;
	not.b32 	%r904, %r887;
	or.b32  	%r905, %r903, %r904;
	xor.b32  	%r906, %r905, %r895;
	add.s32 	%r907, %r441, %r879;
	add.s32 	%r908, %r907, %r906;
	add.s32 	%r909, %r908, -1120210379;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r909, 10;
	shr.b32 	%rhs, %r909, 22;
	add.u32 	%r910, %lhs, %rhs;
	}
	add.s32 	%r911, %r910, %r903;
	not.b32 	%r912, %r895;
	or.b32  	%r913, %r911, %r912;
	xor.b32  	%r914, %r913, %r903;
	add.s32 	%r915, %r421, %r887;
	add.s32 	%r916, %r915, %r914;
	add.s32 	%r917, %r916, 718787259;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r917, 15;
	shr.b32 	%rhs, %r917, 17;
	add.u32 	%r918, %lhs, %rhs;
	}
	add.s32 	%r919, %r918, %r911;
	not.b32 	%r920, %r903;
	or.b32  	%r921, %r919, %r920;
	xor.b32  	%r922, %r921, %r911;
	add.s32 	%r923, %r437, %r895;
	add.s32 	%r924, %r923, %r922;
	add.s32 	%r925, %r924, -343485551;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r925, 21;
	shr.b32 	%rhs, %r925, 11;
	add.u32 	%r926, %lhs, %rhs;
	}
	add.s32 	%r1713, %r903, 1732584193;
	add.s32 	%r927, %r919, %r926;
	add.s32 	%r1712, %r927, -271733879;
	add.s32 	%r1711, %r919, -1732584194;
	add.s32 	%r1710, %r911, 271733878;
	mov.u32 	%r1756, 0;
	setp.gt.s32	%p38, %r1728, 7;
	@%p38 bra 	BB3_73;

	setp.gt.s32	%p50, %r1728, 3;
	@%p50 bra 	BB3_66;

	setp.gt.s32	%p56, %r1728, 1;
	@%p56 bra 	BB3_63;

	setp.eq.s32	%p59, %r1728, 0;
	@%p59 bra 	BB3_95;
	bra.uni 	BB3_61;

BB3_95:
	mov.u32 	%r1699, 2371876;
	bra.uni 	BB3_96;

BB3_73:
	setp.gt.s32	%p39, %r1728, 11;
	@%p39 bra 	BB3_81;

	setp.gt.s32	%p45, %r1728, 9;
	@%p45 bra 	BB3_78;

	setp.eq.s32	%p48, %r1728, 8;
	@%p48 bra 	BB3_91;
	bra.uni 	BB3_76;

BB3_91:
	mov.u32 	%r1697, 2371876;
	bra.uni 	BB3_96;

BB3_66:
	setp.gt.s32	%p51, %r1728, 5;
	@%p51 bra 	BB3_70;

	setp.eq.s32	%p54, %r1728, 4;
	@%p54 bra 	BB3_93;
	bra.uni 	BB3_68;

BB3_93:
	mov.u32 	%r1698, 2371876;
	bra.uni 	BB3_96;

BB3_81:
	setp.gt.s32	%p40, %r1728, 13;
	@%p40 bra 	BB3_85;

	setp.eq.s32	%p43, %r1728, 12;
	@%p43 bra 	BB3_89;
	bra.uni 	BB3_83;

BB3_89:
	mov.u32 	%r1696, 2371876;
	bra.uni 	BB3_96;

BB3_63:
	setp.eq.s32	%p57, %r1728, 2;
	@%p57 bra 	BB3_94;
	bra.uni 	BB3_64;

BB3_94:
	or.b32  	%r1699, %r1699, 824442880;
	mov.u32 	%r1698, 36;
	bra.uni 	BB3_96;

BB3_78:
	setp.eq.s32	%p46, %r1728, 10;
	@%p46 bra 	BB3_90;
	bra.uni 	BB3_79;

BB3_90:
	or.b32  	%r1697, %r1697, 824442880;
	mov.u32 	%r1696, 36;
	bra.uni 	BB3_96;

BB3_70:
	setp.eq.s32	%p52, %r1728, 6;
	@%p52 bra 	BB3_92;
	bra.uni 	BB3_71;

BB3_92:
	or.b32  	%r1698, %r1698, 824442880;
	mov.u32 	%r1697, 36;
	bra.uni 	BB3_96;

BB3_85:
	setp.eq.s32	%p41, %r1728, 14;
	@%p41 bra 	BB3_88;
	bra.uni 	BB3_86;

BB3_88:
	or.b32  	%r1696, %r1696, 824442880;
	mov.u32 	%r1695, 36;
	bra.uni 	BB3_97;

BB3_61:
	setp.eq.s32	%p60, %r1728, 1;
	@%p60 bra 	BB3_62;
	bra.uni 	BB3_96;

BB3_62:
	or.b32  	%r1699, %r1699, 607200256;
	mov.u32 	%r1698, 0;
	mov.u32 	%r1695, %r1698;
	bra.uni 	BB3_97;

BB3_76:
	setp.eq.s32	%p49, %r1728, 9;
	@%p49 bra 	BB3_77;
	bra.uni 	BB3_96;

BB3_77:
	or.b32  	%r1697, %r1697, 607200256;
	mov.u32 	%r1696, 0;
	mov.u32 	%r1695, %r1696;
	bra.uni 	BB3_97;

BB3_68:
	setp.eq.s32	%p55, %r1728, 5;
	@%p55 bra 	BB3_69;
	bra.uni 	BB3_96;

BB3_69:
	or.b32  	%r1698, %r1698, 607200256;
	mov.u32 	%r1697, 0;
	mov.u32 	%r1695, %r1697;
	bra.uni 	BB3_97;

BB3_83:
	setp.eq.s32	%p44, %r1728, 13;
	@%p44 bra 	BB3_84;
	bra.uni 	BB3_96;

BB3_84:
	or.b32  	%r1696, %r1696, 607200256;
	bra.uni 	BB3_96;

BB3_64:
	setp.eq.s32	%p58, %r1728, 3;
	@%p58 bra 	BB3_65;
	bra.uni 	BB3_96;

BB3_65:
	or.b32  	%r1699, %r1699, 603979776;
	mov.u32 	%r1698, 9265;
	bra.uni 	BB3_96;

BB3_79:
	setp.eq.s32	%p47, %r1728, 11;
	@%p47 bra 	BB3_80;
	bra.uni 	BB3_96;

BB3_80:
	or.b32  	%r1697, %r1697, 603979776;
	mov.u32 	%r1696, 9265;
	bra.uni 	BB3_96;

BB3_71:
	setp.eq.s32	%p53, %r1728, 7;
	@%p53 bra 	BB3_72;
	bra.uni 	BB3_96;

BB3_72:
	or.b32  	%r1698, %r1698, 603979776;
	mov.u32 	%r1697, 9265;
	bra.uni 	BB3_96;

BB3_86:
	setp.ne.s32	%p42, %r1728, 15;
	@%p42 bra 	BB3_96;

	or.b32  	%r1696, %r1696, 603979776;
	mov.u32 	%r1695, 9265;
	bra.uni 	BB3_97;

BB3_96:
	mov.u32 	%r1695, %r1756;

BB3_97:
	mov.u32 	%r1653, 1985229328;
	mov.u32 	%r1652, 4;
	add.s32 	%r979, %r6, 3;
	and.b32  	%r980, %r979, 3;
	sub.s32 	%r982, %r1652, %r980;
	shl.b32 	%r983, %r982, 2;
	shr.u32 	%r985, %r1653, %r983;
	and.b32  	%r968, %r985, 65535;
	// inline asm
	prmt.b32 %r1707, %r1756, %r8, %r968;
	// inline asm
	// inline asm
	prmt.b32 %r1709, %r8, %r9, %r968;
	// inline asm
	// inline asm
	prmt.b32 %r965, %r9, %r1756, %r968;
	// inline asm
	add.s32 	%r86, %r1728, 3;
	shr.u32 	%r978, %r86, 2;
	setp.gt.s32	%p61, %r978, 5;
	@%p61 bra 	BB3_107;

	setp.gt.s32	%p69, %r978, 2;
	@%p69 bra 	BB3_103;

	setp.eq.s32	%p73, %r978, 0;
	@%p73 bra 	BB3_123;

	setp.eq.s32	%p74, %r978, 1;
	@%p74 bra 	BB3_122;
	bra.uni 	BB3_101;

BB3_122:
	or.b32  	%r1698, %r1707, %r1698;
	mov.u32 	%r1696, %r965;
	mov.u32 	%r1697, %r1709;
	bra.uni 	BB3_124;

BB3_107:
	setp.gt.s32	%p62, %r978, 8;
	@%p62 bra 	BB3_112;

	setp.eq.s32	%p66, %r978, 6;
	@%p66 bra 	BB3_119;

	setp.eq.s32	%p67, %r978, 7;
	@%p67 bra 	BB3_118;
	bra.uni 	BB3_110;

BB3_118:
	mov.u32 	%r1700, %r1707;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r1756;
	mov.u32 	%r1705, %r1756;
	mov.u32 	%r1706, %r965;
	mov.u32 	%r1707, %r1709;
	bra.uni 	BB3_127;

BB3_103:
	setp.eq.s32	%p70, %r978, 3;
	@%p70 bra 	BB3_121;

	setp.eq.s32	%p71, %r978, 4;
	@%p71 bra 	BB3_120;
	bra.uni 	BB3_105;

BB3_120:
	or.b32  	%r1695, %r1707, %r1695;
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r965;
	mov.u32 	%r1702, %r1709;
	bra.uni 	BB3_125;

BB3_112:
	setp.eq.s32	%p63, %r978, 9;
	@%p63 bra 	BB3_117;

	setp.eq.s32	%p64, %r978, 10;
	@%p64 bra 	BB3_116;
	bra.uni 	BB3_114;

BB3_116:
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r1709;
	mov.u32 	%r1705, %r1707;
	mov.u32 	%r1706, %r1756;
	mov.u32 	%r1707, %r1756;
	mov.u32 	%r1709, %r965;
	bra.uni 	BB3_128;

BB3_123:
	or.b32  	%r1699, %r1707, %r1699;
	mov.u32 	%r1697, %r965;
	mov.u32 	%r1698, %r1709;
	bra.uni 	BB3_124;

BB3_101:
	setp.eq.s32	%p75, %r978, 2;
	@%p75 bra 	BB3_102;
	bra.uni 	BB3_124;

BB3_102:
	or.b32  	%r1697, %r1707, %r1697;
	mov.u32 	%r1696, %r1709;
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1695, %r965;
	bra.uni 	BB3_125;

BB3_119:
	mov.u32 	%r1700, %r1709;
	mov.u32 	%r1701, %r1707;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r1756;
	mov.u32 	%r1705, %r1756;
	mov.u32 	%r1706, %r1756;
	mov.u32 	%r1707, %r965;
	bra.uni 	BB3_127;

BB3_110:
	setp.eq.s32	%p68, %r978, 8;
	@%p68 bra 	BB3_111;
	bra.uni 	BB3_124;

BB3_111:
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r1756;
	mov.u32 	%r1705, %r965;
	mov.u32 	%r1706, %r1709;
	bra.uni 	BB3_127;

BB3_121:
	or.b32  	%r1696, %r1707, %r1696;
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r965;
	mov.u32 	%r1695, %r1709;
	bra.uni 	BB3_125;

BB3_105:
	setp.eq.s32	%p72, %r978, 5;
	@%p72 bra 	BB3_106;
	bra.uni 	BB3_124;

BB3_106:
	mov.u32 	%r1700, %r965;
	mov.u32 	%r1701, %r1709;
	mov.u32 	%r1702, %r1707;
	bra.uni 	BB3_125;

BB3_117:
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r965;
	mov.u32 	%r1705, %r1709;
	mov.u32 	%r1706, %r1707;
	bra.uni 	BB3_126;

BB3_114:
	setp.ne.s32	%p65, %r978, 11;
	@%p65 bra 	BB3_124;

	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;
	mov.u32 	%r1704, %r1707;
	mov.u32 	%r1705, %r1756;
	mov.u32 	%r1706, %r1756;
	mov.u32 	%r1707, %r1756;
	mov.u32 	%r1756, %r965;
	bra.uni 	BB3_128;

BB3_124:
	mov.u32 	%r1700, %r1756;
	mov.u32 	%r1701, %r1756;
	mov.u32 	%r1702, %r1756;

BB3_125:
	mov.u32 	%r1704, %r1756;
	mov.u32 	%r1705, %r1756;
	mov.u32 	%r1706, %r1756;

BB3_126:
	mov.u32 	%r1707, %r1756;

BB3_127:
	mov.u32 	%r1709, %r1756;

BB3_128:
	setp.gt.s32	%p202, %r1728, 7;
	add.s32 	%r106, %r10, %r86;
	@%p202 bra 	BB3_144;

	setp.gt.s32	%p88, %r1728, 3;
	@%p88 bra 	BB3_137;

	setp.gt.s32	%p94, %r1728, 1;
	@%p94 bra 	BB3_134;

	setp.eq.s32	%p97, %r1728, 0;
	@%p97 bra 	BB3_166;
	bra.uni 	BB3_132;

BB3_166:
	mov.u32 	%r1710, 0;
	mov.u32 	%r1711, %r1710;
	mov.u32 	%r1712, %r1710;
	mov.u32 	%r1713, %r1710;
	bra.uni 	BB3_167;

BB3_144:
	setp.gt.s32	%p77, %r1728, 11;
	@%p77 bra 	BB3_152;

	setp.gt.s32	%p83, %r1728, 9;
	@%p83 bra 	BB3_149;

	setp.eq.s32	%p86, %r1728, 8;
	@%p86 bra 	BB3_163;

	setp.eq.s32	%p87, %r1728, 9;
	@%p87 bra 	BB3_148;
	bra.uni 	BB3_167;

BB3_148:
	and.b32  	%r1711, %r1711, 255;
	mov.u32 	%r1710, 0;
	bra.uni 	BB3_167;

BB3_137:
	setp.gt.s32	%p89, %r1728, 5;
	@%p89 bra 	BB3_141;

	setp.eq.s32	%p92, %r1728, 4;
	@%p92 bra 	BB3_165;

	setp.eq.s32	%p93, %r1728, 5;
	@%p93 bra 	BB3_140;
	bra.uni 	BB3_167;

BB3_140:
	and.b32  	%r1712, %r1712, 255;
	bra.uni 	BB3_163;

BB3_152:
	setp.gt.s32	%p78, %r1728, 13;
	@%p78 bra 	BB3_156;

	setp.eq.s32	%p81, %r1728, 12;
	@%p81 bra 	BB3_160;
	bra.uni 	BB3_154;

BB3_160:
	mov.u32 	%r1710, 0;
	bra.uni 	BB3_167;

BB3_134:
	setp.eq.s32	%p95, %r1728, 2;
	@%p95 bra 	BB3_164;
	bra.uni 	BB3_135;

BB3_164:
	and.b32  	%r1713, %r1713, 65535;
	bra.uni 	BB3_165;

BB3_149:
	setp.eq.s32	%p84, %r1728, 10;
	@%p84 bra 	BB3_161;
	bra.uni 	BB3_150;

BB3_161:
	and.b32  	%r1711, %r1711, 65535;
	mov.u32 	%r1710, 0;
	bra.uni 	BB3_167;

BB3_141:
	setp.eq.s32	%p90, %r1728, 6;
	@%p90 bra 	BB3_162;
	bra.uni 	BB3_142;

BB3_162:
	and.b32  	%r1712, %r1712, 65535;
	bra.uni 	BB3_163;

BB3_156:
	setp.eq.s32	%p79, %r1728, 14;
	@%p79 bra 	BB3_159;
	bra.uni 	BB3_157;

BB3_159:
	and.b32  	%r1710, %r1710, 65535;
	bra.uni 	BB3_167;

BB3_132:
	setp.eq.s32	%p98, %r1728, 1;
	@%p98 bra 	BB3_133;
	bra.uni 	BB3_167;

BB3_133:
	and.b32  	%r1713, %r1713, 255;
	bra.uni 	BB3_165;

BB3_154:
	setp.eq.s32	%p82, %r1728, 13;
	@%p82 bra 	BB3_155;
	bra.uni 	BB3_167;

BB3_155:
	and.b32  	%r1710, %r1710, 255;
	bra.uni 	BB3_167;

BB3_135:
	setp.eq.s32	%p96, %r1728, 3;
	@%p96 bra 	BB3_136;
	bra.uni 	BB3_167;

BB3_136:
	and.b32  	%r1713, %r1713, 16777215;

BB3_165:
	mov.u32 	%r1710, 0;
	mov.u32 	%r1711, %r1710;
	mov.u32 	%r1712, %r1710;
	bra.uni 	BB3_167;

BB3_150:
	setp.eq.s32	%p85, %r1728, 11;
	@%p85 bra 	BB3_151;
	bra.uni 	BB3_167;

BB3_151:
	and.b32  	%r1711, %r1711, 16777215;
	mov.u32 	%r1710, 0;
	bra.uni 	BB3_167;

BB3_142:
	setp.eq.s32	%p91, %r1728, 7;
	@%p91 bra 	BB3_143;
	bra.uni 	BB3_167;

BB3_143:
	and.b32  	%r1712, %r1712, 16777215;

BB3_163:
	mov.u32 	%r1710, 0;
	mov.u32 	%r1711, %r1710;

BB3_167:
	mov.u32 	%r1655, 1985229328;
	mov.u32 	%r1654, 4;
	and.b32  	%r1119, %r106, 3;
	sub.s32 	%r1121, %r1654, %r1119;
	shl.b32 	%r1122, %r1121, 2;
	shr.u32 	%r1124, %r1655, %r1122;
	and.b32  	%r1117, %r1124, 65535;
	mov.u32 	%r1116, 0;
	// inline asm
	prmt.b32 %r1098, %r1116, %r1713, %r1117;
	// inline asm
	// inline asm
	prmt.b32 %r1102, %r1713, %r1712, %r1117;
	// inline asm
	// inline asm
	prmt.b32 %r1106, %r1712, %r1711, %r1117;
	// inline asm
	// inline asm
	prmt.b32 %r1727, %r1711, %r1710, %r1117;
	// inline asm
	// inline asm
	prmt.b32 %r1114, %r1710, %r1116, %r1117;
	// inline asm
	shr.u32 	%r1118, %r106, 2;
	setp.gt.s32	%p99, %r1118, 4;
	@%p99 bra 	BB3_176;

	setp.gt.s32	%p106, %r1118, 1;
	@%p106 bra 	BB3_172;

	setp.eq.s32	%p110, %r1118, 0;
	@%p110 bra 	BB3_189;
	bra.uni 	BB3_170;

BB3_189:
	or.b32  	%r1699, %r1098, %r1699;
	mov.u32 	%r1696, %r1727;
	mov.u32 	%r1697, %r1106;
	mov.u32 	%r1698, %r1102;
	mov.u32 	%r1695, %r1114;
	bra.uni 	BB3_190;

BB3_176:
	setp.gt.s32	%p100, %r1118, 6;
	@%p100 bra 	BB3_180;

	setp.eq.s32	%p104, %r1118, 5;
	@%p104 bra 	BB3_186;
	bra.uni 	BB3_178;

BB3_186:
	or.b32  	%r1702, %r1098, %r1702;
	mov.u32 	%r1700, %r1106;
	mov.u32 	%r1701, %r1102;
	mov.u32 	%r1706, %r1114;
	mov.u32 	%r1707, %r1727;
	bra.uni 	BB3_190;

BB3_172:
	setp.eq.s32	%p107, %r1118, 2;
	@%p107 bra 	BB3_188;

	setp.eq.s32	%p108, %r1118, 3;
	@%p108 bra 	BB3_187;
	bra.uni 	BB3_174;

BB3_187:
	or.b32  	%r1696, %r1098, %r1696;
	mov.u32 	%r1700, %r1114;
	mov.u32 	%r1701, %r1727;
	mov.u32 	%r1702, %r1106;
	mov.u32 	%r1695, %r1102;
	bra.uni 	BB3_190;

BB3_180:
	setp.eq.s32	%p101, %r1118, 7;
	@%p101 bra 	BB3_185;

	setp.eq.s32	%p102, %r1118, 8;
	@%p102 bra 	BB3_184;
	bra.uni 	BB3_182;

BB3_184:
	or.b32  	%r1707, %r1098, %r1707;
	mov.u32 	%r1704, %r1727;
	mov.u32 	%r1705, %r1106;
	mov.u32 	%r1706, %r1102;
	mov.u32 	%r1727, %r1114;
	bra.uni 	BB3_191;

BB3_170:
	setp.eq.s32	%p111, %r1118, 1;
	@%p111 bra 	BB3_171;
	bra.uni 	BB3_190;

BB3_171:
	or.b32  	%r1698, %r1098, %r1698;
	mov.u32 	%r1696, %r1106;
	mov.u32 	%r1697, %r1102;
	mov.u32 	%r1702, %r1114;
	mov.u32 	%r1695, %r1727;
	bra.uni 	BB3_190;

BB3_178:
	setp.eq.s32	%p105, %r1118, 6;
	@%p105 bra 	BB3_179;
	bra.uni 	BB3_190;

BB3_179:
	or.b32  	%r1701, %r1098, %r1701;
	mov.u32 	%r1700, %r1102;
	mov.u32 	%r1705, %r1114;
	mov.u32 	%r1706, %r1727;
	mov.u32 	%r1707, %r1106;
	bra.uni 	BB3_190;

BB3_188:
	or.b32  	%r1697, %r1098, %r1697;
	mov.u32 	%r1696, %r1102;
	mov.u32 	%r1701, %r1114;
	mov.u32 	%r1702, %r1727;
	mov.u32 	%r1695, %r1106;
	bra.uni 	BB3_190;

BB3_174:
	setp.eq.s32	%p109, %r1118, 4;
	@%p109 bra 	BB3_175;
	bra.uni 	BB3_190;

BB3_175:
	or.b32  	%r1695, %r1098, %r1695;
	mov.u32 	%r1700, %r1727;
	mov.u32 	%r1701, %r1106;
	mov.u32 	%r1702, %r1102;
	mov.u32 	%r1707, %r1114;
	bra.uni 	BB3_190;

BB3_185:
	or.b32  	%r1700, %r1098, %r1700;
	mov.u32 	%r1704, %r1114;
	mov.u32 	%r1705, %r1727;
	mov.u32 	%r1706, %r1106;
	mov.u32 	%r1707, %r1102;
	bra.uni 	BB3_190;

BB3_182:
	setp.ne.s32	%p103, %r1118, 9;
	@%p103 bra 	BB3_190;

	or.b32  	%r1706, %r1098, %r1706;
	mov.u32 	%r1704, %r1106;
	mov.u32 	%r1705, %r1102;
	mov.u32 	%r1756, %r1114;
	bra.uni 	BB3_191;

BB3_190:
	mov.u32 	%r1727, %r1709;

BB3_191:
	add.s32 	%r1758, %r106, %r1728;
	and.b32  	%r153, %r1699, 255;
	setp.eq.s32	%p112, %r1728, 0;
	@%p112 bra 	BB3_330;

	shl.b32 	%r154, %r153, 8;
	shl.b32 	%r155, %r153, 16;
	shl.b32 	%r156, %r1699, 24;

BB3_193:
	and.b32  	%r1125, %r1728, 1;
	setp.eq.b32	%p113, %r1125, 1;
	@%p113 bra 	BB3_329;

	setp.gt.s32	%p114, %r1758, 27;
	@%p114 bra 	BB3_249;

	setp.gt.s32	%p154, %r1758, 13;
	@%p154 bra 	BB3_223;

	setp.gt.s32	%p174, %r1758, 6;
	@%p174 bra 	BB3_209;

	setp.gt.s32	%p184, %r1758, 2;
	@%p184 bra 	BB3_202;

	setp.eq.s32	%p190, %r1758, 0;
	@%p190 bra 	BB3_328;

	setp.eq.s32	%p191, %r1758, 1;
	@%p191 bra 	BB3_327;
	bra.uni 	BB3_200;

BB3_327:
	or.b32  	%r1699, %r1699, %r154;
	bra.uni 	BB3_329;

BB3_249:
	setp.gt.s32	%p115, %r1758, 41;
	@%p115 bra 	BB3_278;

	setp.gt.s32	%p135, %r1758, 34;
	@%p135 bra 	BB3_264;

	setp.gt.s32	%p145, %r1758, 30;
	@%p145 bra 	BB3_257;

	setp.eq.s32	%p151, %r1758, 28;
	@%p151 bra 	BB3_253;

	setp.eq.s32	%p152, %r1758, 29;
	@%p152 bra 	BB3_315;
	bra.uni 	BB3_255;

BB3_315:
	or.b32  	%r1700, %r1700, %r154;
	bra.uni 	BB3_329;

BB3_223:
	setp.gt.s32	%p155, %r1758, 20;
	@%p155 bra 	BB3_236;

	setp.gt.s32	%p165, %r1758, 16;
	@%p165 bra 	BB3_229;

	setp.eq.s32	%p171, %r1758, 14;
	@%p171 bra 	BB3_322;

	setp.eq.s32	%p172, %r1758, 15;
	@%p172 bra 	BB3_321;
	bra.uni 	BB3_227;

BB3_321:
	or.b32  	%r1696, %r1696, %r156;
	bra.uni 	BB3_329;

BB3_278:
	setp.gt.s32	%p116, %r1758, 48;
	@%p116 bra 	BB3_291;

	setp.gt.s32	%p126, %r1758, 44;
	@%p126 bra 	BB3_284;

	setp.eq.s32	%p132, %r1758, 42;
	@%p132 bra 	BB3_310;

	setp.eq.s32	%p133, %r1758, 43;
	@%p133 bra 	BB3_309;
	bra.uni 	BB3_282;

BB3_309:
	or.b32  	%r1705, %r1705, %r156;
	bra.uni 	BB3_329;

BB3_209:
	setp.gt.s32	%p175, %r1758, 9;
	@%p175 bra 	BB3_215;

	setp.eq.s32	%p181, %r1758, 7;
	@%p181 bra 	BB3_324;

	setp.eq.s32	%p182, %r1758, 8;
	@%p182 bra 	BB3_212;

	setp.eq.s32	%p183, %r1758, 9;
	@%p183 bra 	BB3_214;
	bra.uni 	BB3_329;

BB3_214:
	or.b32  	%r1697, %r1697, %r154;
	bra.uni 	BB3_329;

BB3_264:
	setp.gt.s32	%p136, %r1758, 37;
	@%p136 bra 	BB3_270;

	setp.eq.s32	%p142, %r1758, 35;
	@%p142 bra 	BB3_312;

	setp.eq.s32	%p143, %r1758, 36;
	@%p143 bra 	BB3_267;

	setp.eq.s32	%p144, %r1758, 37;
	@%p144 bra 	BB3_269;
	bra.uni 	BB3_329;

BB3_269:
	or.b32  	%r1706, %r1706, %r154;
	bra.uni 	BB3_329;

BB3_236:
	setp.gt.s32	%p156, %r1758, 23;
	@%p156 bra 	BB3_241;

	setp.eq.s32	%p162, %r1758, 21;
	@%p162 bra 	BB3_318;

	setp.eq.s32	%p163, %r1758, 22;
	@%p163 bra 	BB3_317;
	bra.uni 	BB3_239;

BB3_317:
	or.b32  	%r1702, %r1702, %r155;
	bra.uni 	BB3_329;

BB3_291:
	setp.gt.s32	%p117, %r1758, 51;
	@%p117 bra 	BB3_296;

	setp.eq.s32	%p123, %r1758, 49;
	@%p123 bra 	BB3_306;

	setp.eq.s32	%p124, %r1758, 50;
	@%p124 bra 	BB3_305;
	bra.uni 	BB3_294;

BB3_305:
	or.b32  	%r1727, %r1727, %r155;
	bra.uni 	BB3_329;

BB3_202:
	setp.gt.s32	%p185, %r1758, 4;
	@%p185 bra 	BB3_206;

	setp.eq.s32	%p188, %r1758, 3;
	@%p188 bra 	BB3_326;
	bra.uni 	BB3_204;

BB3_326:
	or.b32  	%r1699, %r1699, %r156;
	bra.uni 	BB3_329;

BB3_257:
	setp.gt.s32	%p146, %r1758, 32;
	@%p146 bra 	BB3_261;

	setp.eq.s32	%p149, %r1758, 31;
	@%p149 bra 	BB3_314;
	bra.uni 	BB3_259;

BB3_314:
	or.b32  	%r1700, %r1700, %r156;
	bra.uni 	BB3_329;

BB3_229:
	setp.gt.s32	%p166, %r1758, 18;
	@%p166 bra 	BB3_233;

	setp.eq.s32	%p169, %r1758, 17;
	@%p169 bra 	BB3_320;
	bra.uni 	BB3_231;

BB3_320:
	or.b32  	%r1695, %r1695, %r154;
	bra.uni 	BB3_329;

BB3_284:
	setp.gt.s32	%p127, %r1758, 46;
	@%p127 bra 	BB3_288;

	setp.eq.s32	%p130, %r1758, 45;
	@%p130 bra 	BB3_308;
	bra.uni 	BB3_286;

BB3_308:
	or.b32  	%r1704, %r1704, %r154;
	bra.uni 	BB3_329;

BB3_215:
	setp.gt.s32	%p176, %r1758, 11;
	@%p176 bra 	BB3_219;

	setp.eq.s32	%p179, %r1758, 10;
	@%p179 bra 	BB3_323;
	bra.uni 	BB3_217;

BB3_323:
	or.b32  	%r1697, %r1697, %r155;
	bra.uni 	BB3_329;

BB3_270:
	setp.gt.s32	%p137, %r1758, 39;
	@%p137 bra 	BB3_274;

	setp.eq.s32	%p140, %r1758, 38;
	@%p140 bra 	BB3_311;
	bra.uni 	BB3_272;

BB3_311:
	or.b32  	%r1706, %r1706, %r155;
	bra.uni 	BB3_329;

BB3_241:
	setp.gt.s32	%p157, %r1758, 25;
	@%p157 bra 	BB3_246;

	setp.eq.s32	%p160, %r1758, 24;
	@%p160 bra 	BB3_243;

	setp.eq.s32	%p161, %r1758, 25;
	@%p161 bra 	BB3_245;
	bra.uni 	BB3_329;

BB3_245:
	or.b32  	%r1701, %r1701, %r154;
	bra.uni 	BB3_329;

BB3_296:
	setp.gt.s32	%p118, %r1758, 53;
	@%p118 bra 	BB3_301;

	setp.eq.s32	%p121, %r1758, 52;
	@%p121 bra 	BB3_298;

	setp.eq.s32	%p122, %r1758, 53;
	@%p122 bra 	BB3_300;
	bra.uni 	BB3_329;

BB3_300:
	or.b32  	%r1756, %r1756, %r154;
	bra.uni 	BB3_329;

BB3_206:
	setp.eq.s32	%p186, %r1758, 5;
	@%p186 bra 	BB3_325;
	bra.uni 	BB3_207;

BB3_325:
	or.b32  	%r1698, %r1698, %r154;
	bra.uni 	BB3_329;

BB3_261:
	setp.eq.s32	%p147, %r1758, 33;
	@%p147 bra 	BB3_313;
	bra.uni 	BB3_262;

BB3_313:
	or.b32  	%r1707, %r1707, %r154;
	bra.uni 	BB3_329;

BB3_233:
	setp.eq.s32	%p167, %r1758, 19;
	@%p167 bra 	BB3_319;
	bra.uni 	BB3_234;

BB3_319:
	or.b32  	%r1695, %r1695, %r156;
	bra.uni 	BB3_329;

BB3_288:
	setp.eq.s32	%p128, %r1758, 47;
	@%p128 bra 	BB3_307;
	bra.uni 	BB3_289;

BB3_307:
	or.b32  	%r1704, %r1704, %r156;
	bra.uni 	BB3_329;

BB3_219:
	setp.eq.s32	%p177, %r1758, 12;
	@%p177 bra 	BB3_220;

	setp.eq.s32	%p178, %r1758, 13;
	@%p178 bra 	BB3_222;
	bra.uni 	BB3_329;

BB3_222:
	or.b32  	%r1696, %r1696, %r154;
	bra.uni 	BB3_329;

BB3_274:
	setp.eq.s32	%p138, %r1758, 40;
	@%p138 bra 	BB3_275;

	setp.eq.s32	%p139, %r1758, 41;
	@%p139 bra 	BB3_277;
	bra.uni 	BB3_329;

BB3_277:
	or.b32  	%r1705, %r1705, %r154;
	bra.uni 	BB3_329;

BB3_246:
	setp.eq.s32	%p158, %r1758, 26;
	@%p158 bra 	BB3_316;
	bra.uni 	BB3_247;

BB3_316:
	or.b32  	%r1701, %r1701, %r155;
	bra.uni 	BB3_329;

BB3_301:
	setp.eq.s32	%p119, %r1758, 54;
	@%p119 bra 	BB3_304;
	bra.uni 	BB3_302;

BB3_304:
	or.b32  	%r1756, %r1756, %r155;
	bra.uni 	BB3_329;

BB3_328:
	mov.u32 	%r1699, %r153;
	bra.uni 	BB3_329;

BB3_200:
	setp.eq.s32	%p192, %r1758, 2;
	@%p192 bra 	BB3_201;
	bra.uni 	BB3_329;

BB3_201:
	or.b32  	%r1699, %r1699, %r155;
	bra.uni 	BB3_329;

BB3_253:
	mov.u32 	%r1700, %r153;
	bra.uni 	BB3_329;

BB3_255:
	setp.eq.s32	%p153, %r1758, 30;
	@%p153 bra 	BB3_256;
	bra.uni 	BB3_329;

BB3_256:
	or.b32  	%r1700, %r1700, %r155;
	bra.uni 	BB3_329;

BB3_322:
	or.b32  	%r1696, %r1696, %r155;
	bra.uni 	BB3_329;

BB3_227:
	setp.eq.s32	%p173, %r1758, 16;
	@%p173 bra 	BB3_228;
	bra.uni 	BB3_329;

BB3_228:
	mov.u32 	%r1695, %r153;
	bra.uni 	BB3_329;

BB3_310:
	or.b32  	%r1705, %r1705, %r155;
	bra.uni 	BB3_329;

BB3_282:
	setp.eq.s32	%p134, %r1758, 44;
	@%p134 bra 	BB3_283;
	bra.uni 	BB3_329;

BB3_283:
	mov.u32 	%r1704, %r153;
	bra.uni 	BB3_329;

BB3_324:
	or.b32  	%r1698, %r1698, %r156;
	bra.uni 	BB3_329;

BB3_212:
	mov.u32 	%r1697, %r153;
	bra.uni 	BB3_329;

BB3_312:
	or.b32  	%r1707, %r1707, %r156;
	bra.uni 	BB3_329;

BB3_267:
	mov.u32 	%r1706, %r153;
	bra.uni 	BB3_329;

BB3_318:
	or.b32  	%r1702, %r1702, %r154;
	bra.uni 	BB3_329;

BB3_239:
	setp.eq.s32	%p164, %r1758, 23;
	@%p164 bra 	BB3_240;
	bra.uni 	BB3_329;

BB3_240:
	or.b32  	%r1702, %r1702, %r156;
	bra.uni 	BB3_329;

BB3_306:
	or.b32  	%r1727, %r1727, %r154;
	bra.uni 	BB3_329;

BB3_294:
	setp.eq.s32	%p125, %r1758, 51;
	@%p125 bra 	BB3_295;
	bra.uni 	BB3_329;

BB3_295:
	or.b32  	%r1727, %r1727, %r156;
	bra.uni 	BB3_329;

BB3_204:
	setp.eq.s32	%p189, %r1758, 4;
	@%p189 bra 	BB3_205;
	bra.uni 	BB3_329;

BB3_205:
	mov.u32 	%r1698, %r153;
	bra.uni 	BB3_329;

BB3_259:
	setp.eq.s32	%p150, %r1758, 32;
	@%p150 bra 	BB3_260;
	bra.uni 	BB3_329;

BB3_260:
	mov.u32 	%r1707, %r153;
	bra.uni 	BB3_329;

BB3_231:
	setp.eq.s32	%p170, %r1758, 18;
	@%p170 bra 	BB3_232;
	bra.uni 	BB3_329;

BB3_232:
	or.b32  	%r1695, %r1695, %r155;
	bra.uni 	BB3_329;

BB3_286:
	setp.eq.s32	%p131, %r1758, 46;
	@%p131 bra 	BB3_287;
	bra.uni 	BB3_329;

BB3_287:
	or.b32  	%r1704, %r1704, %r155;
	bra.uni 	BB3_329;

BB3_217:
	setp.eq.s32	%p180, %r1758, 11;
	@%p180 bra 	BB3_218;
	bra.uni 	BB3_329;

BB3_218:
	or.b32  	%r1697, %r1697, %r156;
	bra.uni 	BB3_329;

BB3_272:
	setp.eq.s32	%p141, %r1758, 39;
	@%p141 bra 	BB3_273;
	bra.uni 	BB3_329;

BB3_273:
	or.b32  	%r1706, %r1706, %r156;
	bra.uni 	BB3_329;

BB3_243:
	mov.u32 	%r1701, %r153;
	bra.uni 	BB3_329;

BB3_298:
	mov.u32 	%r1756, %r153;
	bra.uni 	BB3_329;

BB3_207:
	setp.eq.s32	%p187, %r1758, 6;
	@%p187 bra 	BB3_208;
	bra.uni 	BB3_329;

BB3_208:
	or.b32  	%r1698, %r1698, %r155;
	bra.uni 	BB3_329;

BB3_262:
	setp.eq.s32	%p148, %r1758, 34;
	@%p148 bra 	BB3_263;
	bra.uni 	BB3_329;

BB3_263:
	or.b32  	%r1707, %r1707, %r155;
	bra.uni 	BB3_329;

BB3_234:
	setp.eq.s32	%p168, %r1758, 20;
	@%p168 bra 	BB3_235;
	bra.uni 	BB3_329;

BB3_235:
	mov.u32 	%r1702, %r153;
	bra.uni 	BB3_329;

BB3_289:
	setp.eq.s32	%p129, %r1758, 48;
	@%p129 bra 	BB3_290;
	bra.uni 	BB3_329;

BB3_290:
	mov.u32 	%r1727, %r153;
	bra.uni 	BB3_329;

BB3_220:
	mov.u32 	%r1696, %r153;
	bra.uni 	BB3_329;

BB3_275:
	mov.u32 	%r1705, %r153;
	bra.uni 	BB3_329;

BB3_247:
	setp.eq.s32	%p159, %r1758, 27;
	@%p159 bra 	BB3_248;
	bra.uni 	BB3_329;

BB3_248:
	or.b32  	%r1701, %r1701, %r156;
	bra.uni 	BB3_329;

BB3_302:
	setp.ne.s32	%p120, %r1758, 55;
	@%p120 bra 	BB3_329;

	or.b32  	%r1756, %r1756, %r156;

BB3_329:
	add.s32 	%r1758, %r1758, 1;
	shr.u32 	%r1728, %r1728, 1;
	setp.ne.s32	%p193, %r1728, 0;
	@%p193 bra 	BB3_193;

BB3_330:
	mov.b32	%r1662, %envreg3;
	mov.u32 	%r1661, %ntid.x;
	mov.u32 	%r1660, %ctaid.x;
	mov.u32 	%r1659, %tid.x;
	mad.lo.s32 	%r1658, %r1660, %r1661, %r1662;
	add.s32 	%r1657, %r1658, %r1659;
	ld.param.u64 	%rd12, [m00500_init_param_4];
	mov.u32 	%r1656, 255;
	bfe.u32 	%r1126, %r1758, 2, 2;
	shl.b32 	%r1127, %r1758, 3;
	and.b32  	%r1128, %r1127, 24;
	shl.b32 	%r1130, %r1656, %r1128;
	setp.eq.s32	%p194, %r1126, 0;
	selp.b32	%r1131, %r1130, 0, %p194;
	setp.eq.s32	%p195, %r1126, 1;
	selp.b32	%r1132, %r1130, 0, %p195;
	setp.eq.s32	%p196, %r1126, 2;
	selp.b32	%r1133, %r1130, 0, %p196;
	setp.eq.s32	%p197, %r1126, 3;
	selp.b32	%r1134, %r1130, 0, %p197;
	shr.u32 	%r1135, %r1758, 4;
	setp.eq.s32	%p198, %r1135, 0;
	selp.b32	%r1136, -2139062144, 0, %p198;
	and.b32  	%r1137, %r1131, %r1136;
	or.b32  	%r1138, %r1137, %r1699;
	and.b32  	%r1139, %r1132, %r1136;
	or.b32  	%r1140, %r1139, %r1698;
	and.b32  	%r1141, %r1133, %r1136;
	or.b32  	%r1142, %r1141, %r1697;
	and.b32  	%r1143, %r1134, %r1136;
	or.b32  	%r1144, %r1143, %r1696;
	setp.eq.s32	%p199, %r1135, 1;
	selp.b32	%r1145, -2139062144, 0, %p199;
	and.b32  	%r1146, %r1131, %r1145;
	or.b32  	%r1147, %r1146, %r1695;
	and.b32  	%r1148, %r1132, %r1145;
	or.b32  	%r1149, %r1148, %r1702;
	and.b32  	%r1150, %r1133, %r1145;
	or.b32  	%r1151, %r1150, %r1701;
	and.b32  	%r1152, %r1134, %r1145;
	or.b32  	%r1153, %r1152, %r1700;
	setp.eq.s32	%p200, %r1135, 2;
	selp.b32	%r1154, -2139062144, 0, %p200;
	and.b32  	%r1155, %r1131, %r1154;
	or.b32  	%r1156, %r1155, %r1707;
	and.b32  	%r1157, %r1132, %r1154;
	or.b32  	%r1158, %r1157, %r1706;
	and.b32  	%r1159, %r1133, %r1154;
	or.b32  	%r1160, %r1159, %r1705;
	and.b32  	%r1161, %r1134, %r1154;
	or.b32  	%r1162, %r1161, %r1704;
	setp.eq.s32	%p201, %r1135, 3;
	selp.b32	%r1163, -2139062144, 0, %p201;
	and.b32  	%r1164, %r1131, %r1163;
	or.b32  	%r1165, %r1164, %r1727;
	and.b32  	%r1166, %r1132, %r1163;
	or.b32  	%r1167, %r1166, %r1756;
	and.b32  	%r1168, %r1134, %r1163;
	add.s32 	%r1169, %r1138, -680876937;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1169, 7;
	shr.b32 	%rhs, %r1169, 25;
	add.u32 	%r1170, %lhs, %rhs;
	}
	add.s32 	%r1171, %r1170, -271733879;
	and.b32  	%r1172, %r1171, 2004318071;
	xor.b32  	%r1173, %r1172, -1732584194;
	add.s32 	%r1174, %r1140, %r1173;
	add.s32 	%r1175, %r1174, -117830708;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1175, 12;
	shr.b32 	%rhs, %r1175, 20;
	add.u32 	%r1176, %lhs, %rhs;
	}
	add.s32 	%r1177, %r1176, %r1171;
	xor.b32  	%r1178, %r1171, -271733879;
	and.b32  	%r1179, %r1177, %r1178;
	xor.b32  	%r1180, %r1179, -271733879;
	add.s32 	%r1181, %r1142, %r1180;
	add.s32 	%r1182, %r1181, -1126478375;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1182, 17;
	shr.b32 	%rhs, %r1182, 15;
	add.u32 	%r1183, %lhs, %rhs;
	}
	add.s32 	%r1184, %r1183, %r1177;
	xor.b32  	%r1185, %r1177, %r1171;
	and.b32  	%r1186, %r1184, %r1185;
	xor.b32  	%r1187, %r1186, %r1171;
	add.s32 	%r1188, %r1144, %r1187;
	add.s32 	%r1189, %r1188, -1316259209;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1189, 22;
	shr.b32 	%rhs, %r1189, 10;
	add.u32 	%r1190, %lhs, %rhs;
	}
	add.s32 	%r1191, %r1190, %r1184;
	xor.b32  	%r1192, %r1184, %r1177;
	and.b32  	%r1193, %r1191, %r1192;
	xor.b32  	%r1194, %r1193, %r1177;
	add.s32 	%r1195, %r1147, %r1170;
	add.s32 	%r1196, %r1195, %r1194;
	add.s32 	%r1197, %r1196, -448152776;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1197, 7;
	shr.b32 	%rhs, %r1197, 25;
	add.u32 	%r1198, %lhs, %rhs;
	}
	add.s32 	%r1199, %r1198, %r1191;
	xor.b32  	%r1200, %r1191, %r1184;
	and.b32  	%r1201, %r1199, %r1200;
	xor.b32  	%r1202, %r1201, %r1184;
	add.s32 	%r1203, %r1149, %r1177;
	add.s32 	%r1204, %r1203, %r1202;
	add.s32 	%r1205, %r1204, 1200080426;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1205, 12;
	shr.b32 	%rhs, %r1205, 20;
	add.u32 	%r1206, %lhs, %rhs;
	}
	add.s32 	%r1207, %r1206, %r1199;
	xor.b32  	%r1208, %r1199, %r1191;
	and.b32  	%r1209, %r1207, %r1208;
	xor.b32  	%r1210, %r1209, %r1191;
	add.s32 	%r1211, %r1151, %r1184;
	add.s32 	%r1212, %r1211, %r1210;
	add.s32 	%r1213, %r1212, -1473231341;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1213, 17;
	shr.b32 	%rhs, %r1213, 15;
	add.u32 	%r1214, %lhs, %rhs;
	}
	add.s32 	%r1215, %r1214, %r1207;
	xor.b32  	%r1216, %r1207, %r1199;
	and.b32  	%r1217, %r1215, %r1216;
	xor.b32  	%r1218, %r1217, %r1199;
	add.s32 	%r1219, %r1153, %r1191;
	add.s32 	%r1220, %r1219, %r1218;
	add.s32 	%r1221, %r1220, -45705983;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1221, 22;
	shr.b32 	%rhs, %r1221, 10;
	add.u32 	%r1222, %lhs, %rhs;
	}
	add.s32 	%r1223, %r1222, %r1215;
	xor.b32  	%r1224, %r1215, %r1207;
	and.b32  	%r1225, %r1223, %r1224;
	xor.b32  	%r1226, %r1225, %r1207;
	add.s32 	%r1227, %r1156, %r1199;
	add.s32 	%r1228, %r1227, %r1226;
	add.s32 	%r1229, %r1228, 1770035416;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1229, 7;
	shr.b32 	%rhs, %r1229, 25;
	add.u32 	%r1230, %lhs, %rhs;
	}
	add.s32 	%r1231, %r1230, %r1223;
	xor.b32  	%r1232, %r1223, %r1215;
	and.b32  	%r1233, %r1231, %r1232;
	xor.b32  	%r1234, %r1233, %r1215;
	add.s32 	%r1235, %r1158, %r1207;
	add.s32 	%r1236, %r1235, %r1234;
	add.s32 	%r1237, %r1236, -1958414417;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1237, 12;
	shr.b32 	%rhs, %r1237, 20;
	add.u32 	%r1238, %lhs, %rhs;
	}
	add.s32 	%r1239, %r1238, %r1231;
	xor.b32  	%r1240, %r1231, %r1223;
	and.b32  	%r1241, %r1239, %r1240;
	xor.b32  	%r1242, %r1241, %r1223;
	add.s32 	%r1243, %r1160, %r1215;
	add.s32 	%r1244, %r1243, %r1242;
	add.s32 	%r1245, %r1244, -42063;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1245, 17;
	shr.b32 	%rhs, %r1245, 15;
	add.u32 	%r1246, %lhs, %rhs;
	}
	add.s32 	%r1247, %r1246, %r1239;
	xor.b32  	%r1248, %r1239, %r1231;
	and.b32  	%r1249, %r1247, %r1248;
	xor.b32  	%r1250, %r1249, %r1231;
	add.s32 	%r1251, %r1162, %r1223;
	add.s32 	%r1252, %r1251, %r1250;
	add.s32 	%r1253, %r1252, -1990404162;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1253, 22;
	shr.b32 	%rhs, %r1253, 10;
	add.u32 	%r1254, %lhs, %rhs;
	}
	add.s32 	%r1255, %r1254, %r1247;
	xor.b32  	%r1256, %r1247, %r1239;
	and.b32  	%r1257, %r1255, %r1256;
	xor.b32  	%r1258, %r1257, %r1239;
	add.s32 	%r1259, %r1165, %r1231;
	add.s32 	%r1260, %r1259, %r1258;
	add.s32 	%r1261, %r1260, 1804603682;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1261, 7;
	shr.b32 	%rhs, %r1261, 25;
	add.u32 	%r1262, %lhs, %rhs;
	}
	add.s32 	%r1263, %r1262, %r1255;
	xor.b32  	%r1264, %r1255, %r1247;
	and.b32  	%r1265, %r1263, %r1264;
	xor.b32  	%r1266, %r1265, %r1247;
	add.s32 	%r1267, %r1167, %r1239;
	add.s32 	%r1268, %r1267, %r1266;
	add.s32 	%r1269, %r1268, -40341101;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1269, 12;
	shr.b32 	%rhs, %r1269, 20;
	add.u32 	%r1270, %lhs, %rhs;
	}
	add.s32 	%r1271, %r1270, %r1263;
	xor.b32  	%r1272, %r1263, %r1255;
	and.b32  	%r1273, %r1271, %r1272;
	xor.b32  	%r1274, %r1273, %r1255;
	add.s32 	%r1275, %r1127, %r1247;
	add.s32 	%r1276, %r1275, %r1274;
	add.s32 	%r1277, %r1276, -1502002290;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1277, 17;
	shr.b32 	%rhs, %r1277, 15;
	add.u32 	%r1278, %lhs, %rhs;
	}
	add.s32 	%r1279, %r1278, %r1271;
	xor.b32  	%r1280, %r1271, %r1263;
	and.b32  	%r1281, %r1279, %r1280;
	xor.b32  	%r1282, %r1281, %r1263;
	add.s32 	%r1283, %r1168, %r1255;
	add.s32 	%r1284, %r1283, %r1282;
	add.s32 	%r1285, %r1284, 1236535329;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1285, 22;
	shr.b32 	%rhs, %r1285, 10;
	add.u32 	%r1286, %lhs, %rhs;
	}
	add.s32 	%r1287, %r1286, %r1279;
	xor.b32  	%r1288, %r1287, %r1279;
	and.b32  	%r1289, %r1288, %r1271;
	xor.b32  	%r1290, %r1289, %r1279;
	add.s32 	%r1291, %r1140, %r1263;
	add.s32 	%r1292, %r1291, %r1290;
	add.s32 	%r1293, %r1292, -165796510;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1293, 5;
	shr.b32 	%rhs, %r1293, 27;
	add.u32 	%r1294, %lhs, %rhs;
	}
	add.s32 	%r1295, %r1294, %r1287;
	xor.b32  	%r1296, %r1295, %r1287;
	and.b32  	%r1297, %r1296, %r1279;
	xor.b32  	%r1298, %r1297, %r1287;
	add.s32 	%r1299, %r1151, %r1271;
	add.s32 	%r1300, %r1299, %r1298;
	add.s32 	%r1301, %r1300, -1069501632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1301, 9;
	shr.b32 	%rhs, %r1301, 23;
	add.u32 	%r1302, %lhs, %rhs;
	}
	add.s32 	%r1303, %r1302, %r1295;
	xor.b32  	%r1304, %r1303, %r1295;
	and.b32  	%r1305, %r1304, %r1287;
	xor.b32  	%r1306, %r1305, %r1295;
	add.s32 	%r1307, %r1162, %r1279;
	add.s32 	%r1308, %r1307, %r1306;
	add.s32 	%r1309, %r1308, 643717713;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1309, 14;
	shr.b32 	%rhs, %r1309, 18;
	add.u32 	%r1310, %lhs, %rhs;
	}
	add.s32 	%r1311, %r1310, %r1303;
	xor.b32  	%r1312, %r1311, %r1303;
	and.b32  	%r1313, %r1312, %r1295;
	xor.b32  	%r1314, %r1313, %r1303;
	add.s32 	%r1315, %r1138, %r1287;
	add.s32 	%r1316, %r1315, %r1314;
	add.s32 	%r1317, %r1316, -373897302;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1317, 20;
	shr.b32 	%rhs, %r1317, 12;
	add.u32 	%r1318, %lhs, %rhs;
	}
	add.s32 	%r1319, %r1318, %r1311;
	xor.b32  	%r1320, %r1319, %r1311;
	and.b32  	%r1321, %r1320, %r1303;
	xor.b32  	%r1322, %r1321, %r1311;
	add.s32 	%r1323, %r1149, %r1295;
	add.s32 	%r1324, %r1323, %r1322;
	add.s32 	%r1325, %r1324, -701558691;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1325, 5;
	shr.b32 	%rhs, %r1325, 27;
	add.u32 	%r1326, %lhs, %rhs;
	}
	add.s32 	%r1327, %r1326, %r1319;
	xor.b32  	%r1328, %r1327, %r1319;
	and.b32  	%r1329, %r1328, %r1311;
	xor.b32  	%r1330, %r1329, %r1319;
	add.s32 	%r1331, %r1160, %r1303;
	add.s32 	%r1332, %r1331, %r1330;
	add.s32 	%r1333, %r1332, 38016083;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1333, 9;
	shr.b32 	%rhs, %r1333, 23;
	add.u32 	%r1334, %lhs, %rhs;
	}
	add.s32 	%r1335, %r1334, %r1327;
	xor.b32  	%r1336, %r1335, %r1327;
	and.b32  	%r1337, %r1336, %r1319;
	xor.b32  	%r1338, %r1337, %r1327;
	add.s32 	%r1339, %r1168, %r1311;
	add.s32 	%r1340, %r1339, %r1338;
	add.s32 	%r1341, %r1340, -660478335;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1341, 14;
	shr.b32 	%rhs, %r1341, 18;
	add.u32 	%r1342, %lhs, %rhs;
	}
	add.s32 	%r1343, %r1342, %r1335;
	xor.b32  	%r1344, %r1343, %r1335;
	and.b32  	%r1345, %r1344, %r1327;
	xor.b32  	%r1346, %r1345, %r1335;
	add.s32 	%r1347, %r1147, %r1319;
	add.s32 	%r1348, %r1347, %r1346;
	add.s32 	%r1349, %r1348, -405537848;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1349, 20;
	shr.b32 	%rhs, %r1349, 12;
	add.u32 	%r1350, %lhs, %rhs;
	}
	add.s32 	%r1351, %r1350, %r1343;
	xor.b32  	%r1352, %r1351, %r1343;
	and.b32  	%r1353, %r1352, %r1335;
	xor.b32  	%r1354, %r1353, %r1343;
	add.s32 	%r1355, %r1158, %r1327;
	add.s32 	%r1356, %r1355, %r1354;
	add.s32 	%r1357, %r1356, 568446438;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1357, 5;
	shr.b32 	%rhs, %r1357, 27;
	add.u32 	%r1358, %lhs, %rhs;
	}
	add.s32 	%r1359, %r1358, %r1351;
	xor.b32  	%r1360, %r1359, %r1351;
	and.b32  	%r1361, %r1360, %r1343;
	xor.b32  	%r1362, %r1361, %r1351;
	add.s32 	%r1363, %r1127, %r1335;
	add.s32 	%r1364, %r1363, %r1362;
	add.s32 	%r1365, %r1364, -1019803690;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1365, 9;
	shr.b32 	%rhs, %r1365, 23;
	add.u32 	%r1366, %lhs, %rhs;
	}
	add.s32 	%r1367, %r1366, %r1359;
	xor.b32  	%r1368, %r1367, %r1359;
	and.b32  	%r1369, %r1368, %r1351;
	xor.b32  	%r1370, %r1369, %r1359;
	add.s32 	%r1371, %r1144, %r1343;
	add.s32 	%r1372, %r1371, %r1370;
	add.s32 	%r1373, %r1372, -187363961;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1373, 14;
	shr.b32 	%rhs, %r1373, 18;
	add.u32 	%r1374, %lhs, %rhs;
	}
	add.s32 	%r1375, %r1374, %r1367;
	xor.b32  	%r1376, %r1375, %r1367;
	and.b32  	%r1377, %r1376, %r1359;
	xor.b32  	%r1378, %r1377, %r1367;
	add.s32 	%r1379, %r1156, %r1351;
	add.s32 	%r1380, %r1379, %r1378;
	add.s32 	%r1381, %r1380, 1163531501;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1381, 20;
	shr.b32 	%rhs, %r1381, 12;
	add.u32 	%r1382, %lhs, %rhs;
	}
	add.s32 	%r1383, %r1382, %r1375;
	xor.b32  	%r1384, %r1383, %r1375;
	and.b32  	%r1385, %r1384, %r1367;
	xor.b32  	%r1386, %r1385, %r1375;
	add.s32 	%r1387, %r1167, %r1359;
	add.s32 	%r1388, %r1387, %r1386;
	add.s32 	%r1389, %r1388, -1444681467;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1389, 5;
	shr.b32 	%rhs, %r1389, 27;
	add.u32 	%r1390, %lhs, %rhs;
	}
	add.s32 	%r1391, %r1390, %r1383;
	xor.b32  	%r1392, %r1391, %r1383;
	and.b32  	%r1393, %r1392, %r1375;
	xor.b32  	%r1394, %r1393, %r1383;
	add.s32 	%r1395, %r1142, %r1367;
	add.s32 	%r1396, %r1395, %r1394;
	add.s32 	%r1397, %r1396, -51403784;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1397, 9;
	shr.b32 	%rhs, %r1397, 23;
	add.u32 	%r1398, %lhs, %rhs;
	}
	add.s32 	%r1399, %r1398, %r1391;
	xor.b32  	%r1400, %r1399, %r1391;
	and.b32  	%r1401, %r1400, %r1383;
	xor.b32  	%r1402, %r1401, %r1391;
	add.s32 	%r1403, %r1153, %r1375;
	add.s32 	%r1404, %r1403, %r1402;
	add.s32 	%r1405, %r1404, 1735328473;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1405, 14;
	shr.b32 	%rhs, %r1405, 18;
	add.u32 	%r1406, %lhs, %rhs;
	}
	add.s32 	%r1407, %r1406, %r1399;
	xor.b32  	%r1408, %r1407, %r1399;
	and.b32  	%r1409, %r1408, %r1391;
	xor.b32  	%r1410, %r1409, %r1399;
	add.s32 	%r1411, %r1165, %r1383;
	add.s32 	%r1412, %r1411, %r1410;
	add.s32 	%r1413, %r1412, -1926607734;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1413, 20;
	shr.b32 	%rhs, %r1413, 12;
	add.u32 	%r1414, %lhs, %rhs;
	}
	add.s32 	%r1415, %r1414, %r1407;
	xor.b32  	%r1416, %r1415, %r1407;
	xor.b32  	%r1417, %r1416, %r1399;
	add.s32 	%r1418, %r1149, %r1391;
	add.s32 	%r1419, %r1418, %r1417;
	add.s32 	%r1420, %r1419, -378558;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1420, 4;
	shr.b32 	%rhs, %r1420, 28;
	add.u32 	%r1421, %lhs, %rhs;
	}
	add.s32 	%r1422, %r1421, %r1415;
	xor.b32  	%r1423, %r1422, %r1416;
	add.s32 	%r1424, %r1156, %r1399;
	add.s32 	%r1425, %r1424, %r1423;
	add.s32 	%r1426, %r1425, -2022574463;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1426, 11;
	shr.b32 	%rhs, %r1426, 21;
	add.u32 	%r1427, %lhs, %rhs;
	}
	add.s32 	%r1428, %r1427, %r1422;
	xor.b32  	%r1429, %r1428, %r1422;
	xor.b32  	%r1430, %r1429, %r1415;
	add.s32 	%r1431, %r1162, %r1407;
	add.s32 	%r1432, %r1431, %r1430;
	add.s32 	%r1433, %r1432, 1839030562;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1433, 16;
	shr.b32 	%rhs, %r1433, 16;
	add.u32 	%r1434, %lhs, %rhs;
	}
	add.s32 	%r1435, %r1434, %r1428;
	xor.b32  	%r1436, %r1435, %r1429;
	add.s32 	%r1437, %r1127, %r1415;
	add.s32 	%r1438, %r1437, %r1436;
	add.s32 	%r1439, %r1438, -35309556;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1439, 23;
	shr.b32 	%rhs, %r1439, 9;
	add.u32 	%r1440, %lhs, %rhs;
	}
	add.s32 	%r1441, %r1440, %r1435;
	xor.b32  	%r1442, %r1441, %r1435;
	xor.b32  	%r1443, %r1442, %r1428;
	add.s32 	%r1444, %r1140, %r1422;
	add.s32 	%r1445, %r1444, %r1443;
	add.s32 	%r1446, %r1445, -1530992060;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1446, 4;
	shr.b32 	%rhs, %r1446, 28;
	add.u32 	%r1447, %lhs, %rhs;
	}
	add.s32 	%r1448, %r1447, %r1441;
	xor.b32  	%r1449, %r1448, %r1442;
	add.s32 	%r1450, %r1147, %r1428;
	add.s32 	%r1451, %r1450, %r1449;
	add.s32 	%r1452, %r1451, 1272893353;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1452, 11;
	shr.b32 	%rhs, %r1452, 21;
	add.u32 	%r1453, %lhs, %rhs;
	}
	add.s32 	%r1454, %r1453, %r1448;
	xor.b32  	%r1455, %r1454, %r1448;
	xor.b32  	%r1456, %r1455, %r1441;
	add.s32 	%r1457, %r1153, %r1435;
	add.s32 	%r1458, %r1457, %r1456;
	add.s32 	%r1459, %r1458, -155497632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1459, 16;
	shr.b32 	%rhs, %r1459, 16;
	add.u32 	%r1460, %lhs, %rhs;
	}
	add.s32 	%r1461, %r1460, %r1454;
	xor.b32  	%r1462, %r1461, %r1455;
	add.s32 	%r1463, %r1160, %r1441;
	add.s32 	%r1464, %r1463, %r1462;
	add.s32 	%r1465, %r1464, -1094730640;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1465, 23;
	shr.b32 	%rhs, %r1465, 9;
	add.u32 	%r1466, %lhs, %rhs;
	}
	add.s32 	%r1467, %r1466, %r1461;
	xor.b32  	%r1468, %r1467, %r1461;
	xor.b32  	%r1469, %r1468, %r1454;
	add.s32 	%r1470, %r1167, %r1448;
	add.s32 	%r1471, %r1470, %r1469;
	add.s32 	%r1472, %r1471, 681279174;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1472, 4;
	shr.b32 	%rhs, %r1472, 28;
	add.u32 	%r1473, %lhs, %rhs;
	}
	add.s32 	%r1474, %r1473, %r1467;
	xor.b32  	%r1475, %r1474, %r1468;
	add.s32 	%r1476, %r1138, %r1454;
	add.s32 	%r1477, %r1476, %r1475;
	add.s32 	%r1478, %r1477, -358537222;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1478, 11;
	shr.b32 	%rhs, %r1478, 21;
	add.u32 	%r1479, %lhs, %rhs;
	}
	add.s32 	%r1480, %r1479, %r1474;
	xor.b32  	%r1481, %r1480, %r1474;
	xor.b32  	%r1482, %r1481, %r1467;
	add.s32 	%r1483, %r1144, %r1461;
	add.s32 	%r1484, %r1483, %r1482;
	add.s32 	%r1485, %r1484, -722521979;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1485, 16;
	shr.b32 	%rhs, %r1485, 16;
	add.u32 	%r1486, %lhs, %rhs;
	}
	add.s32 	%r1487, %r1486, %r1480;
	xor.b32  	%r1488, %r1487, %r1481;
	add.s32 	%r1489, %r1151, %r1467;
	add.s32 	%r1490, %r1489, %r1488;
	add.s32 	%r1491, %r1490, 76029189;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1491, 23;
	shr.b32 	%rhs, %r1491, 9;
	add.u32 	%r1492, %lhs, %rhs;
	}
	add.s32 	%r1493, %r1492, %r1487;
	xor.b32  	%r1494, %r1493, %r1487;
	xor.b32  	%r1495, %r1494, %r1480;
	add.s32 	%r1496, %r1158, %r1474;
	add.s32 	%r1497, %r1496, %r1495;
	add.s32 	%r1498, %r1497, -640364487;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1498, 4;
	shr.b32 	%rhs, %r1498, 28;
	add.u32 	%r1499, %lhs, %rhs;
	}
	add.s32 	%r1500, %r1499, %r1493;
	xor.b32  	%r1501, %r1500, %r1494;
	add.s32 	%r1502, %r1165, %r1480;
	add.s32 	%r1503, %r1502, %r1501;
	add.s32 	%r1504, %r1503, -421815835;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1504, 11;
	shr.b32 	%rhs, %r1504, 21;
	add.u32 	%r1505, %lhs, %rhs;
	}
	add.s32 	%r1506, %r1505, %r1500;
	xor.b32  	%r1507, %r1506, %r1500;
	xor.b32  	%r1508, %r1507, %r1493;
	add.s32 	%r1509, %r1168, %r1487;
	add.s32 	%r1510, %r1509, %r1508;
	add.s32 	%r1511, %r1510, 530742520;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1511, 16;
	shr.b32 	%rhs, %r1511, 16;
	add.u32 	%r1512, %lhs, %rhs;
	}
	add.s32 	%r1513, %r1512, %r1506;
	xor.b32  	%r1514, %r1513, %r1507;
	add.s32 	%r1515, %r1142, %r1493;
	add.s32 	%r1516, %r1515, %r1514;
	add.s32 	%r1517, %r1516, -995338651;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1517, 23;
	shr.b32 	%rhs, %r1517, 9;
	add.u32 	%r1518, %lhs, %rhs;
	}
	add.s32 	%r1519, %r1518, %r1513;
	not.b32 	%r1520, %r1506;
	or.b32  	%r1521, %r1519, %r1520;
	xor.b32  	%r1522, %r1521, %r1513;
	add.s32 	%r1523, %r1138, %r1500;
	add.s32 	%r1524, %r1523, %r1522;
	add.s32 	%r1525, %r1524, -198630844;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1525, 6;
	shr.b32 	%rhs, %r1525, 26;
	add.u32 	%r1526, %lhs, %rhs;
	}
	add.s32 	%r1527, %r1526, %r1519;
	not.b32 	%r1528, %r1513;
	or.b32  	%r1529, %r1527, %r1528;
	xor.b32  	%r1530, %r1529, %r1519;
	add.s32 	%r1531, %r1153, %r1506;
	add.s32 	%r1532, %r1531, %r1530;
	add.s32 	%r1533, %r1532, 1126891415;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1533, 10;
	shr.b32 	%rhs, %r1533, 22;
	add.u32 	%r1534, %lhs, %rhs;
	}
	add.s32 	%r1535, %r1534, %r1527;
	not.b32 	%r1536, %r1519;
	or.b32  	%r1537, %r1535, %r1536;
	xor.b32  	%r1538, %r1537, %r1527;
	add.s32 	%r1539, %r1127, %r1513;
	add.s32 	%r1540, %r1539, %r1538;
	add.s32 	%r1541, %r1540, -1416354905;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1541, 15;
	shr.b32 	%rhs, %r1541, 17;
	add.u32 	%r1542, %lhs, %rhs;
	}
	add.s32 	%r1543, %r1542, %r1535;
	not.b32 	%r1544, %r1527;
	or.b32  	%r1545, %r1543, %r1544;
	xor.b32  	%r1546, %r1545, %r1535;
	add.s32 	%r1547, %r1149, %r1519;
	add.s32 	%r1548, %r1547, %r1546;
	add.s32 	%r1549, %r1548, -57434055;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1549, 21;
	shr.b32 	%rhs, %r1549, 11;
	add.u32 	%r1550, %lhs, %rhs;
	}
	add.s32 	%r1551, %r1550, %r1543;
	not.b32 	%r1552, %r1535;
	or.b32  	%r1553, %r1551, %r1552;
	xor.b32  	%r1554, %r1553, %r1543;
	add.s32 	%r1555, %r1165, %r1527;
	add.s32 	%r1556, %r1555, %r1554;
	add.s32 	%r1557, %r1556, 1700485571;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1557, 6;
	shr.b32 	%rhs, %r1557, 26;
	add.u32 	%r1558, %lhs, %rhs;
	}
	add.s32 	%r1559, %r1558, %r1551;
	not.b32 	%r1560, %r1543;
	or.b32  	%r1561, %r1559, %r1560;
	xor.b32  	%r1562, %r1561, %r1551;
	add.s32 	%r1563, %r1144, %r1535;
	add.s32 	%r1564, %r1563, %r1562;
	add.s32 	%r1565, %r1564, -1894986606;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1565, 10;
	shr.b32 	%rhs, %r1565, 22;
	add.u32 	%r1566, %lhs, %rhs;
	}
	add.s32 	%r1567, %r1566, %r1559;
	not.b32 	%r1568, %r1551;
	or.b32  	%r1569, %r1567, %r1568;
	xor.b32  	%r1570, %r1569, %r1559;
	add.s32 	%r1571, %r1160, %r1543;
	add.s32 	%r1572, %r1571, %r1570;
	add.s32 	%r1573, %r1572, -1051523;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1573, 15;
	shr.b32 	%rhs, %r1573, 17;
	add.u32 	%r1574, %lhs, %rhs;
	}
	add.s32 	%r1575, %r1574, %r1567;
	not.b32 	%r1576, %r1559;
	or.b32  	%r1577, %r1575, %r1576;
	xor.b32  	%r1578, %r1577, %r1567;
	add.s32 	%r1579, %r1140, %r1551;
	add.s32 	%r1580, %r1579, %r1578;
	add.s32 	%r1581, %r1580, -2054922799;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1581, 21;
	shr.b32 	%rhs, %r1581, 11;
	add.u32 	%r1582, %lhs, %rhs;
	}
	add.s32 	%r1583, %r1582, %r1575;
	not.b32 	%r1584, %r1567;
	or.b32  	%r1585, %r1583, %r1584;
	xor.b32  	%r1586, %r1585, %r1575;
	add.s32 	%r1587, %r1156, %r1559;
	add.s32 	%r1588, %r1587, %r1586;
	add.s32 	%r1589, %r1588, 1873313359;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1589, 6;
	shr.b32 	%rhs, %r1589, 26;
	add.u32 	%r1590, %lhs, %rhs;
	}
	add.s32 	%r1591, %r1590, %r1583;
	not.b32 	%r1592, %r1575;
	or.b32  	%r1593, %r1591, %r1592;
	xor.b32  	%r1594, %r1593, %r1583;
	add.s32 	%r1595, %r1168, %r1567;
	add.s32 	%r1596, %r1595, %r1594;
	add.s32 	%r1597, %r1596, -30611744;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1597, 10;
	shr.b32 	%rhs, %r1597, 22;
	add.u32 	%r1598, %lhs, %rhs;
	}
	add.s32 	%r1599, %r1598, %r1591;
	not.b32 	%r1600, %r1583;
	or.b32  	%r1601, %r1599, %r1600;
	xor.b32  	%r1602, %r1601, %r1591;
	add.s32 	%r1603, %r1151, %r1575;
	add.s32 	%r1604, %r1603, %r1602;
	add.s32 	%r1605, %r1604, -1560198380;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1605, 15;
	shr.b32 	%rhs, %r1605, 17;
	add.u32 	%r1606, %lhs, %rhs;
	}
	add.s32 	%r1607, %r1606, %r1599;
	not.b32 	%r1608, %r1591;
	or.b32  	%r1609, %r1607, %r1608;
	xor.b32  	%r1610, %r1609, %r1599;
	add.s32 	%r1611, %r1167, %r1583;
	add.s32 	%r1612, %r1611, %r1610;
	add.s32 	%r1613, %r1612, 1309151649;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1613, 21;
	shr.b32 	%rhs, %r1613, 11;
	add.u32 	%r1614, %lhs, %rhs;
	}
	add.s32 	%r1615, %r1614, %r1607;
	not.b32 	%r1616, %r1599;
	or.b32  	%r1617, %r1615, %r1616;
	xor.b32  	%r1618, %r1617, %r1607;
	add.s32 	%r1619, %r1147, %r1591;
	add.s32 	%r1620, %r1619, %r1618;
	add.s32 	%r1621, %r1620, -145523070;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1621, 6;
	shr.b32 	%rhs, %r1621, 26;
	add.u32 	%r1622, %lhs, %rhs;
	}
	add.s32 	%r1623, %r1622, %r1615;
	not.b32 	%r1624, %r1607;
	or.b32  	%r1625, %r1623, %r1624;
	xor.b32  	%r1626, %r1625, %r1615;
	add.s32 	%r1627, %r1162, %r1599;
	add.s32 	%r1628, %r1627, %r1626;
	add.s32 	%r1629, %r1628, -1120210379;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1629, 10;
	shr.b32 	%rhs, %r1629, 22;
	add.u32 	%r1630, %lhs, %rhs;
	}
	add.s32 	%r1631, %r1630, %r1623;
	not.b32 	%r1632, %r1615;
	or.b32  	%r1633, %r1631, %r1632;
	xor.b32  	%r1634, %r1633, %r1623;
	add.s32 	%r1635, %r1142, %r1607;
	add.s32 	%r1636, %r1635, %r1634;
	add.s32 	%r1637, %r1636, 718787259;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1637, 15;
	shr.b32 	%rhs, %r1637, 17;
	add.u32 	%r1638, %lhs, %rhs;
	}
	add.s32 	%r1639, %r1638, %r1631;
	not.b32 	%r1640, %r1623;
	or.b32  	%r1641, %r1639, %r1640;
	xor.b32  	%r1642, %r1641, %r1631;
	add.s32 	%r1643, %r1158, %r1615;
	add.s32 	%r1644, %r1643, %r1642;
	add.s32 	%r1645, %r1644, -343485551;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1645, 21;
	shr.b32 	%rhs, %r1645, 11;
	add.u32 	%r1646, %lhs, %rhs;
	}
	add.s32 	%r1647, %r1623, 1732584193;
	add.s32 	%r1648, %r1639, %r1646;
	add.s32 	%r1649, %r1648, -271733879;
	add.s32 	%r1650, %r1639, -1732584194;
	add.s32 	%r1651, %r1631, 271733878;
	mul.wide.s32 	%rd10, %r1657, 16;
	add.s64 	%rd11, %rd12, %rd10;
	st.global.u32 	[%rd11], %r1647;
	st.global.u32 	[%rd11+4], %r1649;
	st.global.u32 	[%rd11+8], %r1650;
	st.global.u32 	[%rd11+12], %r1651;

BB3_331:
	ret;

BB3_157:
	setp.ne.s32	%p80, %r1728, 15;
	@%p80 bra 	BB3_167;

	and.b32  	%r1710, %r1710, 16777215;
	bra.uni 	BB3_167;
}

	// .globl	m00500_loop
.entry m00500_loop(
	.param .u64 .ptr .global .align 4 m00500_loop_param_0,
	.param .u64 .ptr .global .align 4 m00500_loop_param_1,
	.param .u64 .ptr .global .align 4 m00500_loop_param_2,
	.param .u64 .ptr .global .align 4 m00500_loop_param_3,
	.param .u64 .ptr .global .align 4 m00500_loop_param_4,
	.param .u64 .ptr .global .align 1 m00500_loop_param_5,
	.param .u64 .ptr .global .align 4 m00500_loop_param_6,
	.param .u64 .ptr .global .align 4 m00500_loop_param_7,
	.param .u64 .ptr .global .align 4 m00500_loop_param_8,
	.param .u64 .ptr .global .align 4 m00500_loop_param_9,
	.param .u64 .ptr .global .align 4 m00500_loop_param_10,
	.param .u64 .ptr .global .align 4 m00500_loop_param_11,
	.param .u64 .ptr .global .align 4 m00500_loop_param_12,
	.param .u64 .ptr .global .align 4 m00500_loop_param_13,
	.param .u64 .ptr .global .align 8 m00500_loop_param_14,
	.param .u64 .ptr .global .align 4 m00500_loop_param_15,
	.param .u64 .ptr .global .align 4 m00500_loop_param_16,
	.param .u64 .ptr .global .align 4 m00500_loop_param_17,
	.param .u64 .ptr .global .align 1 m00500_loop_param_18,
	.param .u64 .ptr .global .align 4 m00500_loop_param_19,
	.param .u64 .ptr .global .align 16 m00500_loop_param_20,
	.param .u64 .ptr .global .align 16 m00500_loop_param_21,
	.param .u64 .ptr .global .align 16 m00500_loop_param_22,
	.param .u64 .ptr .global .align 16 m00500_loop_param_23,
	.param .u32 m00500_loop_param_24,
	.param .u32 m00500_loop_param_25,
	.param .u32 m00500_loop_param_26,
	.param .u32 m00500_loop_param_27,
	.param .u32 m00500_loop_param_28,
	.param .u32 m00500_loop_param_29,
	.param .u32 m00500_loop_param_30,
	.param .u32 m00500_loop_param_31,
	.param .u32 m00500_loop_param_32,
	.param .u32 m00500_loop_param_33,
	.param .u64 m00500_loop_param_34
)
{
	.reg .pred 	%p<83>;
	.reg .b32 	%r<1156>;
	.reg .b64 	%rd<16>;


	ld.param.u64 	%rd3, [m00500_loop_param_0];
	ld.param.u64 	%rd4, [m00500_loop_param_4];
	ld.param.u64 	%rd5, [m00500_loop_param_17];
	ld.param.u32 	%r220, [m00500_loop_param_27];
	ld.param.u32 	%r1044, [m00500_loop_param_28];
	ld.param.u32 	%r222, [m00500_loop_param_29];
	ld.param.u64 	%rd6, [m00500_loop_param_34];
	mov.b32	%r223, %envreg3;
	mov.u32 	%r224, %ctaid.x;
	mov.u32 	%r225, %ntid.x;
	mad.lo.s32 	%r226, %r224, %r225, %r223;
	mov.u32 	%r227, %tid.x;
	add.s32 	%r1, %r226, %r227;
	cvt.s64.s32	%rd7, %r1;
	setp.ge.u64	%p1, %rd7, %rd6;
	@%p1 bra 	BB4_149;

	mul.wide.s32 	%rd8, %r1, 260;
	add.s64 	%rd9, %rd3, %rd8;
	ld.global.u32 	%r2, [%rd9];
	ld.global.u32 	%r3, [%rd9+4];
	ld.global.u32 	%r4, [%rd9+8];
	ld.global.u32 	%r5, [%rd9+12];
	ld.global.u32 	%r6, [%rd9+256];
	mul.wide.u32 	%rd10, %r220, 560;
	add.s64 	%rd1, %rd5, %rd10;
	ld.global.u32 	%r7, [%rd1];
	ld.global.u32 	%r8, [%rd1+4];
	mul.wide.s32 	%rd11, %r1, 16;
	add.s64 	%rd2, %rd4, %rd11;
	ld.global.u32 	%r1111, [%rd2];
	ld.global.u32 	%r1110, [%rd2+4];
	ld.global.u32 	%r1109, [%rd2+8];
	ld.global.u32 	%r1108, [%rd2+12];
	setp.eq.s32	%p2, %r222, 0;
	@%p2 bra 	BB4_148;

	ld.global.u32 	%r229, [%rd1+512];
	add.s32 	%r13, %r229, 16;
	and.b32  	%r230, %r6, 63;
	add.s32 	%r14, %r13, %r230;
	mov.u32 	%r1045, 0;

BB4_3:
	and.b32  	%r231, %r1044, 1;
	setp.eq.b32	%p3, %r231, 1;
	mul.wide.u32 	%rd12, %r1044, -1431655765;
	shr.u64 	%rd13, %rd12, 33;
	cvt.u32.u64	%r232, %rd13;
	mul.lo.s32 	%r233, %r232, 3;
	sub.s32 	%r21, %r1044, %r233;
	mul.wide.u32 	%rd14, %r1044, 613566757;
	shr.u64 	%rd15, %rd14, 32;
	cvt.u32.u64	%r234, %rd15;
	sub.s32 	%r235, %r1044, %r234;
	shr.u32 	%r236, %r235, 1;
	add.s32 	%r237, %r236, %r234;
	shr.u32 	%r238, %r237, 2;
	mul.lo.s32 	%r239, %r238, 7;
	sub.s32 	%r22, %r1044, %r239;
	@!%p3 bra 	BB4_91;
	bra.uni 	BB4_4;

BB4_91:
	setp.eq.s32	%p47, %r21, 0;
	setp.eq.s32	%p48, %r22, 0;
	or.pred  	%p49, %p47, %p48;
	@%p49 bra 	BB4_118;
	bra.uni 	BB4_92;

BB4_118:
	setp.ne.s32	%p63, %r21, 0;
	mov.u32 	%r1058, 0;
	@%p63 bra 	BB4_119;
	bra.uni 	BB4_120;

BB4_119:
	mov.u32 	%r1054, %r1058;
	mov.u32 	%r1055, %r1058;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1059, %r1058;
	mov.u32 	%r1060, %r1058;
	mov.u32 	%r1061, %r1058;
	mov.u32 	%r1106, %r1058;
	mov.u32 	%r1121, %r1058;
	mov.u32 	%r1122, %r13;
	bra.uni 	BB4_121;

BB4_4:
	and.b32  	%r1064, %r6, 63;
	mov.u32 	%r1054, 0;
	setp.eq.s32	%p4, %r21, 0;
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1055, %r1054;
	mov.u32 	%r1056, %r1054;
	mov.u32 	%r1057, %r1054;
	mov.u32 	%r1058, %r1054;
	mov.u32 	%r1059, %r1054;
	mov.u32 	%r1060, %r1054;
	mov.u32 	%r1061, %r1054;
	mov.u32 	%r1106, %r1054;
	mov.u32 	%r1063, %r1054;
	@%p4 bra 	BB4_39;

	and.b32  	%r273, %r6, 3;
	mov.u32 	%r274, 4;
	sub.s32 	%r275, %r274, %r273;
	shl.b32 	%r276, %r275, 2;
	mov.u32 	%r277, 1985229328;
	shr.u32 	%r278, %r277, %r276;
	and.b32  	%r261, %r278, 65535;
	mov.u32 	%r1106, 0;
	// inline asm
	prmt.b32 %r1061, %r1106, %r7, %r261;
	// inline asm
	// inline asm
	prmt.b32 %r1063, %r7, %r8, %r261;
	// inline asm
	// inline asm
	prmt.b32 %r258, %r8, %r1106, %r261;
	// inline asm
	add.s32 	%r1064, %r14, -16;
	bfe.u32 	%r272, %r6, 2, 4;
	setp.gt.s32	%p5, %r272, 5;
	@%p5 bra 	BB4_15;

	setp.gt.s32	%p13, %r272, 2;
	@%p13 bra 	BB4_11;

	setp.eq.s32	%p17, %r272, 0;
	@%p17 bra 	BB4_33;

	setp.eq.s32	%p18, %r272, 1;
	@%p18 bra 	BB4_31;
	bra.uni 	BB4_9;

BB4_31:
	or.b32  	%r1052, %r1061, %r3;
	mov.u32 	%r1050, %r258;
	mov.u32 	%r1051, %r1063;
	bra.uni 	BB4_32;

BB4_92:
	and.b32  	%r456, %r13, 3;
	mov.u32 	%r457, 4;
	sub.s32 	%r458, %r457, %r456;
	shl.b32 	%r459, %r458, 2;
	mov.u32 	%r460, 1985229328;
	shr.u32 	%r461, %r460, %r459;
	and.b32  	%r446, %r461, 65535;
	mov.u32 	%r1106, 0;
	// inline asm
	prmt.b32 %r1061, %r1106, %r2, %r446;
	// inline asm
	// inline asm
	prmt.b32 %r431, %r2, %r3, %r446;
	// inline asm
	// inline asm
	prmt.b32 %r435, %r3, %r4, %r446;
	// inline asm
	// inline asm
	prmt.b32 %r1121, %r4, %r5, %r446;
	// inline asm
	// inline asm
	prmt.b32 %r443, %r5, %r1106, %r446;
	// inline asm
	shr.u32 	%r455, %r13, 2;
	setp.gt.s32	%p50, %r455, 4;
	@%p50 bra 	BB4_101;

	setp.gt.s32	%p57, %r455, 1;
	@%p57 bra 	BB4_97;

	setp.eq.s32	%p61, %r455, 0;
	@%p61 bra 	BB4_117;
	bra.uni 	BB4_95;

BB4_117:
	or.b32  	%r1111, %r1061, %r1111;
	mov.u32 	%r1108, %r1121;
	mov.u32 	%r1109, %r435;
	mov.u32 	%r1110, %r431;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r443;
	bra.uni 	BB4_109;

BB4_120:
	setp.ne.s32	%p64, %r22, 0;
	selp.b32	%r1054, %r5, 0, %p64;
	selp.b32	%r1055, %r4, 0, %p64;
	selp.b32	%r1056, %r3, 0, %p64;
	selp.b32	%r1057, %r2, 0, %p64;
	and.b32  	%r526, %r6, 63;
	add.s32 	%r527, %r526, 16;
	selp.b32	%r1122, %r527, 16, %p64;
	mov.u32 	%r1059, %r1058;
	mov.u32 	%r1060, %r1058;
	mov.u32 	%r1061, %r1058;
	mov.u32 	%r1106, %r1058;
	mov.u32 	%r1121, %r1058;
	bra.uni 	BB4_121;

BB4_15:
	setp.gt.s32	%p6, %r272, 8;
	@%p6 bra 	BB4_20;

	setp.eq.s32	%p10, %r272, 6;
	@%p10 bra 	BB4_28;

	setp.eq.s32	%p11, %r272, 7;
	@%p11 bra 	BB4_27;
	bra.uni 	BB4_18;

BB4_27:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1061;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r258;
	mov.u32 	%r1061, %r1063;
	bra.uni 	BB4_38;

BB4_101:
	setp.gt.s32	%p51, %r455, 6;
	@%p51 bra 	BB4_105;

	setp.eq.s32	%p55, %r455, 5;
	@%p55 bra 	BB4_114;
	bra.uni 	BB4_103;

BB4_114:
	or.b32  	%r1056, %r1061, %r8;
	mov.u32 	%r1054, %r435;
	mov.u32 	%r1055, %r431;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r443;
	mov.u32 	%r1061, %r1121;
	bra.uni 	BB4_110;

BB4_11:
	setp.eq.s32	%p14, %r272, 3;
	@%p14 bra 	BB4_30;

	setp.eq.s32	%p15, %r272, 4;
	@%p15 bra 	BB4_29;
	bra.uni 	BB4_13;

BB4_29:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r258;
	mov.u32 	%r1056, %r1063;
	mov.u32 	%r1057, %r1061;
	bra.uni 	BB4_36;

BB4_97:
	setp.eq.s32	%p58, %r455, 2;
	@%p58 bra 	BB4_116;

	setp.eq.s32	%p59, %r455, 3;
	@%p59 bra 	BB4_115;
	bra.uni 	BB4_99;

BB4_115:
	or.b32  	%r1108, %r1061, %r1108;
	mov.u32 	%r1054, %r443;
	mov.u32 	%r1055, %r1121;
	mov.u32 	%r1056, %r435;
	mov.u32 	%r1057, %r431;
	bra.uni 	BB4_109;

BB4_20:
	setp.eq.s32	%p7, %r272, 9;
	@%p7 bra 	BB4_26;

	setp.eq.s32	%p8, %r272, 10;
	@%p8 bra 	BB4_25;
	bra.uni 	BB4_22;

BB4_25:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r1063;
	mov.u32 	%r1059, %r1061;
	mov.u32 	%r1060, %r1106;
	mov.u32 	%r1061, %r1106;
	mov.u32 	%r1063, %r258;
	bra.uni 	BB4_39;

BB4_105:
	setp.eq.s32	%p52, %r455, 7;
	@%p52 bra 	BB4_113;

	setp.eq.s32	%p53, %r455, 8;
	@%p53 bra 	BB4_112;
	bra.uni 	BB4_107;

BB4_112:
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1058, %r1121;
	mov.u32 	%r1059, %r435;
	mov.u32 	%r1060, %r431;
	mov.u32 	%r1121, %r443;
	mov.u32 	%r1122, %r14;
	bra.uni 	BB4_121;

BB4_95:
	setp.eq.s32	%p62, %r455, 1;
	@%p62 bra 	BB4_96;
	bra.uni 	BB4_108;

BB4_96:
	or.b32  	%r1110, %r1061, %r1110;
	mov.u32 	%r1108, %r435;
	mov.u32 	%r1109, %r431;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r443;
	mov.u32 	%r1057, %r1121;
	bra.uni 	BB4_109;

BB4_103:
	setp.eq.s32	%p56, %r455, 6;
	@%p56 bra 	BB4_104;
	bra.uni 	BB4_108;

BB4_104:
	mov.u32 	%r1054, %r431;
	mov.u32 	%r1055, %r1061;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r443;
	mov.u32 	%r1060, %r1121;
	mov.u32 	%r1061, %r435;
	bra.uni 	BB4_110;

BB4_33:
	or.b32  	%r1053, %r1061, %r2;
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r258;
	mov.u32 	%r1052, %r1063;
	bra.uni 	BB4_34;

BB4_9:
	setp.eq.s32	%p19, %r272, 2;
	@%p19 bra 	BB4_10;
	bra.uni 	BB4_23;

BB4_10:
	or.b32  	%r1051, %r1061, %r4;
	mov.u32 	%r1050, %r1063;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r258;
	bra.uni 	BB4_36;

BB4_28:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1063;
	mov.u32 	%r1055, %r1061;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r1106;
	mov.u32 	%r1061, %r258;
	bra.uni 	BB4_38;

BB4_18:
	setp.eq.s32	%p12, %r272, 8;
	@%p12 bra 	BB4_19;
	bra.uni 	BB4_23;

BB4_19:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r258;
	mov.u32 	%r1060, %r1063;
	bra.uni 	BB4_38;

BB4_30:
	or.b32  	%r1050, %r1061, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r258;
	mov.u32 	%r1057, %r1063;
	bra.uni 	BB4_36;

BB4_13:
	setp.eq.s32	%p16, %r272, 5;
	@%p16 bra 	BB4_14;
	bra.uni 	BB4_23;

BB4_14:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r258;
	mov.u32 	%r1055, %r1063;
	mov.u32 	%r1056, %r1061;
	bra.uni 	BB4_35;

BB4_116:
	or.b32  	%r1109, %r1061, %r1109;
	mov.u32 	%r1108, %r431;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r443;
	mov.u32 	%r1056, %r1121;
	mov.u32 	%r1057, %r435;
	bra.uni 	BB4_109;

BB4_99:
	setp.eq.s32	%p60, %r455, 4;
	@%p60 bra 	BB4_100;
	bra.uni 	BB4_108;

BB4_100:
	or.b32  	%r1057, %r1061, %r7;
	mov.u32 	%r1054, %r1121;
	mov.u32 	%r1055, %r435;
	mov.u32 	%r1056, %r431;
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r1106;
	mov.u32 	%r1061, %r443;
	bra.uni 	BB4_110;

BB4_26:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r258;
	mov.u32 	%r1059, %r1063;
	mov.u32 	%r1060, %r1061;
	bra.uni 	BB4_37;

BB4_22:
	setp.ne.s32	%p9, %r272, 11;
	@%p9 bra 	BB4_23;

	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;
	mov.u32 	%r1053, %r2;
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;
	mov.u32 	%r1057, %r1106;
	mov.u32 	%r1058, %r1061;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r1106;
	mov.u32 	%r1061, %r1106;
	mov.u32 	%r1106, %r258;
	bra.uni 	BB4_39;

BB4_23:
	mov.u32 	%r1050, %r5;
	mov.u32 	%r1051, %r4;
	mov.u32 	%r1052, %r3;

BB4_32:
	mov.u32 	%r1053, %r2;

BB4_34:
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r1106;

BB4_35:
	mov.u32 	%r1057, %r1106;

BB4_36:
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r1106;

BB4_37:
	mov.u32 	%r1061, %r1106;

BB4_38:
	mov.u32 	%r1063, %r1106;

BB4_39:
	setp.eq.s32	%p20, %r22, 0;
	@%p20 bra 	BB4_40;

	and.b32  	%r393, %r1064, 3;
	mov.u32 	%r394, 4;
	sub.s32 	%r395, %r394, %r393;
	shl.b32 	%r396, %r395, 2;
	mov.u32 	%r397, 1985229328;
	shr.u32 	%r398, %r397, %r396;
	and.b32  	%r391, %r398, 65535;
	mov.u32 	%r390, 0;
	// inline asm
	prmt.b32 %r372, %r390, %r2, %r391;
	// inline asm
	// inline asm
	prmt.b32 %r376, %r2, %r3, %r391;
	// inline asm
	// inline asm
	prmt.b32 %r380, %r3, %r4, %r391;
	// inline asm
	// inline asm
	prmt.b32 %r1078, %r4, %r5, %r391;
	// inline asm
	// inline asm
	prmt.b32 %r388, %r5, %r390, %r391;
	// inline asm
	shr.u32 	%r392, %r1064, 2;
	setp.gt.s32	%p21, %r392, 4;
	@%p21 bra 	BB4_50;

	setp.gt.s32	%p28, %r392, 1;
	@%p28 bra 	BB4_46;

	setp.eq.s32	%p32, %r392, 0;
	@%p32 bra 	BB4_63;
	bra.uni 	BB4_44;

BB4_63:
	or.b32  	%r1053, %r372, %r1053;
	mov.u32 	%r1050, %r1078;
	mov.u32 	%r1051, %r380;
	mov.u32 	%r1052, %r376;
	mov.u32 	%r1057, %r388;
	bra.uni 	BB4_64;

BB4_40:
	mov.u32 	%r1078, %r1063;
	bra.uni 	BB4_66;

BB4_50:
	setp.gt.s32	%p22, %r392, 6;
	@%p22 bra 	BB4_54;

	setp.eq.s32	%p26, %r392, 5;
	@%p26 bra 	BB4_60;
	bra.uni 	BB4_52;

BB4_60:
	or.b32  	%r1056, %r372, %r1056;
	mov.u32 	%r1054, %r380;
	mov.u32 	%r1055, %r376;
	mov.u32 	%r1060, %r388;
	mov.u32 	%r1061, %r1078;
	bra.uni 	BB4_64;

BB4_46:
	setp.eq.s32	%p29, %r392, 2;
	@%p29 bra 	BB4_62;

	setp.eq.s32	%p30, %r392, 3;
	@%p30 bra 	BB4_61;
	bra.uni 	BB4_48;

BB4_61:
	or.b32  	%r1050, %r372, %r1050;
	mov.u32 	%r1054, %r388;
	mov.u32 	%r1055, %r1078;
	mov.u32 	%r1056, %r380;
	mov.u32 	%r1057, %r376;
	bra.uni 	BB4_64;

BB4_54:
	setp.eq.s32	%p23, %r392, 7;
	@%p23 bra 	BB4_59;

	setp.eq.s32	%p24, %r392, 8;
	@%p24 bra 	BB4_58;
	bra.uni 	BB4_56;

BB4_58:
	or.b32  	%r1061, %r372, %r1061;
	mov.u32 	%r1058, %r1078;
	mov.u32 	%r1059, %r380;
	mov.u32 	%r1060, %r376;
	mov.u32 	%r1078, %r388;
	bra.uni 	BB4_65;

BB4_44:
	setp.eq.s32	%p33, %r392, 1;
	@%p33 bra 	BB4_45;
	bra.uni 	BB4_64;

BB4_45:
	or.b32  	%r1052, %r372, %r1052;
	mov.u32 	%r1050, %r380;
	mov.u32 	%r1051, %r376;
	mov.u32 	%r1056, %r388;
	mov.u32 	%r1057, %r1078;
	bra.uni 	BB4_64;

BB4_52:
	setp.eq.s32	%p27, %r392, 6;
	@%p27 bra 	BB4_53;
	bra.uni 	BB4_64;

BB4_53:
	or.b32  	%r1055, %r372, %r1055;
	mov.u32 	%r1054, %r376;
	mov.u32 	%r1059, %r388;
	mov.u32 	%r1060, %r1078;
	mov.u32 	%r1061, %r380;
	bra.uni 	BB4_64;

BB4_113:
	mov.u32 	%r1054, %r1061;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1058, %r443;
	mov.u32 	%r1059, %r1121;
	mov.u32 	%r1060, %r435;
	mov.u32 	%r1061, %r431;
	bra.uni 	BB4_110;

BB4_107:
	setp.ne.s32	%p54, %r455, 9;
	@%p54 bra 	BB4_108;

	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;
	mov.u32 	%r1058, %r435;
	mov.u32 	%r1059, %r431;
	mov.u32 	%r1060, %r1061;
	mov.u32 	%r1061, %r1106;
	mov.u32 	%r1106, %r443;
	mov.u32 	%r1122, %r14;
	bra.uni 	BB4_121;

BB4_108:
	mov.u32 	%r1054, %r1106;
	mov.u32 	%r1055, %r1106;
	mov.u32 	%r1056, %r8;
	mov.u32 	%r1057, %r7;

BB4_109:
	mov.u32 	%r1058, %r1106;
	mov.u32 	%r1059, %r1106;
	mov.u32 	%r1060, %r1106;
	mov.u32 	%r1061, %r1106;

BB4_110:
	mov.u32 	%r1121, %r1106;
	mov.u32 	%r1122, %r14;

BB4_121:
	and.b32  	%r549, %r1122, 3;
	mov.u32 	%r550, 4;
	sub.s32 	%r551, %r550, %r549;
	shl.b32 	%r552, %r551, 2;
	mov.u32 	%r553, 1985229328;
	shr.u32 	%r554, %r553, %r552;
	and.b32  	%r547, %r554, 65535;
	bfe.u32 	%r555, %r6, 2, 2;
	setp.eq.s32	%p65, %r555, 0;
	and.b32  	%r556, %r6, 3;
	shl.b32 	%r557, %r556, 3;
	mov.u32 	%r558, 255;
	shl.b32 	%r559, %r558, %r557;
	and.b32  	%r560, %r559, -2139062144;
	selp.b32	%r561, %r560, 0, %p65;
	or.b32  	%r533, %r561, %r2;
	mov.u32 	%r546, 0;
	// inline asm
	prmt.b32 %r528, %r546, %r533, %r547;
	// inline asm
	setp.eq.s32	%p66, %r555, 1;
	selp.b32	%r562, %r560, 0, %p66;
	or.b32  	%r537, %r562, %r3;
	// inline asm
	prmt.b32 %r532, %r533, %r537, %r547;
	// inline asm
	setp.eq.s32	%p67, %r555, 2;
	selp.b32	%r563, %r560, 0, %p67;
	or.b32  	%r541, %r563, %r4;
	// inline asm
	prmt.b32 %r536, %r537, %r541, %r547;
	// inline asm
	setp.eq.s32	%p68, %r555, 3;
	selp.b32	%r564, %r560, 0, %p68;
	or.b32  	%r545, %r564, %r5;
	// inline asm
	prmt.b32 %r1107, %r541, %r545, %r547;
	// inline asm
	// inline asm
	prmt.b32 %r544, %r545, %r546, %r547;
	// inline asm
	shr.u32 	%r548, %r1122, 2;
	setp.gt.s32	%p69, %r548, 4;
	@%p69 bra 	BB4_130;

	setp.gt.s32	%p76, %r548, 1;
	@%p76 bra 	BB4_126;

	setp.eq.s32	%p80, %r548, 0;
	@%p80 bra 	BB4_144;
	bra.uni 	BB4_124;

BB4_144:
	or.b32  	%r1053, %r528, %r1111;
	mov.u32 	%r1050, %r1107;
	mov.u32 	%r1051, %r536;
	mov.u32 	%r1052, %r532;
	mov.u32 	%r1057, %r544;
	bra.uni 	BB4_145;

BB4_130:
	setp.gt.s32	%p70, %r548, 6;
	@%p70 bra 	BB4_134;

	setp.eq.s32	%p74, %r548, 5;
	@%p74 bra 	BB4_141;
	bra.uni 	BB4_132;

BB4_141:
	or.b32  	%r1056, %r528, %r1056;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1054, %r536;
	mov.u32 	%r1055, %r532;
	mov.u32 	%r1060, %r544;
	mov.u32 	%r1061, %r1107;
	bra.uni 	BB4_145;

BB4_126:
	setp.eq.s32	%p77, %r548, 2;
	@%p77 bra 	BB4_143;

	setp.eq.s32	%p78, %r548, 3;
	@%p78 bra 	BB4_142;
	bra.uni 	BB4_128;

BB4_142:
	or.b32  	%r1050, %r528, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1054, %r544;
	mov.u32 	%r1055, %r1107;
	mov.u32 	%r1056, %r536;
	mov.u32 	%r1057, %r532;
	bra.uni 	BB4_145;

BB4_134:
	setp.eq.s32	%p71, %r548, 7;
	@%p71 bra 	BB4_140;

	setp.eq.s32	%p72, %r548, 8;
	@%p72 bra 	BB4_139;
	bra.uni 	BB4_136;

BB4_139:
	or.b32  	%r1061, %r528, %r1061;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1058, %r1107;
	mov.u32 	%r1059, %r536;
	mov.u32 	%r1060, %r532;
	mov.u32 	%r1107, %r544;
	bra.uni 	BB4_146;

BB4_124:
	setp.eq.s32	%p81, %r548, 1;
	@%p81 bra 	BB4_125;
	bra.uni 	BB4_137;

BB4_125:
	or.b32  	%r1052, %r528, %r1110;
	mov.u32 	%r1050, %r536;
	mov.u32 	%r1051, %r532;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1056, %r544;
	mov.u32 	%r1057, %r1107;
	bra.uni 	BB4_145;

BB4_132:
	setp.eq.s32	%p75, %r548, 6;
	@%p75 bra 	BB4_133;
	bra.uni 	BB4_137;

BB4_133:
	or.b32  	%r1055, %r528, %r1055;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1054, %r532;
	mov.u32 	%r1059, %r544;
	mov.u32 	%r1060, %r1107;
	mov.u32 	%r1061, %r536;
	bra.uni 	BB4_145;

BB4_143:
	or.b32  	%r1051, %r528, %r1109;
	mov.u32 	%r1050, %r532;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1055, %r544;
	mov.u32 	%r1056, %r1107;
	mov.u32 	%r1057, %r536;
	bra.uni 	BB4_145;

BB4_140:
	or.b32  	%r1054, %r528, %r1054;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1058, %r544;
	mov.u32 	%r1059, %r1107;
	mov.u32 	%r1060, %r536;
	mov.u32 	%r1061, %r532;
	bra.uni 	BB4_145;

BB4_128:
	setp.eq.s32	%p79, %r548, 4;
	@%p79 bra 	BB4_129;
	bra.uni 	BB4_137;

BB4_129:
	or.b32  	%r1057, %r528, %r1057;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1054, %r1107;
	mov.u32 	%r1055, %r536;
	mov.u32 	%r1056, %r532;
	mov.u32 	%r1061, %r544;
	bra.uni 	BB4_145;

BB4_136:
	setp.ne.s32	%p73, %r548, 9;
	@%p73 bra 	BB4_137;

	or.b32  	%r1060, %r528, %r1060;
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;
	mov.u32 	%r1058, %r536;
	mov.u32 	%r1059, %r532;
	mov.u32 	%r1106, %r544;
	bra.uni 	BB4_146;

BB4_137:
	mov.u32 	%r1050, %r1108;
	mov.u32 	%r1051, %r1109;
	mov.u32 	%r1052, %r1110;
	mov.u32 	%r1053, %r1111;

BB4_145:
	mov.u32 	%r1107, %r1121;

BB4_146:
	and.b32  	%r565, %r6, 63;
	add.s32 	%r1151, %r1122, %r565;
	bra.uni 	BB4_147;

BB4_62:
	or.b32  	%r1051, %r372, %r1051;
	mov.u32 	%r1050, %r376;
	mov.u32 	%r1055, %r388;
	mov.u32 	%r1056, %r1078;
	mov.u32 	%r1057, %r380;
	bra.uni 	BB4_64;

BB4_48:
	setp.eq.s32	%p31, %r392, 4;
	@%p31 bra 	BB4_49;
	bra.uni 	BB4_64;

BB4_49:
	or.b32  	%r1057, %r372, %r1057;
	mov.u32 	%r1054, %r1078;
	mov.u32 	%r1055, %r380;
	mov.u32 	%r1056, %r376;
	mov.u32 	%r1061, %r388;
	bra.uni 	BB4_64;

BB4_59:
	or.b32  	%r1054, %r372, %r1054;
	mov.u32 	%r1058, %r388;
	mov.u32 	%r1059, %r1078;
	mov.u32 	%r1060, %r380;
	mov.u32 	%r1061, %r376;
	bra.uni 	BB4_64;

BB4_56:
	setp.ne.s32	%p25, %r392, 9;
	@%p25 bra 	BB4_64;

	or.b32  	%r1060, %r372, %r1060;
	mov.u32 	%r1058, %r380;
	mov.u32 	%r1059, %r376;
	mov.u32 	%r1106, %r388;
	bra.uni 	BB4_65;

BB4_64:
	mov.u32 	%r1078, %r1063;

BB4_65:
	and.b32  	%r399, %r6, 63;
	add.s32 	%r1064, %r1064, %r399;

BB4_66:
	and.b32  	%r421, %r1064, 3;
	mov.u32 	%r422, 4;
	sub.s32 	%r423, %r422, %r421;
	shl.b32 	%r424, %r423, 2;
	mov.u32 	%r425, 1985229328;
	shr.u32 	%r426, %r425, %r424;
	and.b32  	%r419, %r426, 65535;
	mov.u32 	%r401, 0;
	// inline asm
	prmt.b32 %r400, %r401, %r1111, %r419;
	// inline asm
	// inline asm
	prmt.b32 %r404, %r1111, %r1110, %r419;
	// inline asm
	// inline asm
	prmt.b32 %r408, %r1110, %r1109, %r419;
	// inline asm
	// inline asm
	prmt.b32 %r1107, %r1109, %r1108, %r419;
	// inline asm
	mov.u32 	%r418, 128;
	// inline asm
	prmt.b32 %r416, %r1108, %r418, %r419;
	// inline asm
	shr.u32 	%r420, %r1064, 2;
	setp.gt.s32	%p34, %r420, 4;
	@%p34 bra 	BB4_75;

	setp.gt.s32	%p41, %r420, 1;
	@%p41 bra 	BB4_71;

	setp.eq.s32	%p45, %r420, 0;
	@%p45 bra 	BB4_88;
	bra.uni 	BB4_69;

BB4_88:
	or.b32  	%r1053, %r400, %r1053;
	mov.u32 	%r1050, %r1107;
	mov.u32 	%r1051, %r408;
	mov.u32 	%r1052, %r404;
	mov.u32 	%r1057, %r416;
	bra.uni 	BB4_89;

BB4_75:
	setp.gt.s32	%p35, %r420, 6;
	@%p35 bra 	BB4_79;

	setp.eq.s32	%p39, %r420, 5;
	@%p39 bra 	BB4_85;
	bra.uni 	BB4_77;

BB4_85:
	or.b32  	%r1056, %r400, %r1056;
	mov.u32 	%r1054, %r408;
	mov.u32 	%r1055, %r404;
	mov.u32 	%r1060, %r416;
	mov.u32 	%r1061, %r1107;
	bra.uni 	BB4_89;

BB4_71:
	setp.eq.s32	%p42, %r420, 2;
	@%p42 bra 	BB4_87;

	setp.eq.s32	%p43, %r420, 3;
	@%p43 bra 	BB4_86;
	bra.uni 	BB4_73;

BB4_86:
	or.b32  	%r1050, %r400, %r1050;
	mov.u32 	%r1054, %r416;
	mov.u32 	%r1055, %r1107;
	mov.u32 	%r1056, %r408;
	mov.u32 	%r1057, %r404;
	bra.uni 	BB4_89;

BB4_79:
	setp.eq.s32	%p36, %r420, 7;
	@%p36 bra 	BB4_84;

	setp.eq.s32	%p37, %r420, 8;
	@%p37 bra 	BB4_83;
	bra.uni 	BB4_81;

BB4_83:
	or.b32  	%r1061, %r400, %r1061;
	mov.u32 	%r1058, %r1107;
	mov.u32 	%r1059, %r408;
	mov.u32 	%r1060, %r404;
	mov.u32 	%r1107, %r416;
	bra.uni 	BB4_90;

BB4_69:
	setp.eq.s32	%p46, %r420, 1;
	@%p46 bra 	BB4_70;
	bra.uni 	BB4_89;

BB4_70:
	or.b32  	%r1052, %r400, %r1052;
	mov.u32 	%r1050, %r408;
	mov.u32 	%r1051, %r404;
	mov.u32 	%r1056, %r416;
	mov.u32 	%r1057, %r1107;
	bra.uni 	BB4_89;

BB4_77:
	setp.eq.s32	%p40, %r420, 6;
	@%p40 bra 	BB4_78;
	bra.uni 	BB4_89;

BB4_78:
	or.b32  	%r1055, %r400, %r1055;
	mov.u32 	%r1054, %r404;
	mov.u32 	%r1059, %r416;
	mov.u32 	%r1060, %r1107;
	mov.u32 	%r1061, %r408;
	bra.uni 	BB4_89;

BB4_87:
	or.b32  	%r1051, %r400, %r1051;
	mov.u32 	%r1050, %r404;
	mov.u32 	%r1055, %r416;
	mov.u32 	%r1056, %r1107;
	mov.u32 	%r1057, %r408;
	bra.uni 	BB4_89;

BB4_84:
	or.b32  	%r1054, %r400, %r1054;
	mov.u32 	%r1058, %r416;
	mov.u32 	%r1059, %r1107;
	mov.u32 	%r1060, %r408;
	mov.u32 	%r1061, %r404;
	bra.uni 	BB4_89;

BB4_73:
	setp.eq.s32	%p44, %r420, 4;
	@%p44 bra 	BB4_74;
	bra.uni 	BB4_89;

BB4_74:
	or.b32  	%r1057, %r400, %r1057;
	mov.u32 	%r1054, %r1107;
	mov.u32 	%r1055, %r408;
	mov.u32 	%r1056, %r404;
	mov.u32 	%r1061, %r416;
	bra.uni 	BB4_89;

BB4_81:
	setp.ne.s32	%p38, %r420, 9;
	@%p38 bra 	BB4_89;

	or.b32  	%r1060, %r400, %r1060;
	mov.u32 	%r1058, %r408;
	mov.u32 	%r1059, %r404;
	mov.u32 	%r1106, %r416;
	bra.uni 	BB4_90;

BB4_89:
	mov.u32 	%r1107, %r1078;

BB4_90:
	add.s32 	%r1151, %r1064, 16;

BB4_147:
	ld.param.u32 	%r1043, [m00500_loop_param_29];
	add.s32 	%r566, %r1053, -680876937;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r566, 7;
	shr.b32 	%rhs, %r566, 25;
	add.u32 	%r567, %lhs, %rhs;
	}
	add.s32 	%r568, %r567, -271733879;
	and.b32  	%r569, %r568, 2004318071;
	xor.b32  	%r570, %r569, -1732584194;
	add.s32 	%r571, %r1052, %r570;
	add.s32 	%r572, %r571, -117830708;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r572, 12;
	shr.b32 	%rhs, %r572, 20;
	add.u32 	%r573, %lhs, %rhs;
	}
	add.s32 	%r574, %r573, %r568;
	xor.b32  	%r575, %r568, -271733879;
	and.b32  	%r576, %r574, %r575;
	xor.b32  	%r577, %r576, -271733879;
	add.s32 	%r578, %r1051, %r577;
	add.s32 	%r579, %r578, -1126478375;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r579, 17;
	shr.b32 	%rhs, %r579, 15;
	add.u32 	%r580, %lhs, %rhs;
	}
	add.s32 	%r581, %r580, %r574;
	xor.b32  	%r582, %r574, %r568;
	and.b32  	%r583, %r581, %r582;
	xor.b32  	%r584, %r583, %r568;
	add.s32 	%r585, %r1050, %r584;
	add.s32 	%r586, %r585, -1316259209;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r586, 22;
	shr.b32 	%rhs, %r586, 10;
	add.u32 	%r587, %lhs, %rhs;
	}
	add.s32 	%r588, %r587, %r581;
	xor.b32  	%r589, %r581, %r574;
	and.b32  	%r590, %r588, %r589;
	xor.b32  	%r591, %r590, %r574;
	add.s32 	%r592, %r1057, %r567;
	add.s32 	%r593, %r592, %r591;
	add.s32 	%r594, %r593, -448152776;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r594, 7;
	shr.b32 	%rhs, %r594, 25;
	add.u32 	%r595, %lhs, %rhs;
	}
	add.s32 	%r596, %r595, %r588;
	xor.b32  	%r597, %r588, %r581;
	and.b32  	%r598, %r596, %r597;
	xor.b32  	%r599, %r598, %r581;
	add.s32 	%r600, %r1056, %r574;
	add.s32 	%r601, %r600, %r599;
	add.s32 	%r602, %r601, 1200080426;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r602, 12;
	shr.b32 	%rhs, %r602, 20;
	add.u32 	%r603, %lhs, %rhs;
	}
	add.s32 	%r604, %r603, %r596;
	xor.b32  	%r605, %r596, %r588;
	and.b32  	%r606, %r604, %r605;
	xor.b32  	%r607, %r606, %r588;
	add.s32 	%r608, %r1055, %r581;
	add.s32 	%r609, %r608, %r607;
	add.s32 	%r610, %r609, -1473231341;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r610, 17;
	shr.b32 	%rhs, %r610, 15;
	add.u32 	%r611, %lhs, %rhs;
	}
	add.s32 	%r612, %r611, %r604;
	xor.b32  	%r613, %r604, %r596;
	and.b32  	%r614, %r612, %r613;
	xor.b32  	%r615, %r614, %r596;
	add.s32 	%r616, %r1054, %r588;
	add.s32 	%r617, %r616, %r615;
	add.s32 	%r618, %r617, -45705983;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r618, 22;
	shr.b32 	%rhs, %r618, 10;
	add.u32 	%r619, %lhs, %rhs;
	}
	add.s32 	%r620, %r619, %r612;
	xor.b32  	%r621, %r612, %r604;
	and.b32  	%r622, %r620, %r621;
	xor.b32  	%r623, %r622, %r604;
	add.s32 	%r624, %r1061, %r596;
	add.s32 	%r625, %r624, %r623;
	add.s32 	%r626, %r625, 1770035416;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r626, 7;
	shr.b32 	%rhs, %r626, 25;
	add.u32 	%r627, %lhs, %rhs;
	}
	add.s32 	%r628, %r627, %r620;
	xor.b32  	%r629, %r620, %r612;
	and.b32  	%r630, %r628, %r629;
	xor.b32  	%r631, %r630, %r612;
	add.s32 	%r632, %r1060, %r604;
	add.s32 	%r633, %r632, %r631;
	add.s32 	%r634, %r633, -1958414417;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r634, 12;
	shr.b32 	%rhs, %r634, 20;
	add.u32 	%r635, %lhs, %rhs;
	}
	add.s32 	%r636, %r635, %r628;
	xor.b32  	%r637, %r628, %r620;
	and.b32  	%r638, %r636, %r637;
	xor.b32  	%r639, %r638, %r620;
	add.s32 	%r640, %r1059, %r612;
	add.s32 	%r641, %r640, %r639;
	add.s32 	%r642, %r641, -42063;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r642, 17;
	shr.b32 	%rhs, %r642, 15;
	add.u32 	%r643, %lhs, %rhs;
	}
	add.s32 	%r644, %r643, %r636;
	xor.b32  	%r645, %r636, %r628;
	and.b32  	%r646, %r644, %r645;
	xor.b32  	%r647, %r646, %r628;
	add.s32 	%r648, %r1058, %r620;
	add.s32 	%r649, %r648, %r647;
	add.s32 	%r650, %r649, -1990404162;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r650, 22;
	shr.b32 	%rhs, %r650, 10;
	add.u32 	%r651, %lhs, %rhs;
	}
	add.s32 	%r652, %r651, %r644;
	xor.b32  	%r653, %r644, %r636;
	and.b32  	%r654, %r652, %r653;
	xor.b32  	%r655, %r654, %r636;
	add.s32 	%r656, %r1107, %r628;
	add.s32 	%r657, %r656, %r655;
	add.s32 	%r658, %r657, 1804603682;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r658, 7;
	shr.b32 	%rhs, %r658, 25;
	add.u32 	%r659, %lhs, %rhs;
	}
	add.s32 	%r660, %r659, %r652;
	xor.b32  	%r661, %r652, %r644;
	and.b32  	%r662, %r660, %r661;
	xor.b32  	%r663, %r662, %r644;
	add.s32 	%r664, %r1106, %r636;
	add.s32 	%r665, %r664, %r663;
	add.s32 	%r666, %r665, -40341101;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r666, 12;
	shr.b32 	%rhs, %r666, 20;
	add.u32 	%r667, %lhs, %rhs;
	}
	add.s32 	%r668, %r667, %r660;
	xor.b32  	%r669, %r660, %r652;
	and.b32  	%r670, %r668, %r669;
	xor.b32  	%r671, %r670, %r652;
	shl.b32 	%r672, %r1151, 3;
	add.s32 	%r673, %r672, %r644;
	add.s32 	%r674, %r673, %r671;
	add.s32 	%r675, %r674, -1502002290;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r675, 17;
	shr.b32 	%rhs, %r675, 15;
	add.u32 	%r676, %lhs, %rhs;
	}
	add.s32 	%r677, %r676, %r668;
	xor.b32  	%r678, %r668, %r660;
	and.b32  	%r679, %r677, %r678;
	xor.b32  	%r680, %r679, %r660;
	add.s32 	%r681, %r652, %r680;
	add.s32 	%r682, %r681, 1236535329;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r682, 22;
	shr.b32 	%rhs, %r682, 10;
	add.u32 	%r683, %lhs, %rhs;
	}
	add.s32 	%r684, %r683, %r677;
	xor.b32  	%r685, %r684, %r677;
	and.b32  	%r686, %r685, %r668;
	xor.b32  	%r687, %r686, %r677;
	add.s32 	%r688, %r1052, %r660;
	add.s32 	%r689, %r688, %r687;
	add.s32 	%r690, %r689, -165796510;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r690, 5;
	shr.b32 	%rhs, %r690, 27;
	add.u32 	%r691, %lhs, %rhs;
	}
	add.s32 	%r692, %r691, %r684;
	xor.b32  	%r693, %r692, %r684;
	and.b32  	%r694, %r693, %r677;
	xor.b32  	%r695, %r694, %r684;
	add.s32 	%r696, %r1055, %r668;
	add.s32 	%r697, %r696, %r695;
	add.s32 	%r698, %r697, -1069501632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r698, 9;
	shr.b32 	%rhs, %r698, 23;
	add.u32 	%r699, %lhs, %rhs;
	}
	add.s32 	%r700, %r699, %r692;
	xor.b32  	%r701, %r700, %r692;
	and.b32  	%r702, %r701, %r684;
	xor.b32  	%r703, %r702, %r692;
	add.s32 	%r704, %r1058, %r677;
	add.s32 	%r705, %r704, %r703;
	add.s32 	%r706, %r705, 643717713;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r706, 14;
	shr.b32 	%rhs, %r706, 18;
	add.u32 	%r707, %lhs, %rhs;
	}
	add.s32 	%r708, %r707, %r700;
	xor.b32  	%r709, %r708, %r700;
	and.b32  	%r710, %r709, %r692;
	xor.b32  	%r711, %r710, %r700;
	add.s32 	%r712, %r1053, %r684;
	add.s32 	%r713, %r712, %r711;
	add.s32 	%r714, %r713, -373897302;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r714, 20;
	shr.b32 	%rhs, %r714, 12;
	add.u32 	%r715, %lhs, %rhs;
	}
	add.s32 	%r716, %r715, %r708;
	xor.b32  	%r717, %r716, %r708;
	and.b32  	%r718, %r717, %r700;
	xor.b32  	%r719, %r718, %r708;
	add.s32 	%r720, %r1056, %r692;
	add.s32 	%r721, %r720, %r719;
	add.s32 	%r722, %r721, -701558691;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r722, 5;
	shr.b32 	%rhs, %r722, 27;
	add.u32 	%r723, %lhs, %rhs;
	}
	add.s32 	%r724, %r723, %r716;
	xor.b32  	%r725, %r724, %r716;
	and.b32  	%r726, %r725, %r708;
	xor.b32  	%r727, %r726, %r716;
	add.s32 	%r728, %r1059, %r700;
	add.s32 	%r729, %r728, %r727;
	add.s32 	%r730, %r729, 38016083;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r730, 9;
	shr.b32 	%rhs, %r730, 23;
	add.u32 	%r731, %lhs, %rhs;
	}
	add.s32 	%r732, %r731, %r724;
	xor.b32  	%r733, %r732, %r724;
	and.b32  	%r734, %r733, %r716;
	xor.b32  	%r735, %r734, %r724;
	add.s32 	%r736, %r708, %r735;
	add.s32 	%r737, %r736, -660478335;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r737, 14;
	shr.b32 	%rhs, %r737, 18;
	add.u32 	%r738, %lhs, %rhs;
	}
	add.s32 	%r739, %r738, %r732;
	xor.b32  	%r740, %r739, %r732;
	and.b32  	%r741, %r740, %r724;
	xor.b32  	%r742, %r741, %r732;
	add.s32 	%r743, %r1057, %r716;
	add.s32 	%r744, %r743, %r742;
	add.s32 	%r745, %r744, -405537848;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r745, 20;
	shr.b32 	%rhs, %r745, 12;
	add.u32 	%r746, %lhs, %rhs;
	}
	add.s32 	%r747, %r746, %r739;
	xor.b32  	%r748, %r747, %r739;
	and.b32  	%r749, %r748, %r732;
	xor.b32  	%r750, %r749, %r739;
	add.s32 	%r751, %r1060, %r724;
	add.s32 	%r752, %r751, %r750;
	add.s32 	%r753, %r752, 568446438;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r753, 5;
	shr.b32 	%rhs, %r753, 27;
	add.u32 	%r754, %lhs, %rhs;
	}
	add.s32 	%r755, %r754, %r747;
	xor.b32  	%r756, %r755, %r747;
	and.b32  	%r757, %r756, %r739;
	xor.b32  	%r758, %r757, %r747;
	add.s32 	%r759, %r672, %r732;
	add.s32 	%r760, %r759, %r758;
	add.s32 	%r761, %r760, -1019803690;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r761, 9;
	shr.b32 	%rhs, %r761, 23;
	add.u32 	%r762, %lhs, %rhs;
	}
	add.s32 	%r763, %r762, %r755;
	xor.b32  	%r764, %r763, %r755;
	and.b32  	%r765, %r764, %r747;
	xor.b32  	%r766, %r765, %r755;
	add.s32 	%r767, %r1050, %r739;
	add.s32 	%r768, %r767, %r766;
	add.s32 	%r769, %r768, -187363961;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r769, 14;
	shr.b32 	%rhs, %r769, 18;
	add.u32 	%r770, %lhs, %rhs;
	}
	add.s32 	%r771, %r770, %r763;
	xor.b32  	%r772, %r771, %r763;
	and.b32  	%r773, %r772, %r755;
	xor.b32  	%r774, %r773, %r763;
	add.s32 	%r775, %r1061, %r747;
	add.s32 	%r776, %r775, %r774;
	add.s32 	%r777, %r776, 1163531501;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r777, 20;
	shr.b32 	%rhs, %r777, 12;
	add.u32 	%r778, %lhs, %rhs;
	}
	add.s32 	%r779, %r778, %r771;
	xor.b32  	%r780, %r779, %r771;
	and.b32  	%r781, %r780, %r763;
	xor.b32  	%r782, %r781, %r771;
	add.s32 	%r783, %r1106, %r755;
	add.s32 	%r784, %r783, %r782;
	add.s32 	%r785, %r784, -1444681467;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r785, 5;
	shr.b32 	%rhs, %r785, 27;
	add.u32 	%r786, %lhs, %rhs;
	}
	add.s32 	%r787, %r786, %r779;
	xor.b32  	%r788, %r787, %r779;
	and.b32  	%r789, %r788, %r771;
	xor.b32  	%r790, %r789, %r779;
	add.s32 	%r791, %r1051, %r763;
	add.s32 	%r792, %r791, %r790;
	add.s32 	%r793, %r792, -51403784;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r793, 9;
	shr.b32 	%rhs, %r793, 23;
	add.u32 	%r794, %lhs, %rhs;
	}
	add.s32 	%r795, %r794, %r787;
	xor.b32  	%r796, %r795, %r787;
	and.b32  	%r797, %r796, %r779;
	xor.b32  	%r798, %r797, %r787;
	add.s32 	%r799, %r1054, %r771;
	add.s32 	%r800, %r799, %r798;
	add.s32 	%r801, %r800, 1735328473;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r801, 14;
	shr.b32 	%rhs, %r801, 18;
	add.u32 	%r802, %lhs, %rhs;
	}
	add.s32 	%r803, %r802, %r795;
	xor.b32  	%r804, %r803, %r795;
	and.b32  	%r805, %r804, %r787;
	xor.b32  	%r806, %r805, %r795;
	add.s32 	%r807, %r1107, %r779;
	add.s32 	%r808, %r807, %r806;
	add.s32 	%r809, %r808, -1926607734;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r809, 20;
	shr.b32 	%rhs, %r809, 12;
	add.u32 	%r810, %lhs, %rhs;
	}
	add.s32 	%r811, %r810, %r803;
	xor.b32  	%r812, %r811, %r803;
	xor.b32  	%r813, %r812, %r795;
	add.s32 	%r814, %r1056, %r787;
	add.s32 	%r815, %r814, %r813;
	add.s32 	%r816, %r815, -378558;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r816, 4;
	shr.b32 	%rhs, %r816, 28;
	add.u32 	%r817, %lhs, %rhs;
	}
	add.s32 	%r818, %r817, %r811;
	xor.b32  	%r819, %r818, %r812;
	add.s32 	%r820, %r1061, %r795;
	add.s32 	%r821, %r820, %r819;
	add.s32 	%r822, %r821, -2022574463;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r822, 11;
	shr.b32 	%rhs, %r822, 21;
	add.u32 	%r823, %lhs, %rhs;
	}
	add.s32 	%r824, %r823, %r818;
	xor.b32  	%r825, %r824, %r818;
	xor.b32  	%r826, %r825, %r811;
	add.s32 	%r827, %r1058, %r803;
	add.s32 	%r828, %r827, %r826;
	add.s32 	%r829, %r828, 1839030562;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r829, 16;
	shr.b32 	%rhs, %r829, 16;
	add.u32 	%r830, %lhs, %rhs;
	}
	add.s32 	%r831, %r830, %r824;
	xor.b32  	%r832, %r831, %r825;
	add.s32 	%r833, %r672, %r811;
	add.s32 	%r834, %r833, %r832;
	add.s32 	%r835, %r834, -35309556;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r835, 23;
	shr.b32 	%rhs, %r835, 9;
	add.u32 	%r836, %lhs, %rhs;
	}
	add.s32 	%r837, %r836, %r831;
	xor.b32  	%r838, %r837, %r831;
	xor.b32  	%r839, %r838, %r824;
	add.s32 	%r840, %r1052, %r818;
	add.s32 	%r841, %r840, %r839;
	add.s32 	%r842, %r841, -1530992060;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r842, 4;
	shr.b32 	%rhs, %r842, 28;
	add.u32 	%r843, %lhs, %rhs;
	}
	add.s32 	%r844, %r843, %r837;
	xor.b32  	%r845, %r844, %r838;
	add.s32 	%r846, %r1057, %r824;
	add.s32 	%r847, %r846, %r845;
	add.s32 	%r848, %r847, 1272893353;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r848, 11;
	shr.b32 	%rhs, %r848, 21;
	add.u32 	%r849, %lhs, %rhs;
	}
	add.s32 	%r850, %r849, %r844;
	xor.b32  	%r851, %r850, %r844;
	xor.b32  	%r852, %r851, %r837;
	add.s32 	%r853, %r1054, %r831;
	add.s32 	%r854, %r853, %r852;
	add.s32 	%r855, %r854, -155497632;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r855, 16;
	shr.b32 	%rhs, %r855, 16;
	add.u32 	%r856, %lhs, %rhs;
	}
	add.s32 	%r857, %r856, %r850;
	xor.b32  	%r858, %r857, %r851;
	add.s32 	%r859, %r1059, %r837;
	add.s32 	%r860, %r859, %r858;
	add.s32 	%r861, %r860, -1094730640;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r861, 23;
	shr.b32 	%rhs, %r861, 9;
	add.u32 	%r862, %lhs, %rhs;
	}
	add.s32 	%r863, %r862, %r857;
	xor.b32  	%r864, %r863, %r857;
	xor.b32  	%r865, %r864, %r850;
	add.s32 	%r866, %r1106, %r844;
	add.s32 	%r867, %r866, %r865;
	add.s32 	%r868, %r867, 681279174;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r868, 4;
	shr.b32 	%rhs, %r868, 28;
	add.u32 	%r869, %lhs, %rhs;
	}
	add.s32 	%r870, %r869, %r863;
	xor.b32  	%r871, %r870, %r864;
	add.s32 	%r872, %r1053, %r850;
	add.s32 	%r873, %r872, %r871;
	add.s32 	%r874, %r873, -358537222;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r874, 11;
	shr.b32 	%rhs, %r874, 21;
	add.u32 	%r875, %lhs, %rhs;
	}
	add.s32 	%r876, %r875, %r870;
	xor.b32  	%r877, %r876, %r870;
	xor.b32  	%r878, %r877, %r863;
	add.s32 	%r879, %r1050, %r857;
	add.s32 	%r880, %r879, %r878;
	add.s32 	%r881, %r880, -722521979;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r881, 16;
	shr.b32 	%rhs, %r881, 16;
	add.u32 	%r882, %lhs, %rhs;
	}
	add.s32 	%r883, %r882, %r876;
	xor.b32  	%r884, %r883, %r877;
	add.s32 	%r885, %r1055, %r863;
	add.s32 	%r886, %r885, %r884;
	add.s32 	%r887, %r886, 76029189;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r887, 23;
	shr.b32 	%rhs, %r887, 9;
	add.u32 	%r888, %lhs, %rhs;
	}
	add.s32 	%r889, %r888, %r883;
	xor.b32  	%r890, %r889, %r883;
	xor.b32  	%r891, %r890, %r876;
	add.s32 	%r892, %r1060, %r870;
	add.s32 	%r893, %r892, %r891;
	add.s32 	%r894, %r893, -640364487;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r894, 4;
	shr.b32 	%rhs, %r894, 28;
	add.u32 	%r895, %lhs, %rhs;
	}
	add.s32 	%r896, %r895, %r889;
	xor.b32  	%r897, %r896, %r890;
	add.s32 	%r898, %r1107, %r876;
	add.s32 	%r899, %r898, %r897;
	add.s32 	%r900, %r899, -421815835;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r900, 11;
	shr.b32 	%rhs, %r900, 21;
	add.u32 	%r901, %lhs, %rhs;
	}
	add.s32 	%r902, %r901, %r896;
	xor.b32  	%r903, %r902, %r896;
	xor.b32  	%r904, %r903, %r889;
	add.s32 	%r905, %r883, %r904;
	add.s32 	%r906, %r905, 530742520;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r906, 16;
	shr.b32 	%rhs, %r906, 16;
	add.u32 	%r907, %lhs, %rhs;
	}
	add.s32 	%r908, %r907, %r902;
	xor.b32  	%r909, %r908, %r903;
	add.s32 	%r910, %r1051, %r889;
	add.s32 	%r911, %r910, %r909;
	add.s32 	%r912, %r911, -995338651;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r912, 23;
	shr.b32 	%rhs, %r912, 9;
	add.u32 	%r913, %lhs, %rhs;
	}
	add.s32 	%r914, %r913, %r908;
	not.b32 	%r915, %r902;
	or.b32  	%r916, %r914, %r915;
	xor.b32  	%r917, %r916, %r908;
	add.s32 	%r918, %r1053, %r896;
	add.s32 	%r919, %r918, %r917;
	add.s32 	%r920, %r919, -198630844;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r920, 6;
	shr.b32 	%rhs, %r920, 26;
	add.u32 	%r921, %lhs, %rhs;
	}
	add.s32 	%r922, %r921, %r914;
	not.b32 	%r923, %r908;
	or.b32  	%r924, %r922, %r923;
	xor.b32  	%r925, %r924, %r914;
	add.s32 	%r926, %r1054, %r902;
	add.s32 	%r927, %r926, %r925;
	add.s32 	%r928, %r927, 1126891415;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r928, 10;
	shr.b32 	%rhs, %r928, 22;
	add.u32 	%r929, %lhs, %rhs;
	}
	add.s32 	%r930, %r929, %r922;
	not.b32 	%r931, %r914;
	or.b32  	%r932, %r930, %r931;
	xor.b32  	%r933, %r932, %r922;
	add.s32 	%r934, %r672, %r908;
	add.s32 	%r935, %r934, %r933;
	add.s32 	%r936, %r935, -1416354905;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r936, 15;
	shr.b32 	%rhs, %r936, 17;
	add.u32 	%r937, %lhs, %rhs;
	}
	add.s32 	%r938, %r937, %r930;
	not.b32 	%r939, %r922;
	or.b32  	%r940, %r938, %r939;
	xor.b32  	%r941, %r940, %r930;
	add.s32 	%r942, %r1056, %r914;
	add.s32 	%r943, %r942, %r941;
	add.s32 	%r944, %r943, -57434055;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r944, 21;
	shr.b32 	%rhs, %r944, 11;
	add.u32 	%r945, %lhs, %rhs;
	}
	add.s32 	%r946, %r945, %r938;
	not.b32 	%r947, %r930;
	or.b32  	%r948, %r946, %r947;
	xor.b32  	%r949, %r948, %r938;
	add.s32 	%r950, %r1107, %r922;
	add.s32 	%r951, %r950, %r949;
	add.s32 	%r952, %r951, 1700485571;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r952, 6;
	shr.b32 	%rhs, %r952, 26;
	add.u32 	%r953, %lhs, %rhs;
	}
	add.s32 	%r954, %r953, %r946;
	not.b32 	%r955, %r938;
	or.b32  	%r956, %r954, %r955;
	xor.b32  	%r957, %r956, %r946;
	add.s32 	%r958, %r1050, %r930;
	add.s32 	%r959, %r958, %r957;
	add.s32 	%r960, %r959, -1894986606;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r960, 10;
	shr.b32 	%rhs, %r960, 22;
	add.u32 	%r961, %lhs, %rhs;
	}
	add.s32 	%r962, %r961, %r954;
	not.b32 	%r963, %r946;
	or.b32  	%r964, %r962, %r963;
	xor.b32  	%r965, %r964, %r954;
	add.s32 	%r966, %r1059, %r938;
	add.s32 	%r967, %r966, %r965;
	add.s32 	%r968, %r967, -1051523;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r968, 15;
	shr.b32 	%rhs, %r968, 17;
	add.u32 	%r969, %lhs, %rhs;
	}
	add.s32 	%r970, %r969, %r962;
	not.b32 	%r971, %r954;
	or.b32  	%r972, %r970, %r971;
	xor.b32  	%r973, %r972, %r962;
	add.s32 	%r974, %r1052, %r946;
	add.s32 	%r975, %r974, %r973;
	add.s32 	%r976, %r975, -2054922799;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r976, 21;
	shr.b32 	%rhs, %r976, 11;
	add.u32 	%r977, %lhs, %rhs;
	}
	add.s32 	%r978, %r977, %r970;
	not.b32 	%r979, %r962;
	or.b32  	%r980, %r978, %r979;
	xor.b32  	%r981, %r980, %r970;
	add.s32 	%r982, %r1061, %r954;
	add.s32 	%r983, %r982, %r981;
	add.s32 	%r984, %r983, 1873313359;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r984, 6;
	shr.b32 	%rhs, %r984, 26;
	add.u32 	%r985, %lhs, %rhs;
	}
	add.s32 	%r986, %r985, %r978;
	not.b32 	%r987, %r970;
	or.b32  	%r988, %r986, %r987;
	xor.b32  	%r989, %r988, %r978;
	add.s32 	%r990, %r962, %r989;
	add.s32 	%r991, %r990, -30611744;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r991, 10;
	shr.b32 	%rhs, %r991, 22;
	add.u32 	%r992, %lhs, %rhs;
	}
	add.s32 	%r993, %r992, %r986;
	not.b32 	%r994, %r978;
	or.b32  	%r995, %r993, %r994;
	xor.b32  	%r996, %r995, %r986;
	add.s32 	%r997, %r1055, %r970;
	add.s32 	%r998, %r997, %r996;
	add.s32 	%r999, %r998, -1560198380;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r999, 15;
	shr.b32 	%rhs, %r999, 17;
	add.u32 	%r1000, %lhs, %rhs;
	}
	add.s32 	%r1001, %r1000, %r993;
	not.b32 	%r1002, %r986;
	or.b32  	%r1003, %r1001, %r1002;
	xor.b32  	%r1004, %r1003, %r993;
	add.s32 	%r1005, %r1106, %r978;
	add.s32 	%r1006, %r1005, %r1004;
	add.s32 	%r1007, %r1006, 1309151649;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1007, 21;
	shr.b32 	%rhs, %r1007, 11;
	add.u32 	%r1008, %lhs, %rhs;
	}
	add.s32 	%r1009, %r1008, %r1001;
	not.b32 	%r1010, %r993;
	or.b32  	%r1011, %r1009, %r1010;
	xor.b32  	%r1012, %r1011, %r1001;
	add.s32 	%r1013, %r1057, %r986;
	add.s32 	%r1014, %r1013, %r1012;
	add.s32 	%r1015, %r1014, -145523070;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1015, 6;
	shr.b32 	%rhs, %r1015, 26;
	add.u32 	%r1016, %lhs, %rhs;
	}
	add.s32 	%r1017, %r1016, %r1009;
	not.b32 	%r1018, %r1001;
	or.b32  	%r1019, %r1017, %r1018;
	xor.b32  	%r1020, %r1019, %r1009;
	add.s32 	%r1021, %r1058, %r993;
	add.s32 	%r1022, %r1021, %r1020;
	add.s32 	%r1023, %r1022, -1120210379;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1023, 10;
	shr.b32 	%rhs, %r1023, 22;
	add.u32 	%r1024, %lhs, %rhs;
	}
	add.s32 	%r1025, %r1024, %r1017;
	not.b32 	%r1026, %r1009;
	or.b32  	%r1027, %r1025, %r1026;
	xor.b32  	%r1028, %r1027, %r1017;
	add.s32 	%r1029, %r1051, %r1001;
	add.s32 	%r1030, %r1029, %r1028;
	add.s32 	%r1031, %r1030, 718787259;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1031, 15;
	shr.b32 	%rhs, %r1031, 17;
	add.u32 	%r1032, %lhs, %rhs;
	}
	add.s32 	%r1033, %r1032, %r1025;
	not.b32 	%r1034, %r1017;
	or.b32  	%r1035, %r1033, %r1034;
	xor.b32  	%r1036, %r1035, %r1025;
	add.s32 	%r1037, %r1060, %r1009;
	add.s32 	%r1038, %r1037, %r1036;
	add.s32 	%r1039, %r1038, -343485551;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1039, 21;
	shr.b32 	%rhs, %r1039, 11;
	add.u32 	%r1040, %lhs, %rhs;
	}
	add.s32 	%r1108, %r1025, 271733878;
	add.s32 	%r1109, %r1033, -1732584194;
	add.s32 	%r1041, %r1033, %r1040;
	add.s32 	%r1110, %r1041, -271733879;
	add.s32 	%r1111, %r1017, 1732584193;
	add.s32 	%r1044, %r1044, 1;
	add.s32 	%r1045, %r1045, 1;
	setp.lt.u32	%p82, %r1045, %r1043;
	@%p82 bra 	BB4_3;

BB4_148:
	st.global.u32 	[%rd2], %r1111;
	st.global.u32 	[%rd2+4], %r1110;
	st.global.u32 	[%rd2+8], %r1109;
	st.global.u32 	[%rd2+12], %r1108;

BB4_149:
	ret;
}

	// .globl	m00500_comp
.entry m00500_comp(
	.param .u64 .ptr .global .align 4 m00500_comp_param_0,
	.param .u64 .ptr .global .align 4 m00500_comp_param_1,
	.param .u64 .ptr .global .align 4 m00500_comp_param_2,
	.param .u64 .ptr .global .align 4 m00500_comp_param_3,
	.param .u64 .ptr .global .align 4 m00500_comp_param_4,
	.param .u64 .ptr .global .align 1 m00500_comp_param_5,
	.param .u64 .ptr .global .align 4 m00500_comp_param_6,
	.param .u64 .ptr .global .align 4 m00500_comp_param_7,
	.param .u64 .ptr .global .align 4 m00500_comp_param_8,
	.param .u64 .ptr .global .align 4 m00500_comp_param_9,
	.param .u64 .ptr .global .align 4 m00500_comp_param_10,
	.param .u64 .ptr .global .align 4 m00500_comp_param_11,
	.param .u64 .ptr .global .align 4 m00500_comp_param_12,
	.param .u64 .ptr .global .align 4 m00500_comp_param_13,
	.param .u64 .ptr .global .align 8 m00500_comp_param_14,
	.param .u64 .ptr .global .align 4 m00500_comp_param_15,
	.param .u64 .ptr .global .align 4 m00500_comp_param_16,
	.param .u64 .ptr .global .align 4 m00500_comp_param_17,
	.param .u64 .ptr .global .align 1 m00500_comp_param_18,
	.param .u64 .ptr .global .align 4 m00500_comp_param_19,
	.param .u64 .ptr .global .align 16 m00500_comp_param_20,
	.param .u64 .ptr .global .align 16 m00500_comp_param_21,
	.param .u64 .ptr .global .align 16 m00500_comp_param_22,
	.param .u64 .ptr .global .align 16 m00500_comp_param_23,
	.param .u32 m00500_comp_param_24,
	.param .u32 m00500_comp_param_25,
	.param .u32 m00500_comp_param_26,
	.param .u32 m00500_comp_param_27,
	.param .u32 m00500_comp_param_28,
	.param .u32 m00500_comp_param_29,
	.param .u32 m00500_comp_param_30,
	.param .u32 m00500_comp_param_31,
	.param .u32 m00500_comp_param_32,
	.param .u32 m00500_comp_param_33,
	.param .u64 m00500_comp_param_34
)
{
	.reg .pred 	%p<25>;
	.reg .b32 	%r<99>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd3, [m00500_comp_param_4];
	ld.param.u64 	%rd4, [m00500_comp_param_6];
	ld.param.u64 	%rd5, [m00500_comp_param_7];
	ld.param.u64 	%rd6, [m00500_comp_param_8];
	ld.param.u64 	%rd7, [m00500_comp_param_9];
	ld.param.u64 	%rd8, [m00500_comp_param_10];
	ld.param.u64 	%rd9, [m00500_comp_param_11];
	ld.param.u64 	%rd10, [m00500_comp_param_12];
	ld.param.u64 	%rd11, [m00500_comp_param_13];
	ld.param.u64 	%rd12, [m00500_comp_param_14];
	ld.param.u64 	%rd13, [m00500_comp_param_15];
	ld.param.u64 	%rd14, [m00500_comp_param_16];
	ld.param.u64 	%rd15, [m00500_comp_param_19];
	ld.param.u32 	%r27, [m00500_comp_param_24];
	ld.param.u32 	%r28, [m00500_comp_param_25];
	ld.param.u32 	%r29, [m00500_comp_param_26];
	ld.param.u32 	%r30, [m00500_comp_param_27];
	ld.param.u32 	%r31, [m00500_comp_param_31];
	ld.param.u32 	%r32, [m00500_comp_param_32];
	ld.param.u64 	%rd16, [m00500_comp_param_34];
	mov.b32	%r33, %envreg3;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r35, %ntid.x;
	mad.lo.s32 	%r36, %r34, %r35, %r33;
	mov.u32 	%r37, %tid.x;
	add.s32 	%r1, %r36, %r37;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd16;
	@%p1 bra 	BB5_29;

	mul.wide.s32 	%rd17, %r1, 16;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.u32 	%r2, [%rd18+4];
	ld.global.u32 	%r3, [%rd18+8];
	ld.global.u32 	%r4, [%rd18+12];
	and.b32  	%r5, %r28, 31;
	ld.global.u32 	%r6, [%rd18];
	shr.u32 	%r38, %r6, %r5;
	and.b32  	%r39, %r38, %r27;
	mul.wide.u32 	%rd19, %r39, 4;
	add.s64 	%rd20, %rd4, %rd19;
	and.b32  	%r40, %r6, 31;
	mov.u32 	%r41, 1;
	shl.b32 	%r7, %r41, %r40;
	ld.global.u32 	%r42, [%rd20];
	and.b32  	%r43, %r42, %r7;
	setp.eq.s32	%p2, %r43, 0;
	@%p2 bra 	BB5_29;

	shr.u32 	%r44, %r2, %r5;
	and.b32  	%r45, %r44, %r27;
	mul.wide.u32 	%rd21, %r45, 4;
	add.s64 	%rd22, %rd5, %rd21;
	and.b32  	%r46, %r2, 31;
	shl.b32 	%r8, %r41, %r46;
	ld.global.u32 	%r48, [%rd22];
	and.b32  	%r49, %r48, %r8;
	setp.eq.s32	%p3, %r49, 0;
	@%p3 bra 	BB5_29;

	shr.u32 	%r50, %r3, %r5;
	and.b32  	%r51, %r50, %r27;
	mul.wide.u32 	%rd23, %r51, 4;
	add.s64 	%rd24, %rd6, %rd23;
	and.b32  	%r52, %r3, 31;
	shl.b32 	%r9, %r41, %r52;
	ld.global.u32 	%r54, [%rd24];
	and.b32  	%r55, %r54, %r9;
	setp.eq.s32	%p4, %r55, 0;
	@%p4 bra 	BB5_29;

	shr.u32 	%r56, %r4, %r5;
	and.b32  	%r57, %r56, %r27;
	mul.wide.u32 	%rd25, %r57, 4;
	add.s64 	%rd26, %rd7, %rd25;
	and.b32  	%r58, %r4, 31;
	shl.b32 	%r10, %r41, %r58;
	ld.global.u32 	%r60, [%rd26];
	and.b32  	%r61, %r60, %r10;
	setp.eq.s32	%p5, %r61, 0;
	@%p5 bra 	BB5_29;

	and.b32  	%r11, %r29, 31;
	shr.u32 	%r62, %r6, %r11;
	and.b32  	%r63, %r62, %r27;
	mul.wide.u32 	%rd27, %r63, 4;
	add.s64 	%rd28, %rd8, %rd27;
	ld.global.u32 	%r64, [%rd28];
	and.b32  	%r65, %r64, %r7;
	setp.eq.s32	%p6, %r65, 0;
	@%p6 bra 	BB5_29;

	shr.u32 	%r66, %r2, %r11;
	and.b32  	%r67, %r66, %r27;
	mul.wide.u32 	%rd29, %r67, 4;
	add.s64 	%rd30, %rd9, %rd29;
	ld.global.u32 	%r68, [%rd30];
	and.b32  	%r69, %r68, %r8;
	setp.eq.s32	%p7, %r69, 0;
	@%p7 bra 	BB5_29;

	shr.u32 	%r70, %r3, %r11;
	and.b32  	%r71, %r70, %r27;
	mul.wide.u32 	%rd31, %r71, 4;
	add.s64 	%rd32, %rd10, %rd31;
	ld.global.u32 	%r72, [%rd32];
	and.b32  	%r73, %r72, %r9;
	setp.eq.s32	%p8, %r73, 0;
	@%p8 bra 	BB5_29;

	shr.u32 	%r74, %r4, %r11;
	and.b32  	%r75, %r74, %r27;
	mul.wide.u32 	%rd33, %r75, 4;
	add.s64 	%rd34, %rd11, %rd33;
	ld.global.u32 	%r76, [%rd34];
	and.b32  	%r77, %r76, %r10;
	setp.eq.s32	%p9, %r77, 0;
	@%p9 bra 	BB5_29;

	setp.eq.s32	%p10, %r31, 0;
	mov.u32 	%r96, 0;
	mov.u32 	%r78, -1;
	@%p10 bra 	BB5_23;

	mov.u32 	%r95, %r31;

BB5_11:
	shr.u32 	%r14, %r95, 1;
	add.s32 	%r98, %r14, %r96;
	cvt.u64.u32	%rd35, %r98;
	cvt.u64.u32	%rd36, %r32;
	add.s64 	%rd37, %rd35, %rd36;
	shl.b64 	%rd38, %rd37, 4;
	add.s64 	%rd2, %rd13, %rd38;
	ld.global.u32 	%r16, [%rd2+12];
	setp.gt.u32	%p11, %r4, %r16;
	mov.u32 	%r97, %r41;
	@%p11 bra 	BB5_21;

	setp.lt.u32	%p12, %r4, %r16;
	mov.u32 	%r81, -1;
	@%p12 bra 	BB5_13;
	bra.uni 	BB5_14;

BB5_13:
	mov.u32 	%r97, %r81;
	bra.uni 	BB5_21;

BB5_14:
	ld.global.u32 	%r17, [%rd2+8];
	setp.gt.u32	%p13, %r3, %r17;
	mov.u32 	%r97, %r41;
	@%p13 bra 	BB5_21;

	setp.lt.u32	%p14, %r3, %r17;
	@%p14 bra 	BB5_16;
	bra.uni 	BB5_17;

BB5_16:
	mov.u32 	%r97, %r81;
	bra.uni 	BB5_21;

BB5_17:
	ld.global.u32 	%r18, [%rd2+4];
	setp.gt.u32	%p15, %r2, %r18;
	mov.u32 	%r97, %r41;
	@%p15 bra 	BB5_21;

	setp.lt.u32	%p16, %r2, %r18;
	mov.u32 	%r97, %r81;
	@%p16 bra 	BB5_21;

	ld.global.u32 	%r19, [%rd2];
	setp.gt.u32	%p17, %r6, %r19;
	mov.u32 	%r97, %r41;
	@%p17 bra 	BB5_21;

	setp.lt.u32	%p18, %r6, %r19;
	selp.b32	%r97, -1, 0, %p18;

BB5_21:
	add.s32 	%r87, %r14, 1;
	setp.gt.s32	%p19, %r97, 0;
	selp.b32	%r88, %r87, 0, %p19;
	add.s32 	%r96, %r88, %r96;
	selp.b32	%r89, -1, 0, %p19;
	add.s32 	%r90, %r89, %r95;
	shr.u32 	%r95, %r90, 1;
	setp.eq.s32	%p20, %r97, 0;
	@%p20 bra 	BB5_24;

	setp.ne.s32	%p21, %r95, 0;
	@%p21 bra 	BB5_11;

BB5_23:
	mov.u32 	%r98, %r78;

BB5_24:
	setp.eq.s32	%p22, %r98, -1;
	@%p22 bra 	BB5_29;

	add.s32 	%r25, %r98, %r32;
	mul.wide.u32 	%rd39, %r25, 4;
	add.s64 	%rd40, %rd14, %rd39;
	atom.global.add.u32 	%r92, [%rd40], 1;
	setp.ne.s32	%p23, %r92, 0;
	@%p23 bra 	BB5_29;

	atom.global.add.u32 	%r26, [%rd15], 1;
	setp.lt.u32	%p24, %r26, %r31;
	@%p24 bra 	BB5_28;
	bra.uni 	BB5_27;

BB5_28:
	mul.wide.u32 	%rd41, %r26, 24;
	add.s64 	%rd42, %rd12, %rd41;
	st.global.v2.u32 	[%rd42+16], {%r98, %r25};
	mov.u32 	%r94, 0;
	st.global.v2.u32 	[%rd42+8], {%r94, %r30};
	st.global.u64 	[%rd42], %rd1;
	bra.uni 	BB5_29;

BB5_27:
	atom.global.add.u32 	%r93, [%rd15], -1;

BB5_29:
	ret;
}


  